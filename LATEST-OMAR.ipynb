{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Assignment Four: Extending Logistic Regression \n",
    "## Rupal Sanghavi, Omar Roa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset represents the responses from students and their friends(ages 15-30, henceforth stated as \"young people\") of a Statistics class from the Faculty of Social and Economic Sciences at The Comenius University in Bratislava, Slovakia. Their survey was a mix of various topics.\n",
    "\n",
    "* Music preferences (19 items)\n",
    "* Movie preferences (12 items)\n",
    "* Hobbies & interests (32 items)\n",
    "* Phobias (10 items)\n",
    "* Health habits (3 items)\n",
    "* Personality traits, views on life, & opinions (57 items)\n",
    "* Spending habits (7 items)\n",
    "* Demographics (10 items)\n",
    "\n",
    "The dataset can be found here. https://www.kaggle.com/miroslavsabo/young-people-survey\n",
    "\n",
    "Our target is to predict how likely a \"young person\" would be interested in shopping at a large shopping center. We were not given details about what a \"large\" shopping center, but searching online for malls led us to the Avion Shopping Park in Ružinov, Slovakia. It has an area of 103,000m<sup>2</sup> and is the largest shopping mall in Slovakia (https://www.avion.sk/sk-sk/about-the-centre/fakty-a-cisla). \n",
    "\n",
    "Slovakia is in the lower half of European nations by size (28/48 - https://en.wikipedia.org/wiki/List_of_European_countries_by_area) and is very mountainous, making real estate space a precious commodity. This information would be of great interest to any commercial devlopment firm deciding on where to build their next shopping center or place of business. This could also help other parties trying to purchase real estate for youth-orientated construction (parks, recreation centers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "%matplotlib inline \n",
    "%load_ext memory_profiler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.special import expit\n",
    "import time\n",
    "import math\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression as SKLogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "np.errstate(all='ignore')\n",
    "\n",
    "target_classifier = 'Shopping centres'\n",
    "df = pd.read_csv('responses.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and Prepare Class Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove rows whose target classfier value is NaN\n",
    "df_cleaned_classifier = df[np.isfinite(df[target_classifier])]\n",
    "# change NaN number values to the mean\n",
    "df_imputed = df_cleaned_classifier.fillna(df.mean())\n",
    "# get categorical features\n",
    "object_features = list(df_cleaned_classifier.select_dtypes(include=['object']).columns)\n",
    "# one hot encode categorical features\n",
    "one_hot_df = pd.concat([pd.get_dummies(df_imputed[col],prefix=col) for col in object_features], axis=1)\n",
    "# drop object features from imputed dataframe\n",
    "df_imputed_dropped = df_imputed.drop(object_features, 1)\n",
    "frames = [df_imputed_dropped, one_hot_df]\n",
    "# concatenate both frames by columns\n",
    "df_fixed = pd.concat(frames, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned_classifier.isnull().sum().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1008, 173)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fixed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset (1010 rows and 150 columns) was mostly ordinal data as numbers (preferences ranked 1-5) . We also had some ordinal data as strings. \n",
    "\n",
    "e.g.\n",
    "How much time do you spend online?: No time at all - Less than an hour a day - Few hours a day - Most of the day\n",
    "\n",
    "We first removed any rows which contained NaN values for our target classifer, Shopping centres. Afterwards we imputed mean values for any NaN values in other features. We decided to impute due to the fact that there were not many NaN values in our features compared to the size of our data set. (At most was 20 for a feature, as shown above). We then one-hot encoded any string object, which created extra features.\n",
    "\n",
    "We are left with numerical values for our features and a size of 1008 x 173"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide Data into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=1, random_state=None, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# we want to predict the X and y data as follows:\n",
    "if target_classifier in df_fixed:\n",
    "    y = df_fixed[target_classifier].values # get the labels we want\n",
    "    del df_fixed[target_classifier] # get rid of the class label\n",
    "    X = df_fixed.values # use everything else to predict!\n",
    "\n",
    "num_cv_iterations = 1\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,test_size = 0.2)\n",
    "\n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using Stratified Shuffle Splits so we can get a good random mix of training and testing data. We want to split and randommize our data to prevent overfitting our model. Our split uses a 20/80 split for testing and training. This gives us a significant representation of data for training and testing. Upon further research, splitting our testing data into testing and validation seems further appropriate, but we are not implementing that for our work.\n",
    "\n",
    "Further down in our work, we are using Principal Component Analysis (via a Pipeline object) to reduce the number of features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 61 µs, sys: 91 µs, total: 152 µs\n",
      "Wall time: 157 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# from last time, our logistic regression algorithm is given by (including everything we previously had):\n",
    "class BinaryLogisticRegression:\n",
    "    def __init__(self, eta, iterations=20, C=0.001,reg=0):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        self.C = C\n",
    "        self.iterations = 0\n",
    "        self.reg = reg\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "        \n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'Binary Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained Binary Logistic Regression Object'\n",
    "        \n",
    "    # convenience, private:\n",
    "    @staticmethod\n",
    "    def _add_bias(X):\n",
    "        return np.hstack((np.ones((X.shape[0],1)),X)) # add bias term\n",
    "    \n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        # increase stability, redefine sigmoid operation\n",
    "        return expit(theta) #1/(1+np.exp(-theta))\n",
    "    \n",
    "    # vectorized gradient calculation with regularization using L2 Norm\n",
    "    def _get_gradient(self,X,y):\n",
    "        ydiff = y-self.predict_proba(X,add_bias=False).ravel() # get y difference\n",
    "        gradient = np.mean(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\n",
    "        \n",
    "        gradient = gradient.reshape(self.w_.shape)\n",
    "        if(self.reg == 0):\n",
    "            gradient[1:] += 2 * self.w_[1:] * self.C\n",
    "        elif(self.reg == 1):\n",
    "            gradient[1:] += np.sign(self.w_[1:]) * self.C\n",
    "        else:\n",
    "            gradient[1:] += 2 * self.w_[1:] * self.C\n",
    "            gradient[1:] += np.sign(self.w_[1:]) * self.C\n",
    "        #gradient[1:] += 2 * self.w_[1:] * self.C\n",
    "        \n",
    "        return gradient\n",
    "    def _get_l1_gradient(self,X,y):\n",
    "        ydiff = y-self.predict_proba(X,add_bias=False).ravel() # get y difference\n",
    "        gradient = np.mean(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\n",
    "        \n",
    "        gradient = gradient.reshape(self.w_.shape)\n",
    "        gradient[1:] += np.sign(self.w_[1:]) * self.C\n",
    "        return gradient\n",
    "    # public:\n",
    "    def predict_proba(self,X,add_bias=True):\n",
    "        # add bias term if requested\n",
    "        Xb = self._add_bias(X) if add_bias else X\n",
    "        return self._sigmoid(Xb @ self.w_) # return the probability y=1\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return (self.predict_proba(X)>0.5) #return the actual prediction\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        Xb = self._add_bias(X) # add bias term\n",
    "        num_samples, num_features = Xb.shape\n",
    "        \n",
    "        self.w_ = np.zeros((num_features,1)) # init weight vector to zeros\n",
    "        \n",
    "        # for as many as the max iterations\n",
    "        for _ in range(self.iters):\n",
    "            gradient = self._get_gradient(Xb,y)\n",
    "            self.w_ += gradient*self.eta # multiply by learning rate \n",
    "\n",
    "# blr = BinaryLogisticRegression(eta=0.1,iterations=500,C=0.001)\n",
    "\n",
    "# blr.fit(X,y)\n",
    "# print(blr)\n",
    "\n",
    "# yhat = blr.predict(X)\n",
    "# print('Accuracy of: ',accuracy_score(y,yhat+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 74 µs, sys: 94 µs, total: 168 µs\n",
      "Wall time: 173 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# and we can update this to use a line search along the gradient like this:\n",
    "from scipy.optimize import minimize_scalar\n",
    "from scipy.optimize import OptimizeResult\n",
    "\n",
    "import copy\n",
    "class LineSearchLogisticRegression(BinaryLogisticRegression):\n",
    "    \n",
    "    # define custom line search for problem\n",
    "    @staticmethod\n",
    "    def line_search_function(eta,X,y,w,grad,C):\n",
    "        wnew = w + grad*eta\n",
    "        yhat = expit(X @ wnew)>0.5\n",
    "        return np.sum((y-yhat)**2) + C*np.sum(wnew**2)\n",
    "     \n",
    "    def fit(self, X, y):\n",
    "        Xb = self._add_bias(X) # add bias term\n",
    "        num_samples, num_features = Xb.shape\n",
    "        \n",
    "        self.w_ = np.zeros((num_features,1)) # init weight vector to zeros\n",
    "        \n",
    "        # for as many as the max iterations\n",
    "        for _ in range(self.iters):\n",
    "            gradient = self._get_gradient(Xb,y)\n",
    "            \n",
    "            # do line search in gradient direction, using scipy function\n",
    "            opts = {'maxiter':self.iters/20} # unclear exactly what this should be\n",
    "            res = minimize_scalar(self.line_search_function, # objective function to optimize\n",
    "                                  bounds=(self.eta/1000,self.eta*10), #bounds to optimize\n",
    "                                  args=(Xb,y,self.w_,gradient,self.C), # additional argument for objective function\n",
    "                                  method='bounded', # bounded optimization for speed\n",
    "                                  options=opts) # set max iterations\n",
    "            eta = res.x # get optimal learning rate\n",
    "            self.w_ += gradient*eta # set new function values\n",
    "                \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44 µs, sys: 37 µs, total: 81 µs\n",
      "Wall time: 86.1 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "class StochasticLogisticRegression(BinaryLogisticRegression):\n",
    "    # stochastic gradient calculation \n",
    "    def _get_gradient(self,X,y):\n",
    "        idx = int(np.random.rand()*len(y)) # grab random instance\n",
    "        ydiff = y[idx]-self.predict_proba(X[idx],add_bias=False) # get y difference (now scalar)\n",
    "        gradient = X[idx] * ydiff[:,np.newaxis] # make ydiff a column vector and multiply through\n",
    "        \n",
    "        gradient = gradient.reshape(self.w_.shape)\n",
    "        if(self.reg == 0):\n",
    "            gradient[1:] += 2 * self.w_[1:] * self.C\n",
    "        elif(self.reg == 1):\n",
    "            gradient[1:] += np.sign(self.w_[1:]) * self.C\n",
    "        else:\n",
    "            gradient[1:] += 2 * self.w_[1:] * self.C\n",
    "            gradient[1:] += np.sign(self.w_[1:]) * self.C\n",
    "        #gradient[1:] += 2 * self.w_[1:] * self.C\n",
    "        #gradient[1:] += np.sign(self.w_[1:]) * self.C\n",
    "        return gradient\n",
    "    \n",
    "    \n",
    "# slr = StochasticLogisticRegression(0.1,1000, C=0.001) # take a lot more steps!!\n",
    "\n",
    "# slr.fit(X,y)\n",
    "\n",
    "# yhat = slr.predict(X)\n",
    "# print(slr)\n",
    "# print('Accuracy of: ',accuracy_score(y,yhat))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 89 µs, sys: 245 µs, total: 334 µs\n",
      "Wall time: 365 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# for this, we won't perform our own BFGS implementation \n",
    "# (it takes a good deal of code and understanding of the algorithm)\n",
    "# luckily for us, scipy has its own BFGS implementation:\n",
    "from scipy.optimize import fmin_bfgs\n",
    "class BFGSBinaryLogisticRegression(BinaryLogisticRegression):\n",
    "    @staticmethod\n",
    "    def objective_function(w,X,y,C,reg):\n",
    "        g = expit(X @ w)\n",
    "        return -np.sum(np.log(g[y==1]))-np.sum(np.log(1-g[y==0])) + C*sum(w**2) #-np.sum(y*np.log(g)+(1-y)*np.log(1-g))\n",
    "\n",
    "    @staticmethod\n",
    "    def objective_gradient(w,X,y,C,reg):\n",
    "        g = expit(X @ w)\n",
    "        ydiff = y-g # get y difference\n",
    "        gradient = np.mean(X * ydiff[:,np.newaxis], axis=0)\n",
    "        gradient = gradient.reshape(w.shape)\n",
    "        if(reg == 0):\n",
    "            gradient[1:] += 2 * w[1:] * C\n",
    "        elif(reg == 1):\n",
    "            gradient[1:] += np.sign(w[1:]) * C\n",
    "        else:\n",
    "            gradient[1:] += 2 * w[1:] * C\n",
    "            gradient[1:] += np.sign(w[1:]) * C\n",
    "        return -gradient\n",
    "    \n",
    "    # just overwrite fit function\n",
    "    def fit(self, X, y):\n",
    "        Xb = self._add_bias(X) # add bias term\n",
    "        num_samples, num_features = Xb.shape\n",
    "        self.w_ = fmin_bfgs(self.objective_function, # what to optimize\n",
    "                            np.zeros((num_features,1)), # starting point\n",
    "                            fprime=self.objective_gradient, # gradient function\n",
    "                            args=(Xb,y,self.C,self.reg), # extra args for gradient and objective function\n",
    "                            gtol=1e-03, # stopping criteria for gradient, |v_k|\n",
    "                            maxiter=self.iters, # stopping criteria iterations\n",
    "                            disp=False)\n",
    "        result = fmin_bfgs(self.objective_function, # what to optimize\n",
    "                            np.zeros((num_features,1)), # starting point\n",
    "                            fprime=self.objective_gradient, # gradient function\n",
    "                            args=(Xb,y,self.C,self.reg), # extra args for gradient and objective function\n",
    "                            gtol=1e-03, # stopping criteria for gradient, |v_k|\n",
    "                            maxiter=self.iters, # stopping criteria iterations\n",
    "                            disp=False,\n",
    "                            retall=True)\n",
    "        self.iterations = len(result)\n",
    "        #print(\"iterations: \", self.iterations)\n",
    "        self.w_ = self.w_.reshape((num_features,1))\n",
    "    def getIterations(self):\n",
    "        return self.iterations\n",
    "# bfgslr = BFGSBinaryLogisticRegression(_,2) # note that we need only a few iterations here\n",
    "\n",
    "# bfgslr.fit(X,y)\n",
    "# yhat = bfgslr.predict(X)\n",
    "# print(bfgslr)\n",
    "# print('Accuracy of: ',accuracy_score(y,yhat+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created the result (with parameter retall=True) variable to hold fmin_bfgs \n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fmin_bfgs.html\n",
    "\n",
    "based on the description for  retall\n",
    "\n",
    "retall : bool, optional\n",
    "Return a list of results at each iteration if True.\n",
    "\n",
    "We return the length of the list for the iterations.\n",
    "\n",
    "EDIT: We realized that we are not getting iterations correctly and were not able to get iterations for our implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MultiClassLogisticRegression:\n",
    "    def __init__(self, eta, iterations=20, C=0.0001, optimization=None,reg=0):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        self.C = C\n",
    "        self.classifiers_ = []\n",
    "        self.optimization = optimization\n",
    "        self.reg = reg\n",
    "        self.params = {}\n",
    "\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "    \n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'MultiClass Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained MultiClass Logistic Regression Object'\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        num_samples, num_features = X.shape\n",
    "        self.unique_ = np.sort(np.unique(y)) # get each unique class value\n",
    "        num_unique_classes = len(self.unique_)\n",
    "        self.classifiers_ = []\n",
    "        for i,yval in enumerate(self.unique_): # for each unique value\n",
    "            y_binary = y==yval # create a binary problem\n",
    "            # train the binary classifier for this class\n",
    "            #hblr = HessianBinaryLogisticRegression(self.eta,self.iters,self.C)\n",
    "            if(self.optimization == \"BFGSBinaryLogisticRegression\"):\n",
    "                #self.iters = 10\n",
    "                hblr = BFGSBinaryLogisticRegression(self.eta,self.iters,self.C,self.reg)\n",
    "                #print(\"Iterations: \",hblr.getIterations())\n",
    "\n",
    "            elif(self.optimization == \"StochasticLogisticRegression\"):\n",
    "                #self.iters = 2000 #1000\n",
    "                hblr = StochasticLogisticRegression(self.eta,self.iters,self.C,self.reg)\n",
    "            else:\n",
    "                #self.iters = 100\n",
    "                #self.C = 0.001\n",
    "                hblr = LineSearchLogisticRegression(self.eta,self.iters,self.C,self.reg)\n",
    "\n",
    "            hblr.fit(X,y_binary)\n",
    "            #print(accuracy(y_binary,hblr.predict(X)))\n",
    "            # add the trained classifier to the list\n",
    "            self.classifiers_.append(hblr)\n",
    "            \n",
    "        # save all the weights into one matrix, separate column for each class\n",
    "        self.w_ = np.hstack([x.w_ for x in self.classifiers_]).T\n",
    "        \n",
    "    def predict_proba(self,X):\n",
    "        probs = []\n",
    "        for hblr in self.classifiers_:\n",
    "            probs.append(hblr.predict_proba(X).reshape((len(X),1))) # get probability for each classifier\n",
    "        \n",
    "        return np.hstack(probs) # make into single matrix\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return np.argmax(self.predict_proba(X),axis=1) # take argmax along row\n",
    "    \n",
    "    def get_params(self,deep=False):\n",
    "        #return self.params\n",
    "        return dict(C=self.C,eta=self.eta,iterations=self.iters, optimization=self.optimization)\n",
    "\n",
    "    def set_params(self,**kwds):\n",
    "        print(kwds)\n",
    "        self.C = kwds['C']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying Different Optimization Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:9: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "For  BFGSBinaryLogisticRegression  eta:  0.1 Iterations:  10 Regularization:  L1  : Accuracy of:  0.331683168317\n",
      "confusion matrix\n",
      " [[ 7  5  7  0  1]\n",
      " [13  7  6  6  1]\n",
      " [ 3 14 12 12  6]\n",
      " [ 6  5 17 14 13]\n",
      " [ 3  2  5 10 27]]\n",
      "MultiClass Logistic Regression Object with coefficients:\n",
      "[[  6.46360840e-03  -1.62018096e-01  -2.14031535e-01   8.42113205e-02\n",
      "   -1.05426915e-01   6.50152272e-03   5.88580432e-02  -1.48308479e-01\n",
      "   -1.74842136e-01  -1.62241845e-01  -1.14954208e-01  -2.77975291e-01\n",
      "   -1.62344560e-01   3.83931535e-01   1.92490449e-01   1.45633274e-01\n",
      "    1.95825379e-01  -6.85022686e-02   1.09130896e-01  -4.38182996e-02\n",
      "   -3.15434803e-01   2.64777362e-01  -5.94468955e-02   3.23021936e-01\n",
      "   -1.88292999e-01  -1.26627858e-01   1.38904792e-01   6.24776252e-02\n",
      "   -9.75636956e-02   1.26772599e-01  -8.45464621e-02  -2.35662436e-01\n",
      "   -5.63543950e-02   1.83488572e-01  -4.15865108e-02   1.24123108e-01\n",
      "   -1.33831289e-01   1.57847254e-01  -1.27507182e-01   1.34000774e-01\n",
      "   -2.77868116e-01   1.75830485e-02   1.49679413e-01  -3.44426651e-02\n",
      "   -2.51635263e-01   2.67490362e-02  -1.49864725e-01   1.40960781e-01\n",
      "   -4.53638046e-02  -2.91838104e-02   8.77171320e-02  -1.00027254e-01\n",
      "    3.78347512e-02   1.00905126e-01  -6.36457272e-02   1.91587085e-01\n",
      "    4.08308776e-01  -3.97747251e-01  -1.19697550e+00   1.19749677e-01\n",
      "    1.44048585e-01   2.57509377e-01   6.38586590e-02  -3.94864388e-03\n",
      "    4.36992206e-01  -5.08486694e-02  -3.59002198e-02   6.40166406e-02\n",
      "   -1.39734096e-02  -1.84952882e-01   3.28387372e-02   6.49349464e-02\n",
      "   -2.84149700e-01   9.25965170e-02  -1.72314897e-01  -1.28148556e-01\n",
      "   -1.13250413e-01  -3.15628292e-02   2.25831871e-01   2.36995116e-02\n",
      "    2.10303980e-01   2.63618410e-01   1.52453598e-01  -4.00058802e-01\n",
      "    1.15958603e-02   8.73339901e-02  -1.52892744e-01  -6.10943872e-02\n",
      "    3.92290101e-02   1.20356643e-01   1.27399904e-01   3.04170860e-01\n",
      "    2.99395040e-01  -1.25456819e-01  -1.93191019e-01  -3.36487392e-01\n",
      "   -2.02010451e-01   3.27544654e-02   2.68150952e-01   2.34221333e-01\n",
      "    3.53936339e-01  -1.84455422e-02  -2.58705844e-01  -4.65469010e-02\n",
      "   -2.11990558e-01   4.28393211e-02   2.27579001e-01  -1.60676441e-01\n",
      "    2.38004465e-01  -5.12810831e-02   1.14636562e-01  -1.76136202e-01\n",
      "   -3.08247320e-02   1.45505370e-01   1.25323514e-01  -3.51661883e-02\n",
      "   -2.13273146e-01  -1.11288616e-01   2.40235539e-01   1.22223905e-01\n",
      "    3.72856478e-01  -2.40549325e-03   3.31865925e-01   6.00542338e-02\n",
      "    1.46166726e-01  -1.59181901e-01  -3.82345183e-01   9.21687591e-02\n",
      "   -5.08307840e-01  -2.98124004e-01  -4.08414905e-01  -7.41372123e-02\n",
      "   -6.14522524e-01  -1.75570078e-01  -2.72569733e-01  -1.48200481e-01\n",
      "    4.07305631e-02  -2.43236957e-02   4.49304398e-02  -4.05260664e-02\n",
      "   -1.35886482e-02  -4.04073326e-02   7.68536764e-02   1.48038028e-01\n",
      "   -9.09020009e-02  -9.88565898e-02  -1.20198788e-01   2.47423940e-02\n",
      "    1.04494083e-01   2.89578563e-02   4.15392805e-02  -1.39044023e-01\n",
      "    7.50827491e-02   2.31958553e-03  -7.40392798e-03   2.02349141e-02\n",
      "   -8.61470847e-03   7.94321033e-02  -8.55829296e-02  -2.57331601e-02\n",
      "    5.74439238e-02   1.56298046e-01   3.90512623e-02  -2.11688573e-02\n",
      "   -1.08752696e-01  -4.00765791e-02  -1.85531770e-02   1.55046047e-01\n",
      "   -1.39202814e-01  -8.38219781e-02   5.26901411e-02   1.10977818e-01\n",
      "   -9.29158919e-02]\n",
      " [ -7.88615090e-03   1.09726930e-01  -8.46022328e-02  -1.33786058e-01\n",
      "   -8.74643377e-02  -6.80421539e-02   7.64811466e-02  -1.91656537e-02\n",
      "    1.33048757e-01   1.90930346e-01  -1.60859101e-02   1.16397257e-02\n",
      "    2.43636710e-01  -5.71842778e-02  -8.29475601e-02  -5.01503389e-02\n",
      "   -2.16053659e-01   3.93463779e-03  -1.59814882e-01   2.75065308e-01\n",
      "    5.01369761e-02  -1.29205940e-03   7.45653723e-02  -2.34911223e-01\n",
      "   -3.94465867e-03  -2.20935042e-02  -3.70170030e-02   9.72899364e-02\n",
      "   -2.66767027e-02   2.76392451e-01   2.23633901e-01   1.17978764e-01\n",
      "   -3.99624716e-02  -1.44555577e-02   3.74352243e-02   1.52291228e-01\n",
      "   -2.47451845e-02   1.62278230e-02  -1.03530480e-01  -2.73831430e-01\n",
      "   -3.21138786e-02  -1.71695372e-01   9.73055159e-02   7.12951837e-02\n",
      "    5.46880897e-02   4.88601151e-02  -1.70156692e-01  -1.08911869e-01\n",
      "    1.86106909e-02   5.72622689e-02   1.00187036e-01   3.44077877e-02\n",
      "   -9.82023488e-02  -2.36724333e-02   5.82691730e-02   6.76285737e-02\n",
      "   -2.99689545e-01   4.09970199e-02  -5.35228988e-01  -2.00433116e-01\n",
      "   -5.06874093e-02  -1.67154028e-01  -5.66364317e-02  -2.00812326e-02\n",
      "   -7.14545337e-02  -4.79601607e-02  -1.02396146e-01   8.21951505e-02\n",
      "   -2.74446212e-01  -2.13410703e-03   1.82330508e-01   5.86951263e-02\n",
      "   -5.64748545e-02   9.08704244e-02   3.40634783e-01  -1.87553158e-02\n",
      "   -5.92640539e-02   4.94967472e-02  -9.88163482e-02   1.35184812e-01\n",
      "   -6.53644790e-02  -1.43774314e-01  -5.84455293e-02  -9.73859031e-02\n",
      "    5.80281804e-02  -4.24855721e-02   1.27716022e-02  -5.35633876e-03\n",
      "    1.52695346e-02  -9.67036686e-02   6.30816058e-02   3.59766059e-03\n",
      "   -1.62987652e-01   1.31913537e-01   2.76986952e-01   9.30958122e-02\n",
      "    5.47106685e-02   1.71867064e-01  -3.41613621e-02  -2.62943437e-02\n",
      "   -1.08727876e-01  -2.08587435e-01   4.74194004e-02   3.54509364e-03\n",
      "    6.28274740e-03  -5.24050826e-02  -9.90157645e-02   1.89209944e-01\n",
      "    9.20180800e-02  -9.72906579e-02  -1.76404221e-01  -7.35611156e-02\n",
      "    4.79970292e-02  -1.69871731e-01  -6.76223987e-02   2.87104641e-01\n",
      "    1.74434705e-01   1.83323545e-01  -4.43691997e-02  -1.80427886e-01\n",
      "   -1.56906617e-01   4.39273631e-02  -4.08697703e-02  -1.07298970e-01\n",
      "   -1.02944120e-01   1.10157164e-01   9.15937467e-02  -1.02093593e-02\n",
      "   -2.04772942e-01   1.09448530e-01  -1.92376357e-01   3.01337221e-02\n",
      "   -2.72700689e-01  -2.13274480e-02   1.82203478e-01   9.96686746e-02\n",
      "   -1.30731976e-02   1.99833664e-02   8.65180168e-02  -3.71138766e-02\n",
      "   -9.63133223e-03  -1.12343443e-01   1.38946648e-01  -3.50022786e-02\n",
      "   -2.62881084e-02   6.49887092e-02  -7.89504155e-02  -1.40273583e-01\n",
      "    2.13303620e-01  -5.20562325e-02  -2.25934714e-02  -6.65036598e-02\n",
      "    1.31764842e-01  -4.02882895e-02   4.30396146e-03   1.80549255e-02\n",
      "    8.54088112e-03  -2.08819276e-02  -1.82288132e-02   4.41999508e-02\n",
      "   -1.01247645e-01  -6.31867495e-03  -1.34150286e-02  -8.08474156e-03\n",
      "    6.17573385e-02   6.21907376e-02  -1.04776156e-01  -1.39558353e-01\n",
      "    1.35098908e-01   9.37399281e-02  -8.70321421e-02  -3.61875619e-02\n",
      "    9.73020351e-03]\n",
      " [  3.44758950e-03  -1.26979836e-01   2.08789806e-02   1.71696807e-01\n",
      "    1.45320752e-01   8.34462114e-02  -1.61923212e-01  -1.67461871e-02\n",
      "    5.82543699e-02   7.34232490e-02   7.96581397e-02   1.22839489e-01\n",
      "    1.57639270e-01  -1.15377810e-02   1.02632397e-01  -4.24142134e-02\n",
      "    1.29945591e-01  -5.49575355e-02  -2.68789546e-02  -1.39166606e-01\n",
      "   -4.25112596e-02  -1.02227070e-02   9.93208808e-02   2.93776203e-02\n",
      "    8.96124536e-02   5.75504076e-02  -6.93542718e-02  -1.20754994e-01\n",
      "    8.59834730e-02  -2.60991071e-01  -1.33123746e-01  -1.76353727e-02\n",
      "   -5.99072516e-04   2.49737273e-01  -2.42145050e-02  -1.36686459e-01\n",
      "   -3.29117268e-02  -2.99651402e-01   9.66967020e-02   1.26809409e-01\n",
      "    1.84494071e-01   1.33554825e-01   2.70429543e-02  -4.54519126e-03\n",
      "   -2.00475113e-01   5.52454492e-02   3.42586762e-01   1.97895957e-01\n",
      "   -6.72081112e-02  -8.95928455e-02   2.57596429e-02  -2.05204879e-01\n",
      "    7.49624925e-02  -1.61693110e-01  -1.35251953e-02  -2.95955056e-01\n",
      "    1.96928302e-01  -1.75710921e-01  -3.07481000e-01  -8.13313378e-02\n",
      "    3.92534008e-02   2.56669901e-02  -1.36335781e-01  -2.22868209e-01\n",
      "   -4.25632920e-02   1.64989101e-01   7.20827462e-02  -4.86338062e-02\n",
      "    1.09267775e-01   8.79892836e-02  -3.73963594e-03  -2.71295201e-01\n",
      "    7.65305965e-02  -9.61485918e-02  -4.89597753e-02  -2.15883611e-01\n",
      "    2.13135222e-01  -6.49325294e-02  -1.70690159e-01  -1.43170930e-01\n",
      "    1.15064985e-01  -6.32480006e-02   1.80450861e-01   1.77680378e-01\n",
      "   -7.05103446e-02   9.59055917e-03   1.36839265e-01   1.59858752e-01\n",
      "    3.48019958e-02   2.90474342e-02  -2.78853058e-03   6.38207610e-02\n",
      "   -1.20928211e-01   2.24603868e-02  -2.63934099e-01   3.49352829e-01\n",
      "   -5.21504232e-02  -5.62704900e-02   1.95898063e-04  -1.64615256e-01\n",
      "   -3.86699173e-02   2.01418404e-01  -7.81586394e-02   5.00187500e-02\n",
      "    1.24972548e-01   2.40167318e-01   1.97585626e-02  -7.51856632e-02\n",
      "   -1.26498089e-01   9.29681296e-02  -2.36778651e-01   7.90249813e-03\n",
      "   -2.08914346e-01  -9.59453719e-02  -1.54762491e-01   3.78788805e-02\n",
      "   -5.12777694e-02  -3.12402708e-01  -9.77230196e-03   1.86964254e-02\n",
      "   -1.40835195e-01   1.34796519e-01   1.39250154e-01  -9.63541216e-03\n",
      "    1.14621129e-01  -1.00255845e-01   3.42719657e-02  -9.12622121e-02\n",
      "   -5.15422495e-03   7.54978326e-02  -9.04245048e-02   5.64824300e-02\n",
      "    6.92361237e-02   1.24759222e-02   4.56838452e-02  -2.75239694e-02\n",
      "    1.86387446e-02  -8.62624605e-03  -2.78068576e-02   4.25739413e-02\n",
      "   -1.16888934e-02   3.28722556e-03  -3.39157175e-02  -6.97604077e-02\n",
      "    3.62588831e-03   8.27856970e-02   2.37571864e-01  -1.57835558e-02\n",
      "   -2.12458713e-01  -7.61330798e-02  -3.37716314e-02   1.40196582e-01\n",
      "   -2.66918377e-02  -3.08171915e-02   6.60269826e-02  -2.29618658e-02\n",
      "   -8.64789216e-03  -1.87035579e-02   3.56969434e-02   2.54834110e-02\n",
      "   -1.22007929e-02  -2.80188240e-02  -2.21234719e-02  -1.05995851e-02\n",
      "    4.56813140e-03  -1.06125653e-02   7.53564205e-02   5.21221226e-02\n",
      "   -7.26430985e-02  -2.18819632e-03   1.64475612e-02   4.01459848e-02\n",
      "   -4.50146948e-02]\n",
      " [ -7.72790960e-03   7.32002532e-02  -1.13877285e-01  -5.74085266e-02\n",
      "   -6.24450407e-03  -7.16590761e-02   2.40436639e-03   3.82396377e-02\n",
      "    2.92962476e-03   3.13774018e-02  -1.56144071e-01   2.39915533e-03\n",
      "   -1.11034912e-01  -2.47763459e-02  -1.45206263e-02   1.17018639e-01\n",
      "    2.84800370e-01   9.75631270e-02   6.46470195e-02   2.43475948e-02\n",
      "    1.30720845e-01  -1.36109348e-01  -8.10356121e-02  -8.59388231e-02\n",
      "    2.46492338e-02   4.15797060e-02   8.15316699e-02   2.64715903e-03\n",
      "   -3.67972171e-02   1.21355824e-01   8.61278532e-02   1.69564412e-01\n",
      "   -1.03485490e-01  -3.02117775e-01   1.37746373e-01  -3.46691767e-02\n",
      "    1.08865845e-01  -3.40914318e-02  -3.58239953e-02   6.11165448e-02\n",
      "    1.28203462e-01  -7.42845787e-02  -2.09384609e-01   7.06634954e-02\n",
      "    6.32386316e-02   9.24748667e-02  -6.59017891e-02  -3.24220696e-02\n",
      "    9.98070246e-02  -2.75636664e-02  -1.32793946e-01   6.92768446e-02\n",
      "   -1.44185577e-01   2.84811509e-03  -1.08486456e-01   8.41313008e-02\n",
      "    2.61960171e-02   7.78371010e-02   5.04374436e-01  -1.50283406e-01\n",
      "    9.38974065e-02  -1.54887750e-01   8.55488807e-02  -6.22542073e-02\n",
      "    8.04790569e-02  -1.73564194e-01  -2.12511666e-01   5.35868813e-03\n",
      "    4.36944139e-02   1.88879478e-01  -3.73075824e-02  -7.19896799e-03\n",
      "   -1.61341420e-01   6.17897194e-02   1.22208107e-01   8.35444795e-02\n",
      "   -2.37354815e-02   2.63974826e-02   2.65696451e-02  -2.01678152e-01\n",
      "   -1.06030475e-01  -1.73797555e-01  -1.11042921e-01  -2.24589245e-02\n",
      "    8.83896904e-02  -1.08807858e-01   4.78980144e-02  -8.52075712e-02\n",
      "    3.80263036e-02   7.73261239e-02  -9.10259505e-02  -2.25232379e-01\n",
      "   -9.47702695e-02   2.28706995e-02  -8.87292960e-02   5.19523707e-02\n",
      "    8.06780378e-02  -1.39430401e-01  -1.52939066e-02   3.68360029e-02\n",
      "    1.16429188e-01   9.59860646e-02   1.39835602e-01  -1.12014659e-02\n",
      "    1.29926389e-01  -8.70390908e-02   6.69125223e-02  -1.30231019e-01\n",
      "    7.38502451e-02  -5.93071502e-02   4.11798298e-02   3.09063217e-01\n",
      "    1.08135411e-01   1.82041730e-01  -2.16519597e-02  -3.27855521e-01\n",
      "    1.53863761e-01  -1.97878503e-01  -2.16025374e-01   1.18641144e-02\n",
      "    1.47419082e-02  -1.70724493e-01  -1.18603836e-01   6.55063327e-02\n",
      "   -8.85477756e-02   3.90361785e-02  -8.21617237e-02  -8.15583122e-02\n",
      "    1.39224529e-01   3.42507480e-01   1.56082129e-01  -4.79766380e-02\n",
      "    6.60557970e-02   9.50448929e-02  -2.25632177e-01   2.54836037e-02\n",
      "   -8.66835038e-03   1.91990621e-03  -8.91854318e-02   5.29168061e-02\n",
      "    6.87339918e-02   3.37902135e-03  -1.03179250e-01   9.03913803e-02\n",
      "    3.73658938e-02  -1.17525150e-01  -3.63491114e-04  -4.39728000e-02\n",
      "    1.18839836e-02  -4.13321206e-02  -2.59329910e-02   3.03527266e-02\n",
      "    2.83587874e-02   2.41028010e-02   4.19688091e-02  -8.38999531e-02\n",
      "    9.27474538e-03  -4.82511131e-02   5.04803220e-02  -1.75301564e-02\n",
      "    1.65334725e-02  -1.14334997e-02   3.85966235e-03   1.34562161e-02\n",
      "   -9.48852317e-05  -5.88146947e-02   4.92781058e-02   3.21725516e-02\n",
      "   -3.54643858e-02  -2.38788324e-02   2.21416525e-02  -5.60305763e-02\n",
      "    5.36217878e-02]\n",
      " [ -1.27892027e-02  -7.66075954e-03   1.76344175e-01  -4.59321624e-02\n",
      "   -1.04113443e-01   6.09405083e-02   7.04361310e-02   1.39879725e-01\n",
      "    2.70483148e-02  -7.13972685e-02   7.36981918e-02   6.69621338e-02\n",
      "   -1.81766146e-01  -6.70184348e-02  -9.13810290e-02  -1.73735184e-02\n",
      "   -2.92300142e-01  -3.08935232e-02  -5.46868212e-02   1.15007896e-02\n",
      "    5.76278110e-02  -9.22801811e-02  -5.17050882e-02  -3.21032009e-02\n",
      "    9.00427477e-02  -3.81922097e-02  -6.09353838e-02  -5.37717291e-02\n",
      "   -7.88271834e-02  -1.86552605e-01  -5.13055208e-02   1.28969065e-02\n",
      "    9.76833404e-02  -1.37369064e-01  -1.03214426e-01   6.98450666e-02\n",
      "   -1.11057498e-02   1.67066102e-01   1.69014883e-01   1.41198460e-02\n",
      "   -1.00869048e-01   7.41368664e-02   1.06555461e-01  -1.89345815e-01\n",
      "    1.35303997e-01  -2.38651975e-01  -1.93640797e-01  -1.25475890e-01\n",
      "   -8.94044489e-02   1.24179424e-01  -1.32300482e-01   7.25063272e-02\n",
      "    1.35002588e-01   1.33764675e-01   5.00140292e-02   2.01425412e-02\n",
      "   -1.58046399e-01   1.75327908e-01   1.08605564e+00   3.76256602e-01\n",
      "   -8.05443982e-02  -2.52166881e-02  -6.65347382e-02   2.79133504e-01\n",
      "   -1.66972361e-01   7.54384983e-02   1.33921482e-01  -1.04030494e-01\n",
      "    2.90498160e-02  -1.67639250e-01  -3.07425688e-01   1.79937609e-01\n",
      "    2.04279269e-01  -1.43641135e-01  -1.50992706e-01   2.46134220e-01\n",
      "   -1.15090884e-01   8.11923953e-03   9.31163407e-02   2.24861309e-01\n",
      "   -7.57943082e-02   1.86409863e-01  -1.47501561e-01   2.09135381e-01\n",
      "   -8.68555495e-02   8.68998305e-02  -1.18791782e-01  -1.22727459e-01\n",
      "   -1.21013157e-01   2.99145076e-02   1.57823742e-02  -8.47897154e-02\n",
      "    2.55554094e-01  -1.06638186e-01   1.28052447e-01  -1.64273168e-01\n",
      "   -5.77013551e-03  -6.99327472e-02  -6.00728129e-02  -1.63953831e-01\n",
      "   -1.14757327e-01  -1.48052959e-01  -3.95931506e-03  -4.38289892e-02\n",
      "   -1.95577038e-01  -2.22626294e-01  -1.73168707e-01  -1.03261068e-02\n",
      "   -1.32586347e-01   1.42919851e-01   1.99219848e-01  -1.53254660e-01\n",
      "   -2.41460077e-02  -9.62917604e-02   6.27824037e-02   7.19525516e-02\n",
      "   -1.02305849e-02   4.77250263e-01   7.42991904e-03  -2.10552580e-02\n",
      "    4.50880291e-02  -8.98812595e-02  -2.88794441e-01  -6.23574543e-02\n",
      "   -1.38289273e-01  -1.10881322e-02   1.46995867e-01   7.84212110e-02\n",
      "    2.39677067e-01  -2.93080786e-01   5.87018323e-01   3.81448218e-02\n",
      "    5.74670715e-01  -3.56337842e-02  -2.93131957e-02  -7.05606427e-02\n",
      "   -1.27845255e-02  -3.28361705e-02  -5.21671765e-02  -9.63337775e-02\n",
      "    1.88029268e-02   5.17242394e-02   8.24590090e-03  -5.35981360e-02\n",
      "    2.80292611e-02  -2.52675742e-03  -7.88291484e-02   6.63488914e-02\n",
      "    1.27651943e-02   1.36658953e-01   4.69957549e-02  -3.94773546e-02\n",
      "   -1.58631952e-01   4.86574006e-02  -1.14169841e-01   5.34078405e-02\n",
      "   -2.34999892e-03  -5.25280787e-02   3.48826964e-02  -1.40495663e-02\n",
      "    3.79228544e-03  -1.87708500e-02  -2.26256011e-03   1.05652938e-02\n",
      "    3.17249514e-03   2.97343459e-02  -4.75036014e-02  -7.69780278e-02\n",
      "    6.73103218e-02  -4.21513486e-02   2.25794321e-02  -3.35922153e-02\n",
      "    2.98464710e-02]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:9: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 1  ====\n",
      "For  BFGSBinaryLogisticRegression  eta:  0.1 Iterations:  10 Regularization:  L1  : Accuracy of:  0.386138613861\n",
      "confusion matrix\n",
      " [[ 9 10  4  0  0]\n",
      " [ 5 11  6  5  1]\n",
      " [ 5  8 15 12  7]\n",
      " [ 2  2 15 13 15]\n",
      " [ 2  3  8 14 30]]\n",
      "MultiClass Logistic Regression Object with coefficients:\n",
      "[[  5.26006467e-03  -1.04599050e-01  -1.16396919e-01   9.46162092e-02\n",
      "   -1.40479960e-01  -5.27473085e-02  -1.85297257e-02  -1.73491198e-01\n",
      "   -1.48812495e-01  -6.83315462e-02  -6.36048657e-03  -2.09725107e-01\n",
      "   -3.06856470e-02   2.31110802e-01   2.27368789e-01   2.66007152e-02\n",
      "    3.78608645e-02  -1.53234775e-01   7.21581058e-02  -2.93238446e-02\n",
      "   -3.10750528e-01   1.02424389e-01  -5.57609251e-02   3.21398753e-01\n",
      "   -1.61343006e-01  -1.22327118e-01   7.93601243e-02   1.61957392e-01\n",
      "   -1.16285447e-01   1.58817482e-01   3.87399235e-02  -2.20292884e-01\n",
      "    2.68546822e-02   1.81758546e-01  -4.90056793e-02   7.76255769e-02\n",
      "   -4.12176131e-02   5.43634930e-02  -1.70415628e-01  -6.04864460e-02\n",
      "   -1.42475717e-01   2.69555139e-02   6.49383141e-02  -1.96615444e-02\n",
      "   -3.12495987e-01  -1.80120939e-02  -1.37059640e-01   1.82285124e-01\n",
      "   -4.23262637e-02   3.41601341e-02   8.88697277e-02  -8.76649502e-02\n",
      "    2.34817821e-01   1.71644571e-01   2.92569577e-02   1.39997610e-01\n",
      "    2.48056751e-01  -3.41950162e-01  -1.09900989e+00   9.96905489e-02\n",
      "    2.19774226e-01   1.95374037e-01   7.46323693e-02  -5.61799584e-02\n",
      "    3.44117197e-01   5.86848106e-02  -2.12301597e-01   1.16411273e-01\n",
      "   -3.43461131e-02  -2.01446131e-01   4.87092031e-02   1.06021766e-01\n",
      "   -2.16385465e-01  -1.46268657e-02  -1.29357608e-01  -1.09366882e-01\n",
      "   -8.80857933e-02   4.36218543e-02   1.30031307e-01  -9.48000296e-02\n",
      "    1.73203337e-01   2.16667189e-01   2.12772285e-01  -1.83498717e-01\n",
      "    1.20268416e-01   1.10132844e-01  -3.04499848e-01  -4.07151668e-04\n",
      "   -7.50404200e-02   1.52550078e-01   2.28262435e-02   2.64671906e-01\n",
      "    1.57199383e-01  -1.82543693e-01  -1.81748370e-01  -3.29546243e-01\n",
      "   -6.57390062e-02   1.07410992e-01   2.03442550e-01   1.43876051e-02\n",
      "    1.90265651e-01   9.45915043e-02  -2.44977924e-01  -3.38277771e-02\n",
      "   -1.39217315e-01   5.90073912e-02   1.45888932e-01  -2.31836261e-01\n",
      "    2.51480478e-01  -3.82539406e-02   1.23389999e-01  -1.10094481e-02\n",
      "    4.42002084e-02   1.67892236e-01   1.62596332e-01   8.09399346e-02\n",
      "   -1.24211354e-01  -1.71479218e-01   1.87566151e-01   1.78687293e-01\n",
      "    1.86132063e-01   2.40479010e-02   3.80948961e-01   1.52181233e-01\n",
      "    2.22180057e-02  -3.84942103e-02  -4.12592024e-01   3.97496252e-02\n",
      "   -3.38777993e-01  -3.22038120e-01  -3.96151720e-01  -1.37157826e-01\n",
      "   -3.86119273e-01  -2.46152525e-01  -2.15837038e-01  -6.41388217e-02\n",
      "    1.55704409e-02   7.64091592e-03   8.21481382e-02  -2.34609679e-02\n",
      "   -2.85444935e-02  -5.91575845e-02   9.61906012e-02   8.85496524e-02\n",
      "   -5.98155562e-02  -6.41583947e-02  -9.76418225e-02  -2.50610154e-03\n",
      "    1.07129604e-01  -3.09943752e-02   4.53517956e-02  -8.94648203e-02\n",
      "    8.41256646e-02   4.62344350e-02  -5.85392240e-02   3.34146172e-02\n",
      "   -1.57230157e-02   5.96107825e-02  -6.61001508e-02   2.40393377e-02\n",
      "   -2.74826995e-03   1.31492303e-01   1.55685431e-02  -2.24129783e-02\n",
      "   -6.42579395e-02  -2.58496097e-02  -2.91535061e-02   1.56261976e-01\n",
      "   -1.46873219e-01   1.76782243e-04  -2.90629432e-02   1.07546778e-01\n",
      "   -8.81736263e-02]\n",
      " [ -3.70232906e-03   1.09940708e-01  -1.52458003e-01  -1.56964990e-01\n",
      "    3.38953273e-02  -3.21096925e-02   3.34846711e-02  -6.59848710e-02\n",
      "    6.89530561e-02   1.27058363e-01  -7.58411239e-02   1.18779840e-02\n",
      "    1.67234829e-01  -2.99887886e-02  -1.38634828e-01   1.69150891e-04\n",
      "   -1.16468795e-01   1.56010201e-01  -2.06860190e-01   2.12815646e-01\n",
      "    1.64423734e-01   9.50522973e-02   4.73323830e-02  -2.00264034e-01\n",
      "    2.16442212e-02  -5.23427783e-02   1.73093986e-02   1.54552175e-02\n",
      "   -8.03413842e-02   2.90236333e-01   1.86473417e-01  -1.31078493e-03\n",
      "   -1.64075964e-02  -4.41445566e-02   7.37650779e-02   1.74192603e-01\n",
      "   -3.25983900e-02   1.67964459e-01   2.19945983e-03  -2.44600328e-01\n",
      "   -7.44499703e-02  -9.48792730e-02   4.91981453e-02  -4.50757559e-02\n",
      "    4.00719298e-02   1.12045884e-01  -1.68202789e-01  -2.09738634e-01\n",
      "    2.77566991e-02   1.04197896e-01  -1.79582521e-02   2.22174532e-02\n",
      "   -1.43334301e-01   5.19025746e-03  -9.54586798e-02   8.05778198e-02\n",
      "   -2.77994973e-01  -3.05031436e-02  -6.07203933e-01  -1.07318584e-01\n",
      "    6.29740161e-02   3.35385821e-02  -3.14959068e-02   3.01637054e-02\n",
      "    5.49033696e-02  -1.91415937e-02  -4.32845898e-02   3.97003555e-02\n",
      "   -2.69514395e-01   9.70139054e-02   6.53533415e-02   1.03000383e-01\n",
      "   -9.82130513e-02   2.21957216e-01   1.64192960e-01   1.15381625e-01\n",
      "   -3.49097590e-02  -8.09482413e-02  -5.56007437e-02   1.37783640e-01\n",
      "   -5.22289057e-02  -1.06454712e-01  -4.81199608e-02  -1.95761193e-01\n",
      "    4.58874422e-02  -8.55619568e-02   1.84258130e-02   3.99857710e-02\n",
      "   -1.44913739e-02  -2.08371343e-02  -1.94549356e-03  -1.64512933e-02\n",
      "   -2.21406370e-01   1.57031043e-01   1.57388991e-01  -7.42712394e-02\n",
      "   -3.32582142e-02   2.57131390e-01  -4.68326795e-02   9.82572253e-02\n",
      "   -7.23569987e-02  -1.04534869e-01   9.08579163e-03   4.44360210e-02\n",
      "   -3.00282984e-02  -7.63821513e-03  -9.70088132e-02   1.90251239e-01\n",
      "   -4.30492541e-03   2.86308523e-02  -1.71312690e-01  -8.53947441e-02\n",
      "   -1.17841911e-01  -9.60368129e-02  -1.11300452e-01   2.57297920e-01\n",
      "    9.83517008e-02   1.51240205e-01  -2.67097436e-02  -2.23980864e-01\n",
      "   -1.56488611e-01   1.08736749e-01  -8.86038223e-02  -1.48614528e-01\n",
      "   -1.24419071e-02   7.82701715e-02   4.80714328e-02   5.96439593e-02\n",
      "   -1.87971412e-01   1.23566510e-01  -2.22299922e-01  -5.45661554e-03\n",
      "   -2.87660944e-01   3.22711459e-02   1.31929308e-01   6.47620527e-02\n",
      "   -4.01311074e-03   2.85226599e-03   5.10416376e-02  -7.10357979e-02\n",
      "    7.40917565e-03  -2.48484079e-02   6.86808614e-02  -5.71014092e-02\n",
      "   -5.47220589e-03   6.96129922e-02   4.05678898e-02  -1.75818388e-01\n",
      "    1.34211286e-01  -9.11091753e-03  -5.30304557e-02  -2.57829237e-02\n",
      "    8.92517827e-02  -3.22787753e-02  -1.18123339e-02   3.60559457e-02\n",
      "    3.62278765e-03  -5.44081590e-03  -2.04186677e-02  -1.38338689e-02\n",
      "   -3.37139542e-02  -1.29304246e-02  -1.04386727e-02  -4.86026800e-03\n",
      "    5.81258863e-02  -4.08553325e-03  -3.02233636e-02  -1.38971513e-01\n",
      "    1.38920091e-01   8.44319633e-02  -7.32334465e-02   5.12841665e-03\n",
      "   -1.91282116e-02]\n",
      " [  5.20391213e-03  -1.56458565e-01  -5.37478619e-02   5.48436985e-02\n",
      "    7.43537074e-02   2.18065194e-03  -1.45859565e-01  -6.14474974e-02\n",
      "    9.90840368e-02   6.95266875e-02   1.41996060e-01   2.47043567e-02\n",
      "    9.75153190e-02  -9.79145101e-03   7.80324037e-02  -5.99020508e-02\n",
      "    1.83464385e-01  -3.16390946e-02  -2.14230470e-02  -1.57461416e-02\n",
      "   -1.52791517e-01  -4.03656223e-02   1.17483159e-01  -9.95701309e-02\n",
      "    4.29543116e-02   4.64587643e-02  -2.59873678e-02  -8.02219589e-02\n",
      "    6.92120814e-02  -3.15680627e-01  -9.20827573e-02   1.58347403e-01\n",
      "    1.25037232e-02   3.07207649e-01  -7.75042422e-02  -7.99139316e-02\n",
      "   -1.20292105e-02  -3.39088842e-01   4.60564222e-02   2.08422957e-01\n",
      "    1.27009152e-01   1.52799872e-01   6.64953068e-02  -1.89971282e-01\n",
      "   -1.75279793e-01   5.57588532e-03   3.15110894e-01   2.18797144e-01\n",
      "    7.96718279e-04  -1.14681236e-01   8.62234823e-02  -6.04062789e-02\n",
      "   -3.70501142e-02  -2.94112211e-01   6.94711158e-02  -3.11634302e-01\n",
      "    1.80476232e-01  -9.39022464e-02  -1.78741624e-01  -9.96122961e-02\n",
      "   -1.48198538e-02  -1.27650907e-02   5.17874988e-02  -1.37251472e-01\n",
      "   -1.73888937e-01   2.35899127e-01   1.98287173e-01   4.70957816e-02\n",
      "    2.52875376e-02   9.22544630e-02  -7.66289338e-02  -2.08133031e-01\n",
      "    5.21087461e-02  -1.28015812e-01  -1.86041207e-02  -3.65751274e-01\n",
      "    2.47044580e-01   1.87160987e-04  -2.50990534e-01   2.39295766e-02\n",
      "    9.31340414e-02  -3.49538724e-02   4.33655744e-02   2.13697789e-01\n",
      "   -1.16700302e-01  -1.21551983e-02   2.38568956e-01   1.24361114e-01\n",
      "    1.59876611e-01   1.22053294e-02   8.15285892e-02  -3.94674661e-02\n",
      "   -1.46031169e-01  -2.78941574e-02  -3.13803631e-01   3.49419404e-01\n",
      "   -4.06368975e-02  -2.12572761e-01   2.19547804e-02  -1.27184813e-01\n",
      "    1.07972793e-02   1.29344024e-01   7.19288638e-02  -3.09839712e-02\n",
      "    1.45850090e-01   9.19032221e-02  -6.41116644e-02  -5.15116915e-02\n",
      "   -2.10145314e-01  -4.28409164e-02  -1.98826832e-01   6.69123431e-04\n",
      "   -1.32780993e-01  -1.64040998e-01  -1.71645261e-01  -2.82052879e-02\n",
      "   -4.61024449e-03  -1.95667041e-01   3.58698562e-02   1.25792020e-02\n",
      "   -1.58144551e-01   6.69527154e-02   2.05620948e-01  -4.81296979e-02\n",
      "    7.08643650e-02  -4.91778911e-02   1.58802100e-01  -1.03068226e-01\n",
      "   -4.74331327e-02   1.14002594e-01  -1.48679012e-01   1.10538417e-02\n",
      "    3.75335589e-02   1.22174147e-02  -2.67604734e-02  -3.16439869e-02\n",
      "    3.32916145e-02  -1.10784124e-02   1.10211681e-03   6.75231234e-02\n",
      "   -3.01482945e-02  -1.36531645e-02  -8.55046348e-03  -6.44597797e-02\n",
      "    1.29580345e-02   7.23226337e-02   1.40015202e-01   8.16100955e-02\n",
      "   -2.10998145e-01  -1.04523359e-01  -4.40075885e-02   1.10938055e-01\n",
      "    3.09288798e-02  -3.25413468e-02   5.94806808e-02  -2.36970418e-02\n",
      "    2.38253613e-03   8.99553720e-04   2.57743498e-02   1.23264916e-02\n",
      "    4.29700963e-03  -7.19256823e-02  -1.51336777e-02  -1.10308633e-02\n",
      "   -7.76417242e-03  -1.29674323e-02   1.24446656e-01   4.76885277e-02\n",
      "   -6.63701020e-02   7.44765289e-03   9.39804690e-03   4.83702741e-02\n",
      "   -6.33686713e-02]\n",
      " [ -8.29826987e-03   4.67491182e-02  -9.97884278e-02  -8.66945529e-02\n",
      "    5.13784439e-02  -4.66854007e-02  -3.71868416e-02   1.34159981e-01\n",
      "   -3.09021081e-02  -6.40282033e-02  -1.97787957e-01   3.72787563e-02\n",
      "   -5.57145743e-02  -3.98450765e-02  -1.84299726e-02   1.16885193e-01\n",
      "    2.84128883e-01   1.76830093e-01   9.12404752e-02   8.40338011e-03\n",
      "    1.00149522e-01  -1.70355989e-01  -6.67000481e-02  -1.02779916e-01\n",
      "   -4.61279964e-02   8.67908743e-02   7.64768613e-03  -1.11229892e-01\n",
      "    1.06226321e-01   2.29000857e-02   8.84429229e-02   1.13081118e-01\n",
      "   -1.23973999e-01  -2.33150674e-01   8.78905830e-02   3.34022996e-02\n",
      "    1.63543109e-01   4.00726132e-02  -1.60958434e-01   7.02851608e-02\n",
      "    5.26420637e-02  -1.38279941e-01  -2.23613359e-01   1.36722592e-01\n",
      "    9.38465558e-02   1.53515196e-01  -2.63775258e-02  -5.40578819e-02\n",
      "    7.32844006e-02  -1.17806239e-01  -9.70645753e-02  -5.08360731e-02\n",
      "   -9.03846410e-02   1.94787186e-03  -8.50869951e-03   1.66622242e-01\n",
      "    3.44046935e-02  -2.66735067e-02   5.68197057e-01  -1.15719678e-01\n",
      "   -4.65064204e-02  -2.08145673e-01   7.15940317e-02   4.93745998e-02\n",
      "    9.31624649e-02  -2.43575396e-01  -1.11922717e-01  -4.44941285e-02\n",
      "    1.95054032e-02   2.28826860e-01  -1.64129942e-03   1.50385627e-02\n",
      "    2.78754115e-02   6.48519629e-02  -8.18824002e-03   7.99503753e-02\n",
      "   -4.55850060e-02   2.28126178e-02   1.26749745e-01  -1.10560747e-01\n",
      "   -1.01117478e-01  -1.05343002e-01  -5.59068728e-02  -5.46228433e-02\n",
      "    1.49805363e-01  -5.45631193e-02   3.30867225e-02  -8.69859051e-03\n",
      "   -7.77310704e-02   1.31178964e-02   3.27143229e-02  -1.48243281e-01\n",
      "   -5.36302398e-02   8.13314750e-02  -1.50486710e-03   2.21551301e-02\n",
      "    5.64523170e-02  -7.03502365e-02   6.03048571e-02   6.37596699e-02\n",
      "    4.05072113e-02   1.70734382e-02   8.11755112e-02   1.94107965e-02\n",
      "    9.11639047e-02  -2.41857764e-02   1.65451125e-01  -1.53867328e-01\n",
      "    1.07024809e-01  -3.19875954e-02  -2.09053931e-02   1.52986623e-01\n",
      "    3.39728807e-02   1.82786812e-01  -4.08620322e-04  -3.82463642e-01\n",
      "    1.25550520e-01  -1.52945820e-01  -1.64351454e-01   1.14485737e-02\n",
      "   -5.27660886e-03  -2.13607435e-01  -3.40258916e-02   2.77695289e-02\n",
      "   -1.66545094e-01  -1.30287940e-01  -3.60027718e-02  -4.56453421e-02\n",
      "    2.06437649e-01   3.15053337e-01   1.33692552e-01   7.90656916e-02\n",
      "    1.18283212e-02  -1.94067615e-02  -1.76034260e-01   1.53888613e-02\n",
      "   -1.02344267e-02  -2.37769082e-03  -1.11256401e-01   7.10591925e-02\n",
      "    4.47769398e-02  -4.11067152e-03  -1.03504052e-01   8.78574482e-02\n",
      "   -2.62986142e-02  -7.32314404e-02  -9.00956615e-03  -4.78582603e-02\n",
      "    2.58206882e-02  -1.07875803e-02   2.76173883e-02   2.23511453e-02\n",
      "   -4.56993106e-02  -2.42454196e-02   6.38879453e-02  -5.69465799e-02\n",
      "    8.05204164e-03  -5.01797943e-02   4.25810593e-02  -7.52303573e-03\n",
      "    4.97106272e-03   6.35814922e-02  -1.62561081e-02   1.54050354e-02\n",
      "    6.20942279e-03  -4.32493917e-02  -3.49424630e-02  -2.51945194e-02\n",
      "    2.32045551e-02  -4.10389111e-02   3.97196748e-02  -9.35871061e-02\n",
      "    9.47034458e-02]\n",
      " [ -1.55056730e-02   6.43738491e-02   2.93786242e-01   9.19002928e-02\n",
      "   -5.24276610e-02   1.35990968e-01   1.56822187e-01   1.55741093e-01\n",
      "    8.41508163e-02  -3.89730665e-02  -2.72365264e-02   1.28019901e-01\n",
      "   -2.34697838e-01  -2.39191674e-02  -4.61055491e-02  -1.05511205e-02\n",
      "   -4.41443845e-01  -2.00942891e-01  -1.07306263e-02  -8.93856370e-02\n",
      "    1.55546886e-01  -9.24499823e-02  -5.42434930e-02   1.00691589e-01\n",
      "    1.70672259e-01  -3.15862792e-02  -4.47366652e-02   7.21237853e-03\n",
      "   -5.24603547e-02  -8.41818185e-02  -1.39963895e-01   4.21575294e-02\n",
      "    9.42205870e-02  -2.24755137e-01  -2.68817022e-02  -1.15969823e-01\n",
      "   -1.35489202e-01   9.86253129e-02   3.30101697e-01  -6.89988767e-02\n",
      "    1.28079790e-02   9.13184412e-02   1.12632252e-01   4.00196861e-02\n",
      "    1.96363424e-01  -3.01413019e-01  -1.86933731e-01  -1.53356741e-01\n",
      "   -1.05374801e-01   2.15435191e-01  -1.75069036e-01   4.09149965e-02\n",
      "    1.80128748e-01   2.21744692e-01   1.22742491e-03  -5.73745945e-02\n",
      "   -6.01726128e-02   2.25211251e-01   1.04710578e+00   3.32156036e-01\n",
      "   -9.06546009e-02  -6.55043044e-02  -2.52559747e-01   9.72653693e-02\n",
      "   -1.55669135e-01   3.59761527e-02  -1.06342844e-02  -1.51885652e-01\n",
      "    1.48984331e-01  -3.06912683e-01  -3.02427696e-01   1.23767314e-01\n",
      "    1.09058640e-01  -1.65708439e-01   5.31498038e-02   2.85330864e-01\n",
      "   -1.25594290e-01   5.21968944e-02   3.55297665e-02   5.15802895e-02\n",
      "   -4.40419823e-02   8.35927931e-02  -1.51687879e-01   4.03846953e-02\n",
      "   -2.35397420e-01   1.55104297e-02  -5.01940419e-02  -2.17533804e-01\n",
      "    5.13070422e-02   9.36961295e-02  -1.14100433e-01  -7.77702463e-02\n",
      "    2.91120646e-01  -9.36252707e-02   2.90077711e-01  -1.68877122e-02\n",
      "    3.37881227e-02  -6.69984178e-02  -1.09851597e-01  -1.26991282e-01\n",
      "   -5.48954713e-02  -1.83164021e-01  -5.82920299e-02  -1.04422929e-01\n",
      "   -2.86327647e-01  -1.70783586e-01  -1.77566582e-01   9.61674067e-02\n",
      "   -8.18465726e-02   1.53271838e-01   2.49374970e-01  -7.14590218e-02\n",
      "   -4.52523182e-02  -2.99606680e-02   7.75140160e-02   1.53154020e-01\n",
      "   -5.86638414e-02   2.83903400e-01  -3.90936861e-02  -3.89822984e-02\n",
      "    8.69865352e-02  -7.49601986e-02  -3.26915751e-01  -3.00537375e-02\n",
      "   -2.99588495e-02  -6.71471810e-03   7.81286194e-02   6.08755573e-02\n",
      "    2.24451930e-01  -3.25912246e-01   6.99742296e-01  -5.19375365e-02\n",
      "    5.27341083e-01   9.20570761e-02  -7.70836172e-03  -2.79384236e-02\n",
      "   -2.26195338e-02  -3.46584707e-02  -3.76595634e-02  -1.44745817e-01\n",
      "    6.00608121e-02   4.28183984e-02   3.02586895e-02  -4.19922282e-02\n",
      "    2.22931111e-02   9.22098017e-03  -4.92220508e-02   2.33139650e-02\n",
      "    2.77517976e-02   1.60521832e-01   2.40181056e-02  -5.33265436e-02\n",
      "   -1.48583444e-01   2.47275968e-02  -7.47867422e-02   3.54078852e-02\n",
      "   -3.46049117e-03  -5.79947813e-02   3.66011765e-02   7.15607868e-03\n",
      "   -1.97588046e-02  -7.09246626e-02   2.70484368e-02   1.03055128e-02\n",
      "   -3.06868993e-03   4.23281266e-02  -2.38004750e-02  -1.43091172e-02\n",
      "    6.77998126e-05  -7.81929689e-02   5.45684479e-02  -4.31484781e-02\n",
      "    3.64406169e-02]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:9: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 2  ====\n",
      "For  BFGSBinaryLogisticRegression  eta:  0.1 Iterations:  10 Regularization:  L1  : Accuracy of:  0.376237623762\n",
      "confusion matrix\n",
      " [[ 9  5  6  4  1]\n",
      " [ 8  9 18 12  1]\n",
      " [ 6  7 18 13  3]\n",
      " [ 2  2  8 17 12]\n",
      " [ 2  3  6  7 23]]\n",
      "MultiClass Logistic Regression Object with coefficients:\n",
      "[[  9.19621810e-04  -3.48546320e-02  -6.53656653e-02  -1.06368746e-02\n",
      "   -1.06711644e-01   1.82474019e-02  -2.41099693e-02  -1.54229981e-01\n",
      "   -2.22508469e-01  -1.73582011e-01  -8.38519730e-02  -7.15660701e-02\n",
      "   -5.23703711e-03   2.16104238e-01   1.90356124e-01   1.30775510e-01\n",
      "    5.06663441e-02  -1.27071101e-01   1.46680790e-02   1.35569832e-02\n",
      "   -2.20935566e-01   4.53767837e-02  -8.84123862e-02   1.86846925e-01\n",
      "   -1.72299255e-01  -1.30526513e-01   2.75241452e-03  -1.26343618e-02\n",
      "   -1.57704329e-01   9.33896306e-02   2.33194370e-02  -1.83660799e-01\n",
      "   -2.16139995e-02   4.81943260e-02  -4.63879231e-02   1.67981263e-01\n",
      "   -8.71348619e-02   4.31308673e-02  -1.38776219e-01  -2.79095965e-02\n",
      "   -1.11524337e-01  -9.55588620e-02   4.20510704e-02  -3.95094883e-02\n",
      "   -1.60706675e-01  -5.43636177e-02  -1.80764518e-01   1.05983470e-01\n",
      "    5.48272393e-03  -1.41716931e-02   2.22643067e-01  -5.25469088e-02\n",
      "    2.06518745e-01   1.51270765e-01   1.77874508e-01   7.12913384e-02\n",
      "    1.94287007e-01  -3.79606388e-01  -8.46484229e-01   2.46442257e-02\n",
      "    1.78227477e-02   1.38244962e-01   7.10060719e-02  -2.90313414e-02\n",
      "    3.08164478e-01   6.11002091e-02  -8.31241059e-03   1.79459722e-02\n",
      "   -1.48861384e-01  -4.57492772e-02  -4.33373188e-02   5.14667655e-02\n",
      "   -1.46995758e-01  -1.31277375e-02  -2.72276450e-02   9.08177889e-03\n",
      "   -1.55625971e-02  -2.99833830e-02   1.70882467e-01  -4.05935868e-02\n",
      "    1.34431165e-01   1.94267724e-01   1.09459915e-01  -1.93785728e-01\n",
      "    1.41478060e-01   1.38894161e-01  -1.94917266e-01   8.15312152e-02\n",
      "   -3.97975590e-02   8.03208471e-02   1.59414000e-01   2.24586110e-01\n",
      "    1.60188012e-01  -6.76663800e-02  -1.10463831e-01  -2.89707495e-01\n",
      "   -8.93064851e-02   7.66987328e-02   1.25511668e-01   5.96626974e-02\n",
      "    2.63650812e-01   3.70180418e-02  -2.30204076e-01  -9.69740390e-02\n",
      "   -1.63323672e-01   4.35038963e-02  -2.95495762e-02  -1.36986240e-01\n",
      "    1.18818550e-01  -1.23861850e-01   7.48353955e-02  -1.75020212e-01\n",
      "    3.35228865e-02   9.57294995e-02   4.91006718e-02   1.43578573e-01\n",
      "   -2.23918556e-01  -1.14715066e-01   1.33748762e-01   1.16111505e-02\n",
      "    1.51527704e-01  -1.49125115e-02   2.82774726e-01  -1.52799186e-02\n",
      "    3.54818085e-02  -7.81638602e-02  -2.49021971e-01   4.57560773e-02\n",
      "   -2.99328880e-01  -1.95809380e-01  -4.59468297e-01  -1.17551102e-01\n",
      "   -4.40157120e-01  -1.42723421e-01  -2.36237418e-01   3.70968779e-02\n",
      "    2.79907132e-02  -9.44844890e-03   5.54508017e-02   2.32968407e-02\n",
      "   -4.13861748e-02  -3.73959784e-02   5.04942968e-02   1.07151693e-01\n",
      "   -6.42235205e-02  -7.20668318e-02  -4.74501075e-02   5.41104782e-02\n",
      "   -5.61712037e-03  -1.28613836e-02   1.92069329e-02  -4.80515173e-02\n",
      "    4.64972292e-02   1.49765468e-02  -2.04387195e-02   1.40640776e-02\n",
      "   -8.70792008e-03   1.70945826e-02  -2.78846255e-02  -1.12509447e-02\n",
      "    2.59687014e-02   7.74475314e-02   2.46489030e-02  -1.74765478e-02\n",
      "   -6.49989676e-02  -1.00809427e-02  -9.63122801e-03   9.08363761e-02\n",
      "   -8.93038442e-02  -5.08790066e-04  -2.09712913e-02   1.05883280e-01\n",
      "   -1.01076200e-01]\n",
      " [ -4.31407352e-03   5.96483537e-02  -1.94998021e-01  -1.09715411e-03\n",
      "    4.66648488e-02  -1.99244754e-02   1.19991361e-01   6.14472443e-03\n",
      "    8.88630116e-02   1.70090874e-01   6.48886857e-02  -1.82317120e-02\n",
      "    9.01006098e-02  -1.54671631e-01  -1.70017547e-02  -1.33615524e-01\n",
      "   -2.20074656e-01   8.21083817e-02  -1.20290585e-01   1.49315868e-01\n",
      "    1.90336319e-01   9.11178293e-02   8.44302911e-02  -1.78791470e-01\n",
      "   -1.40330292e-02   3.67876498e-03  -2.01957254e-02   1.40402951e-01\n",
      "   -8.12260736e-02   2.94394308e-01   3.85660309e-02   1.02326367e-03\n",
      "    3.80320328e-02  -2.46798201e-02   1.17989822e-01   1.67896976e-01\n",
      "   -1.14471570e-02  -8.86072853e-02  -4.40531721e-02  -2.58001391e-01\n",
      "   -3.81918948e-02  -2.32765609e-01   1.81457382e-01  -7.25416032e-02\n",
      "   -1.95652323e-02   8.45211802e-02  -1.59526407e-01  -1.25155206e-01\n",
      "    4.12028384e-02   1.06398089e-01  -4.73320369e-02   5.24874854e-02\n",
      "   -8.89672473e-02  -1.24699486e-01  -5.69508424e-02   1.56846619e-01\n",
      "   -2.62706703e-01  -7.11524765e-02  -5.53474897e-01  -1.07718939e-01\n",
      "    7.24861681e-02  -1.15685931e-01  -5.15684540e-02   7.85342480e-02\n",
      "   -1.28194532e-01  -5.76876230e-02  -2.12166929e-01   1.30744795e-01\n",
      "   -2.27821460e-01   1.00365652e-01   1.90243507e-01   1.16885252e-01\n",
      "    1.87672923e-02   2.80372597e-01   2.07632931e-01   1.74494953e-02\n",
      "   -8.89660284e-02   1.77854297e-02  -2.33573684e-02   1.79309014e-01\n",
      "   -1.20307095e-01  -1.13749478e-01   2.33855892e-02  -1.82384323e-01\n",
      "    1.21595488e-01  -1.53685130e-01   2.20465511e-02  -2.82220380e-02\n",
      "   -1.18107898e-01  -4.66261395e-02   3.43797322e-03  -5.47605306e-02\n",
      "   -2.54589584e-01   1.53790355e-01   1.36555148e-01   2.21220132e-02\n",
      "   -2.00430580e-02   2.35466361e-01  -1.07883319e-01   2.45668195e-02\n",
      "   -2.05958601e-01  -8.99011967e-02  -8.41814959e-02   3.88098514e-02\n",
      "   -1.38372111e-01  -9.41844326e-02  -3.47967340e-03   2.69863768e-01\n",
      "    2.55140886e-02   6.07174972e-03  -1.45317519e-01  -3.61697106e-02\n",
      "    7.28205588e-02  -4.35930932e-02  -4.66008486e-02   1.64488986e-01\n",
      "    1.71716142e-01   1.50144458e-01   1.68368897e-02  -1.38198770e-01\n",
      "   -2.26438198e-01   1.05181616e-01  -9.65021889e-02  -2.13084377e-01\n",
      "    3.47188289e-02   8.84080188e-02  -6.21127782e-02   2.25155328e-02\n",
      "   -2.53185225e-01   1.40335683e-01  -1.74093051e-01  -7.48752279e-02\n",
      "   -2.32042898e-01  -6.21990006e-02  -7.35493462e-02   5.12409080e-02\n",
      "   -3.11970233e-03   2.49968990e-02   1.23604402e-01  -1.08521557e-01\n",
      "    2.55169665e-02  -8.84762374e-02   1.43153382e-01  -9.00845560e-02\n",
      "    2.12711943e-02   7.40606140e-02  -3.59223776e-02  -1.85097484e-01\n",
      "    2.17972422e-01  -4.42053010e-02  -1.93412875e-02  -1.78813371e-02\n",
      "    7.01247613e-02  -3.53491586e-02   1.54292679e-03   2.18250714e-02\n",
      "    6.59304065e-03  -1.55793101e-02   4.92198511e-03   1.92858978e-02\n",
      "   -5.90308749e-02   5.09726215e-03  -8.96640763e-03  -2.26371472e-03\n",
      "    8.48279296e-02   1.81369747e-02  -1.01677962e-01  -8.12623177e-02\n",
      "    7.71656234e-02   1.03145448e-01  -9.71793525e-02   3.01600789e-02\n",
      "   -5.43957191e-02]\n",
      " [  2.21073643e-03  -1.04961054e-01  -4.14529408e-03   6.11289490e-02\n",
      "    1.41153390e-01   5.62160378e-02  -9.05749805e-02  -6.91900799e-02\n",
      "    3.95638490e-02   1.45338117e-01   1.27164517e-01   3.15200989e-02\n",
      "    1.50135524e-01  -3.15142621e-02   2.17405985e-02  -6.87475495e-02\n",
      "    1.23804277e-01  -9.90462677e-02   6.39485094e-02   1.51674398e-02\n",
      "   -1.12071462e-01  -8.62076196e-03   6.19050879e-02   1.57684759e-02\n",
      "   -2.71934175e-02   1.08722062e-01  -2.74196026e-02  -2.67216757e-02\n",
      "    1.29248970e-01  -1.91569864e-01  -9.06141081e-02   7.30824945e-02\n",
      "    6.28573434e-02   1.66307264e-01  -1.02608614e-01  -1.35718441e-01\n",
      "   -3.30340150e-02  -2.46760173e-01   4.59143700e-02   1.08969798e-01\n",
      "    1.18147084e-01   1.05916732e-01   2.11916051e-02  -8.17420232e-02\n",
      "   -6.40828711e-02   9.15918314e-02   3.14796005e-01   7.80305118e-02\n",
      "   -4.04095714e-02  -1.30859536e-01   2.01177007e-02  -5.43159766e-02\n",
      "    6.01347713e-02  -1.41358964e-01  -1.12454023e-02  -1.75514424e-01\n",
      "    7.58382492e-02  -9.27050932e-02  -2.34078681e-01  -5.88735620e-02\n",
      "   -4.18965613e-02   2.37624196e-03   1.85270068e-02  -1.86437353e-01\n",
      "   -2.02091615e-02   1.37895005e-01   1.23972084e-01   3.27969633e-02\n",
      "    5.97002516e-02   5.48245083e-02   8.95843870e-03  -1.48790313e-01\n",
      "   -3.32014983e-02  -9.49147642e-02   2.73294956e-03  -2.96109417e-01\n",
      "    1.68542665e-01  -1.06467353e-01  -2.35278464e-01   4.69861901e-03\n",
      "    1.23076565e-01  -3.16606849e-02   4.52881255e-02   1.19217059e-01\n",
      "   -1.41457890e-01  -2.59319391e-02   1.56920333e-01   4.72103577e-02\n",
      "    2.48107899e-02   2.41770124e-02  -5.90228166e-02  -1.96861355e-02\n",
      "   -8.74418978e-02  -4.80887811e-03  -1.91065684e-01   2.27075677e-01\n",
      "   -6.04264572e-02  -1.09836460e-01   2.06852034e-02  -1.49461582e-01\n",
      "    1.10848794e-02   1.62740110e-01  -1.71273588e-03   1.68892407e-02\n",
      "    2.68456294e-01  -1.71618484e-02   3.75171225e-02  -8.60504295e-02\n",
      "   -1.37125216e-01  -2.52660320e-02  -1.97039579e-01   3.67261414e-03\n",
      "   -2.42261786e-01  -1.04896809e-01  -3.30759025e-02  -5.01925246e-02\n",
      "    2.15296757e-02  -1.81840828e-01   1.08988399e-02   5.23748574e-02\n",
      "   -1.30663290e-01   5.35444626e-02   1.98195747e-01   5.32525519e-03\n",
      "    7.66964108e-02  -3.66070165e-02   1.90171295e-01  -4.66544118e-02\n",
      "   -4.15453914e-02   1.37295644e-01  -1.17868797e-02   7.33328247e-02\n",
      "    1.63512373e-02  -3.57809808e-02   1.04237982e-01  -3.88906227e-03\n",
      "    1.36329774e-02  -3.45464079e-03  -6.26403527e-02  -3.26177183e-02\n",
      "    3.33666748e-02  -2.91059223e-02   4.72798343e-02  -8.09025432e-02\n",
      "    2.99893117e-02   6.56572377e-02   1.00883497e-01   4.39892753e-02\n",
      "   -1.38029202e-01  -9.34623369e-02  -2.28578246e-02   7.93933073e-02\n",
      "    3.44237165e-02  -3.91631360e-02   6.64681661e-02  -3.07520222e-02\n",
      "    5.73260744e-03  -1.54639554e-02   1.99890968e-02   3.38928300e-02\n",
      "   -2.72743532e-02  -6.41151711e-02  -3.01117735e-02  -1.04480824e-02\n",
      "    2.13342888e-02  -2.64602258e-02   1.15242997e-01   4.89261914e-03\n",
      "   -1.27639065e-02   4.46773283e-02  -3.34642369e-02   4.41964858e-02\n",
      "   -3.86560324e-02]\n",
      " [ -3.30215326e-03   6.99487659e-02  -6.09975576e-02  -7.56391482e-02\n",
      "    2.45999554e-02  -1.58368851e-01  -3.83556368e-02   9.48372976e-02\n",
      "   -3.69059032e-02  -6.21113204e-02  -1.80116197e-01   1.15986835e-02\n",
      "   -1.44456068e-01   7.46640436e-02  -3.21136254e-02   1.60580097e-01\n",
      "    3.71206980e-01   1.98804388e-01  -1.77802748e-02  -7.90627335e-02\n",
      "    9.81118019e-02  -1.01505349e-01  -7.60101526e-02  -1.23055507e-01\n",
      "    6.11623238e-02   8.89998602e-02   2.45744971e-03  -1.49822900e-01\n",
      "    4.35385346e-02   3.31103408e-02   8.54083897e-02   1.46674067e-01\n",
      "   -1.69707642e-01  -7.79152734e-02   1.02388757e-01  -1.48231762e-02\n",
      "    1.49543115e-01   1.33830194e-01  -4.96055333e-03   9.48449000e-02\n",
      "    1.69579983e-02   4.50910080e-03  -1.63661830e-01   2.39725363e-01\n",
      "    2.81003895e-02   1.23814669e-01  -1.10152762e-01  -1.28208821e-01\n",
      "    2.85190929e-02  -9.88349270e-02  -1.14578777e-01  -2.59473071e-02\n",
      "   -2.14863088e-01  -3.51067496e-02  -7.12977509e-02   5.47964785e-02\n",
      "    3.88634353e-02  -4.36206649e-03   5.18106734e-01  -2.10319325e-01\n",
      "   -4.91576677e-03  -1.58845615e-01   4.01590989e-02  -5.55846165e-02\n",
      "    1.16726229e-01  -1.63978619e-01  -6.52447231e-02  -5.34154265e-02\n",
      "    7.00770812e-03   1.35856300e-01  -1.08954680e-01  -1.00364818e-02\n",
      "   -6.08557132e-02   2.95401100e-02  -5.55496848e-02   9.57620949e-02\n",
      "    8.04613805e-02   9.64238512e-02   1.98344636e-01  -2.57953460e-01\n",
      "   -1.30011510e-01  -1.08519975e-01  -6.05313973e-02   2.79461040e-02\n",
      "    8.42334771e-02   2.05436863e-02   1.31739315e-01   4.73995262e-02\n",
      "    1.48104201e-01   5.38801175e-03  -1.28851025e-01  -1.85456094e-01\n",
      "    2.35840425e-02   1.57553353e-02   5.95561825e-02   8.00923787e-02\n",
      "    1.38374920e-01  -2.88663922e-02   4.25057951e-02  -4.66750352e-02\n",
      "    6.66230834e-02   1.17506200e-02   1.90207093e-01   3.72687357e-02\n",
      "   -5.13878789e-03   1.15549418e-01   4.28521427e-02  -2.14598580e-01\n",
      "    7.54490786e-02  -3.79399330e-03   4.85786669e-03   9.52832269e-02\n",
      "    5.56249109e-02   2.20976540e-01   9.77866323e-03  -4.03117787e-01\n",
      "    2.03878867e-01  -2.80031968e-01  -1.24652120e-01   9.38421083e-03\n",
      "    1.53999994e-02  -1.77986039e-01  -6.76807769e-02   8.25270881e-02\n",
      "   -6.47600289e-02  -1.73340834e-02  -9.22672250e-02  -9.92007355e-02\n",
      "    1.49643115e-01   2.46830400e-01   8.51552872e-02   8.64052211e-02\n",
      "   -4.89632932e-02   1.37703012e-01  -1.42318370e-01   2.21815955e-02\n",
      "   -1.94722060e-02   1.01164965e-02  -1.25142819e-01   7.63057271e-02\n",
      "    1.55774189e-02   3.01296782e-02  -1.05265840e-01   1.38013332e-01\n",
      "   -1.09456981e-02  -1.24111183e-01   3.65955872e-02  -1.05040311e-01\n",
      "    4.32316504e-02   1.99631394e-02   1.18102242e-02   3.12818462e-02\n",
      "   -6.00765756e-02   2.25759407e-02   2.25703686e-02  -4.32700681e-02\n",
      "   -5.57229873e-03  -4.99389357e-02   4.88484845e-02  -4.30916210e-02\n",
      "    4.62826651e-02   1.47784235e-02   1.70792970e-02   1.26016740e-02\n",
      "   -2.70692960e-02  -1.72410476e-02   1.00601621e-03   1.45690433e-02\n",
      "   -1.31114634e-02  -7.92494622e-02   8.40915026e-02  -1.42245190e-01\n",
      "    1.40785482e-01]\n",
      " [ -1.25496595e-02  -2.76707435e-02   1.33336633e-01   1.11215198e-02\n",
      "   -1.35046177e-01   9.51671161e-02   8.23794394e-02   9.64617623e-02\n",
      "    1.43990627e-01  -4.22662332e-02  -3.20862155e-02   8.33449992e-02\n",
      "   -1.43023911e-01  -4.59148070e-02  -6.29598426e-02   4.86819087e-03\n",
      "   -3.29947843e-01  -7.54619329e-02  -4.11725996e-02   3.10908294e-02\n",
      "    5.98046126e-02  -7.29022389e-02  -4.86164397e-03   5.22341406e-02\n",
      "    1.09312409e-01  -1.15560379e-01   1.02052012e-02  -2.45576979e-02\n",
      "   -1.19962264e-01  -8.75265428e-02   4.63238617e-05   2.94075913e-03\n",
      "   -1.33956078e-03  -1.59541229e-01   2.27258444e-02  -3.45009880e-02\n",
      "   -3.14457593e-02   9.73878660e-02   1.25142186e-01   2.49714289e-02\n",
      "   -8.66524514e-03   1.26630267e-01  -1.05070137e-02  -9.49882160e-02\n",
      "    6.08136075e-02  -2.01972610e-01  -9.23036223e-02   2.88657479e-02\n",
      "   -2.33277865e-02   1.67582790e-01  -1.16250106e-01   1.17751107e-02\n",
      "    9.60182602e-02   1.89337976e-01   7.12371730e-02  -1.84005885e-02\n",
      "    2.63530445e-02   2.26038901e-01   7.84272333e-01   3.40180564e-01\n",
      "    3.28119913e-02   2.21701693e-02  -1.54436659e-01   1.53524916e-01\n",
      "   -1.68450149e-01   2.20559030e-02  -5.66556165e-02  -5.61861958e-02\n",
      "    1.13389642e-01  -1.69175305e-01  -1.95511316e-01   1.01879276e-01\n",
      "    1.49495476e-01  -1.61942710e-01  -3.55922365e-02   1.92482305e-01\n",
      "   -2.20818384e-01   4.47653293e-02  -3.84623242e-02   1.17956764e-01\n",
      "    1.17505121e-02   4.86840165e-02  -6.84299195e-02   9.90303797e-02\n",
      "   -1.26836362e-01   4.32896140e-02  -1.31882833e-01  -1.14519278e-01\n",
      "   -3.67930495e-02   9.48916763e-02   8.30297574e-02   2.63975629e-02\n",
      "    1.48670869e-01  -1.46501914e-01   7.70647813e-02  -1.00589003e-01\n",
      "    2.69180108e-02  -8.49682303e-02  -7.13451165e-02   5.88814868e-02\n",
      "   -3.07165433e-02  -1.77829264e-01  -1.41612616e-02  -3.54685820e-02\n",
      "   -1.63158109e-01  -1.23866887e-01  -7.54719693e-02   9.26922216e-02\n",
      "   -1.90368592e-02   2.12875571e-01   1.66656235e-01   7.24931254e-02\n",
      "    2.07886988e-02  -1.34613426e-01  -1.09685264e-02   1.75668155e-01\n",
      "   -8.25943811e-02   3.34865080e-01  -9.29394256e-02  -4.11739043e-02\n",
      "    1.01357902e-01   6.60293709e-03  -2.75144337e-01  -2.51780428e-02\n",
      "   -1.44367422e-01   6.27216817e-03   9.12862136e-02   4.19987474e-02\n",
      "    2.73462369e-01  -3.00543950e-01   5.26198332e-01  -3.08919709e-03\n",
      "    4.51869377e-01  -1.97922974e-02   2.87850640e-02  -1.21402804e-01\n",
      "   -2.95462792e-02  -3.48225095e-03  -6.16928177e-03  -5.70475317e-02\n",
      "    1.20995447e-02   4.70714843e-02  -2.48172449e-02  -5.55440655e-02\n",
      "   -3.22018885e-03   4.28972532e-02  -2.86826746e-02   4.72491638e-02\n",
      "   -1.94528624e-02   1.00270572e-01   1.17850824e-02  -5.06338578e-02\n",
      "   -7.38067471e-02   1.13655436e-02  -5.03820821e-02   2.62321203e-02\n",
      "   -6.94590280e-04  -2.31502356e-02   9.95922281e-03  -6.74772235e-04\n",
      "   -1.11444095e-02  -5.23424605e-03  -1.67777331e-03   8.97049367e-03\n",
      "   -7.00213677e-03   6.00939429e-03  -2.09290652e-02  -4.30114449e-02\n",
      "    3.12500320e-02  -6.02637844e-02   3.97305411e-02  -2.69589058e-02\n",
      "    1.43889638e-02]]\n",
      "====Iteration 0  ====\n",
      "For  StochasticLogisticRegression  eta:  0.1 Iterations:  5000 Regularization:  L2  : Accuracy of:  0.163366336634\n",
      "confusion matrix\n",
      " [[ 5 22  0  0  0]\n",
      " [ 1 28  0  0  0]\n",
      " [ 2 47  0  0  0]\n",
      " [ 1 57  0  0  0]\n",
      " [ 1 38  0  0  0]]\n",
      "MultiClass Logistic Regression Object with coefficients:\n",
      "[[  2.46942254e-01  -1.58750455e+01  -1.00642960e+01  -3.33861109e+01\n",
      "    8.42397993e+00   1.58566202e+01   1.75804264e+01  -2.58697243e+01\n",
      "   -4.62104167e+01  -6.69103776e+00   3.37988132e+01  -1.08028621e+01\n",
      "   -3.11631677e+01   1.39013380e+01   3.28251580e+01   1.60598638e+01\n",
      "    1.76790681e+01  -2.80897604e+01  -2.29476356e+01   1.14277146e+01\n",
      "   -2.52234662e+01  -1.02799508e+01   1.34000429e+01  -7.40124074e+00\n",
      "   -3.25276674e+01  -1.48468276e+01   2.09395109e+01  -1.76561981e+01\n",
      "   -2.15231494e+01   2.66843522e+01   1.65828412e+01  -2.38012521e+01\n",
      "    1.70902102e+01  -6.61285837e+00   1.28828204e+01  -1.31165053e+01\n",
      "   -1.10597139e+01  -1.85380819e+01  -1.51166596e+01  -1.84283251e+01\n",
      "   -1.57517921e+01   8.47483465e+00   2.28679279e+01   1.69043649e+01\n",
      "   -2.68911343e+01  -1.14918061e+01  -1.83629017e+01  -1.56537544e+01\n",
      "    1.51551829e+01   6.60156000e+00   1.27674295e+01  -3.11492517e+01\n",
      "    3.03645452e+01   2.35947663e+01  -1.80158020e+01  -1.28821970e+01\n",
      "    1.98174401e+01  -3.81155823e+01  -7.53161863e+01  -1.48720915e+01\n",
      "    2.05022856e+00  -1.26225772e+01  -1.59967577e+01  -1.90097893e+01\n",
      "   -7.44469369e+00  -2.17948503e+01  -2.33581347e+01  -7.29125859e+00\n",
      "   -3.09745733e+01  -3.03234242e+01  -2.28946274e+01  -1.50075150e+01\n",
      "   -3.44119515e+01  -8.45418326e+00  -2.50161150e+01   8.03263176e+00\n",
      "   -1.89515544e+01  -2.25216124e+01  -1.39387863e+01  -1.07911115e+01\n",
      "   -1.91196555e+01  -6.80476241e+00  -5.35681158e+00  -2.73483484e+01\n",
      "    3.78037623e+00   1.72994867e+01  -1.22461721e+01  -1.82276361e+01\n",
      "   -9.09717312e+00  -9.51286516e+00   1.09733730e+01   9.93477223e+00\n",
      "    1.17189416e+01  -1.41769270e+01  -1.60274515e+01  -3.16191598e+01\n",
      "   -1.42030552e+01   1.23823607e+01  -5.22345738e+00  -6.65213504e+00\n",
      "   -1.81709691e+01   7.46025114e+00  -3.27569411e+01  -1.19795636e+01\n",
      "   -2.33666423e+01  -1.88098189e+01  -1.83621423e+00  -1.96447437e+01\n",
      "    1.56242697e+01  -2.65837459e+01  -1.65036243e+01  -1.59456377e+01\n",
      "    5.81051620e+00  -2.29348598e+01   1.69773681e+01  -1.25582074e+00\n",
      "   -2.93360945e+01  -2.06476489e+01   1.02149146e+01  -1.09443310e+01\n",
      "   -1.04609896e+01  -1.84939460e+01   3.53667298e+01  -1.51593013e+01\n",
      "   -9.90867765e+00   1.36448960e+01  -2.05490932e+01   8.16272164e+00\n",
      "   -2.36853821e+01  -1.65193127e+01  -5.56105996e+01  -2.72167844e+01\n",
      "   -5.24906409e+01  -3.44878494e+01  -2.02904575e+01   2.91563700e+01\n",
      "    1.28620985e+01   1.42159427e+00  -4.74554781e+00  -8.98193570e+00\n",
      "   -1.07553920e+01  -9.51047725e+00   9.71874720e+00   1.45620000e+01\n",
      "   -1.06549817e+01  -1.44960760e+01   9.88577833e+00   9.26954707e+00\n",
      "   -9.08238314e+00  -7.77392723e+00   1.20740000e+01  -1.34754020e+01\n",
      "   -1.03777285e+01  -9.67373916e+00   8.90860865e+00   1.11220728e+01\n",
      "   -5.87000000e+00   1.09274669e+01  -1.06985247e+01  -8.24799886e+00\n",
      "    8.58094112e+00   1.28626086e+01   1.03760000e+01  -9.07000000e+00\n",
      "   -1.16933857e+01   1.14887984e+01  -1.22507913e+01   1.46485384e+01\n",
      "   -1.36215962e+01   1.01992300e+01  -1.00702877e+01   1.23860078e+01\n",
      "   -1.21490655e+01]\n",
      " [ -8.21464417e-02   1.37900801e+01  -1.94526280e+01  -3.02901081e+01\n",
      "    1.06965037e+01   9.12941856e+00   3.93286067e+01  -6.38085222e+00\n",
      "   -1.77935898e+01   3.04336780e+01   2.95803285e+01   2.09654565e+01\n",
      "   -2.22533540e+01  -1.67919402e+01   1.16166855e+01  -9.09065066e+00\n",
      "    1.40476348e+01  -1.50045542e+01  -3.09422448e+01   3.56413731e+01\n",
      "   -7.86466844e+00  -1.14953267e+01  -7.73661689e+00  -2.16056120e+01\n",
      "   -3.33008102e+01   1.75874906e+01  -5.13350759e+00   9.08928948e+00\n",
      "    6.77956607e+00   3.87161073e+01   2.38286353e+01  -7.88120385e+00\n",
      "   -2.87118874e+00   6.49392836e+00  -3.65535994e+00   1.90050038e+01\n",
      "    1.87924297e+01  -1.78171438e+01   1.56237158e+01  -2.18199493e+01\n",
      "   -3.28339791e+01  -2.76526238e+01   7.15647621e+00  -1.24328858e+01\n",
      "   -1.18309699e+01  -1.65926771e+01  -1.68277859e+01  -1.09818230e+01\n",
      "    1.03582463e+01  -1.03331374e+01   4.38991625e+00  -2.56037962e+01\n",
      "   -2.02321527e+01  -1.03596933e+01  -2.56032722e+01  -1.66326309e+01\n",
      "   -3.12178591e+01  -3.63758144e+01  -6.46903272e+01   1.49995340e+01\n",
      "    5.17524895e+00  -1.97567786e+01  -2.05993046e+01  -2.66978233e+01\n",
      "   -1.30869936e+01  -1.12096193e+01  -1.58618890e+01  -6.06366599e+00\n",
      "   -3.92419338e+01  -2.21156490e+01  -1.66813434e+01  -1.95206165e+01\n",
      "   -1.20202021e+01   1.69515574e+01  -2.09979572e+00  -9.59828893e+00\n",
      "    1.42121515e+01   7.49465791e+00   1.19702843e+01   2.76185481e+01\n",
      "   -1.47717440e+01  -3.44511747e+00  -6.28621086e+00  -2.45611489e+01\n",
      "   -1.12526574e+01  -2.70364867e+01   1.36317499e+01   1.97535708e+01\n",
      "    2.09158258e+01   1.91214788e+01   1.67675600e+01   1.20908569e+01\n",
      "   -2.45406522e+01   1.15711770e+01   2.20202872e-01  -2.86481700e+01\n",
      "   -1.34609241e+01   1.65926546e+01   1.61841840e+01  -2.29318894e+01\n",
      "   -1.48773784e+01  -2.61529558e+01  -1.44318084e+01  -7.69473106e+00\n",
      "   -1.55152965e+01  -2.68729108e+01  -1.29488984e+01  -4.06512085e+00\n",
      "   -1.47521803e+01  -2.13959633e+01  -3.05505759e+01  -1.43830707e+01\n",
      "    2.13013779e+01  -1.60341817e+01  -1.49443628e+01  -8.15424032e+00\n",
      "    9.17989011e+00   2.20285980e+01   1.60858719e+01  -1.60321742e+01\n",
      "   -2.04024534e+01  -2.32279233e+01  -1.07368467e+01  -1.59955172e+01\n",
      "    1.33858666e+01   1.14086568e+01  -1.22330461e+01   1.45647326e+01\n",
      "   -1.96215836e+01   2.98519403e+01  -3.39163323e+01  -2.31066459e+01\n",
      "   -5.02617354e+01  -1.52299940e+01   1.75116899e+01   3.89940068e+01\n",
      "    9.27027343e+00   2.80228614e+01   6.67387224e+00  -1.38480000e+01\n",
      "    9.75599989e+00  -1.10445770e+01   1.49364307e+01   6.72399989e+00\n",
      "   -1.21542851e+01   1.58181388e+01   1.21987564e+01  -1.56826177e+01\n",
      "    1.33897148e+01  -9.96399983e+00   7.85600001e+00  -1.06832915e+01\n",
      "   -6.66485513e+00  -1.46658594e+01   8.79200000e+00   1.53657130e+01\n",
      "   -6.99200000e+00   5.96337411e+00  -6.11952055e+00  -9.98999955e+00\n",
      "    9.00385311e+00  -1.31508511e+01  -1.06340000e+01   9.71000000e+00\n",
      "   -6.34800007e+00  -9.57400494e+00   9.90470967e+00   7.59610394e+00\n",
      "   -7.57425038e+00   1.23990928e+01  -1.24852392e+01   1.41429457e+01\n",
      "   -1.45290921e+01]\n",
      " [  1.13631700e-02  -2.10778466e+01  -5.95540707e+00  -1.01670720e+01\n",
      "    9.83740074e+00  -8.91831259e+00  -1.69634225e+01  -1.42518109e+01\n",
      "    8.00308951e+00   2.49945833e+01   3.01987039e+01   2.54512512e+01\n",
      "    1.00065388e+01   9.22439424e+00  -1.60377120e+01  -1.42419760e+01\n",
      "    1.83536501e+01  -1.11331139e+01  -7.54076797e+00  -1.22569627e+01\n",
      "   -1.69333614e+01  -4.38634696e+00   2.09351123e+01   5.09572998e+00\n",
      "   -1.27923074e+01  -5.07258297e+00   1.24437837e+01   1.17581884e+01\n",
      "    2.72567208e+01  -2.63781440e+01  -3.22943956e+00   1.39043385e+01\n",
      "   -1.45812892e+01   2.35571108e+01  -1.24830392e+01   1.15315476e+01\n",
      "    2.52377808e+00  -1.53609453e+01  -1.37645203e+01   1.68332380e+01\n",
      "    8.70555412e+00   2.18719128e+01  -9.72375864e+00  -2.07591029e+01\n",
      "   -1.88881690e+01   2.69217345e+01   1.98866717e+01   1.77344212e+01\n",
      "    6.73299612e+00   2.14432014e+00   4.50327749e+00  -2.93255696e+00\n",
      "    1.34721096e+01   8.16419008e-01   1.41416048e+01  -3.25512175e+01\n",
      "    1.82180736e+01  -1.91002569e+01  -2.85631483e+01  -1.76346383e+01\n",
      "   -1.78687545e+01  -1.67022759e+01  -1.29024783e+01  -1.44378892e+01\n",
      "   -1.35410660e+01  -4.32100605e+00   1.48063621e+01  -3.13432865e+00\n",
      "    1.70624038e+01   2.32973100e+01   9.92710837e+00  -2.74321427e+01\n",
      "   -1.23127166e+01  -1.95226959e+01  -1.18050089e+01  -3.56801218e+01\n",
      "    2.63096626e+01  -2.40596332e+01  -1.95828279e+01  -9.95699493e+00\n",
      "    2.86803861e+01  -1.13539605e+01  -1.09501337e+01  -9.71148655e+00\n",
      "   -2.23504452e+01  -2.39458095e+01  -5.05389649e+00  -9.52063908e+00\n",
      "   -1.45145089e+01   1.31512518e+01  -1.76689908e+01   8.97962116e+00\n",
      "   -1.49418733e+01  -9.73374779e+00  -8.00599576e+00   2.53657739e+01\n",
      "   -1.62988941e+01  -1.30724319e+01  -1.18850495e+01  -2.23965172e+01\n",
      "   -1.98870337e+01   2.64713062e+01   1.73170806e+01  -1.63038376e+01\n",
      "    2.60787631e+01   1.30745498e+01   1.06981914e+01  -1.25279390e+01\n",
      "   -2.05696597e+01  -1.33023632e+01  -2.22401484e+01  -1.81314448e+01\n",
      "   -1.79063905e+01   9.96036443e+00  -2.10406111e+01  -1.60922824e+01\n",
      "   -1.31445796e+01  -1.85540915e+01   1.31786390e+01  -1.12514220e+01\n",
      "   -2.21320641e+01  -9.46115262e+00   1.47627959e+01   1.21477362e+01\n",
      "   -1.05933641e+01  -3.03855074e+01   1.13045413e+01  -1.89554834e+01\n",
      "   -1.04343731e+01   1.19936003e+01   1.59720134e+01   1.28718463e+01\n",
      "    1.19305044e+01  -1.40013774e+01   9.97484520e-01  -1.61719484e+01\n",
      "    2.35034461e+00   1.20391421e+01   8.82265374e+00   1.32122353e+01\n",
      "   -1.22270632e+01  -1.37734958e+01   1.27176868e+01  -1.73479951e+01\n",
      "    1.46805325e+01   1.33328257e+01  -9.54555174e+00   1.64890205e+01\n",
      "   -1.66881055e+01  -1.53743669e+01   6.57000000e+00   1.66888159e+01\n",
      "    1.13409143e+01   1.25692248e+01   9.58806273e+00  -1.27679243e+01\n",
      "    8.37200000e+00  -1.26720218e+01   1.37542196e+01   1.23690838e+01\n",
      "   -1.19737206e+01   1.13868032e+01  -1.00580000e+01  -9.57600000e+00\n",
      "   -1.07840025e+01   7.18000000e+00  -7.26543745e+00  -9.65688522e+00\n",
      "    8.97024839e+00  -7.38047751e+00  -1.22221593e+01  -1.17286026e+01\n",
      "    1.06459658e+01]\n",
      " [  9.40981680e-02   1.36325049e+01  -1.45839812e+01   2.75320053e+01\n",
      "    1.84894680e+01   1.30348151e+01  -3.69362375e+00   2.75072187e+01\n",
      "    2.85342287e+01  -2.15046400e+01  -3.67413713e+01  -1.64361761e+01\n",
      "    1.83896895e+01   1.56843657e+01  -1.49961631e+01   1.46277263e+01\n",
      "    1.94106253e+01   2.99243395e+01  -6.30303002e+00  -1.41722278e+01\n",
      "    1.62597994e+01  -3.93193785e+00  -8.01188549e+00   1.14616182e+01\n",
      "    3.41506302e+01   1.71040373e+01   3.44982729e+00   1.47553760e+01\n",
      "    1.18093740e+01  -1.38002714e+01  -4.90596366e+00   2.07519662e+01\n",
      "   -1.94454030e+01  -1.48666718e+00  -2.17336876e+00   2.20291288e+01\n",
      "    1.38999103e+01   1.01676227e+01   3.85747198e+00   3.13648740e+01\n",
      "    1.14587164e+01   5.84240079e+00  -1.40294782e+01   1.08196685e+01\n",
      "    2.67874092e+01   4.83618670e+00   1.67250013e+01  -1.08929524e+01\n",
      "    1.66849217e+01   1.70487408e+01   1.61848690e+01   2.79829698e+01\n",
      "   -1.43677454e+01   1.63782061e+01   4.19287443e+00   2.52064939e+01\n",
      "    2.63294437e+01   9.80635019e+00   5.79836655e+01  -1.63740820e+01\n",
      "    2.12844298e+01   9.19781868e+00   2.83139768e+01   1.67473411e+01\n",
      "    1.74160030e+01  -1.37719124e+01   4.51816432e+00  -9.17476761e+00\n",
      "    1.50919553e+01   1.85979148e+01   1.50032235e+01   9.91697730e+00\n",
      "    1.32406025e+01   7.51000205e+00   1.28731944e+01   9.13470235e+00\n",
      "    2.05298756e+01  -1.46890172e+01   1.53139036e+01  -2.86822040e+01\n",
      "    9.78495897e+00   9.49883689e-01   6.30519850e+00  -1.82882132e+01\n",
      "    1.71525779e+01   3.08208918e+00   1.70899446e+01   5.01914046e+00\n",
      "    6.84751861e+00   1.50053987e+01  -2.39471486e+01  -1.68311030e+01\n",
      "   -9.72567845e+00   1.21204766e+01  -1.47184052e+01   1.21412674e+01\n",
      "    1.51522787e+01  -1.84664645e+01   9.76640483e+00   3.43108970e+00\n",
      "    2.05949937e+01  -1.22385715e+01   3.56001400e+01  -9.51818142e+00\n",
      "    1.51069159e+01   1.05934981e+01   4.67283047e+00  -1.19323381e+01\n",
      "    1.28938718e+01   1.88694663e+01   1.64315054e+01   2.86103471e+01\n",
      "   -8.06263797e+00   2.64325202e+01  -8.34524551e+00  -2.62286414e+01\n",
      "    1.26141156e+01  -2.82937223e+01  -9.44968160e+00   1.22513530e+01\n",
      "    2.26319864e+01   1.08508249e+01  -7.58228488e+00  -3.37038688e+00\n",
      "   -1.14150300e+01   1.13322960e+01  -1.18867440e+01   7.18360146e+00\n",
      "    1.95412453e+01   2.68210660e+01   3.24344981e+01  -1.34799411e+01\n",
      "    2.16873547e+01   2.38045231e+01  -1.67566376e+01  -2.90422978e+00\n",
      "   -2.24375752e+01  -2.91343730e+01   1.00607192e+01  -6.55160152e+00\n",
      "    1.23290416e+01   1.42693877e+01  -1.63848614e+01   1.20683997e+01\n",
      "    1.12852586e+01  -1.29876918e+01   1.09917118e+01  -1.33292209e+01\n",
      "    1.10976073e+01   8.49815145e+00   1.20659999e+01  -1.23068462e+01\n",
      "    1.22547930e+01  -8.75559106e+00   1.33572403e+01  -1.46475510e+01\n",
      "   -8.73000000e+00  -7.02391742e+00   7.52001559e+00   6.96000006e+00\n",
      "   -6.54390189e+00  -9.11861193e+00   1.00520000e+01   1.06580000e+01\n",
      "   -8.44800000e+00  -1.05147414e+01   8.02545150e+00  -1.00365242e+01\n",
      "    1.05806224e+01  -1.37457275e+01   1.41378257e+01  -1.63914372e+01\n",
      "    1.63975353e+01]\n",
      " [  7.35700055e-02   1.93502311e+01   1.80588762e+01   1.28641668e+01\n",
      "   -3.07019549e+01  -2.06996689e+01  -1.78415474e+01  -6.24828746e+00\n",
      "    3.25691388e+01  -2.17394082e+01  -3.25181642e+01  -1.30566541e+01\n",
      "    2.71461792e+01  -1.62563658e+01  -2.49722574e+01  -1.83634151e+01\n",
      "   -4.24726165e+01  -1.78972019e+01   2.18756268e+01  -1.79731999e+01\n",
      "    2.08022434e+01   1.89260938e+01  -5.98751728e+00   2.40557981e+01\n",
      "    2.24689021e+01  -1.29896275e+01  -1.71460119e+01   1.58378105e+01\n",
      "   -1.24753282e+01  -2.20823347e+01  -2.20284047e+01   1.91755058e+01\n",
      "   -6.49443922e+00  -1.50536622e+01  -1.15946123e+01  -3.21567639e+01\n",
      "   -2.66120551e+01   2.16768465e+01  -5.20012397e+00  -1.05962496e+01\n",
      "   -8.96091842e+00  -1.56663295e+01  -1.31496703e+01   1.01674935e+01\n",
      "    2.28958081e+01  -2.58865676e+01   1.37156683e+01   6.36306751e+00\n",
      "    1.34880271e+01  -1.05928442e+01  -1.29501202e+01   2.39900957e+01\n",
      "   -1.28816460e+01   2.58267805e+01   1.70986607e+01   1.23472849e+01\n",
      "    1.07953000e+01   6.20378064e+01   9.75830964e+01   2.60920626e+01\n",
      "    1.54749657e+01   2.00036897e+01  -6.38642102e+00   3.53757084e+01\n",
      "    5.03460843e+00   2.24162672e+01   2.77071246e+01  -1.10809678e+01\n",
      "    4.29609445e+01   2.35781674e+01   2.20296207e+01   3.56386082e+01\n",
      "    2.85403857e+01  -1.48236691e+01   1.58421589e+01   2.72569635e+01\n",
      "   -2.37839523e+01   1.67178420e+01  -1.07221816e+01   7.14374108e+00\n",
      "    1.81577787e+01   1.31328475e+01   4.84112881e+00   3.98837810e+01\n",
      "   -2.06652208e+01   2.27778303e+01   1.65746028e+01   2.10834868e+01\n",
      "   -8.72202037e+00  -3.48499479e+01  -8.14114281e+00  -9.84056231e+00\n",
      "    2.27923258e+01  -2.08435986e+01   2.16784680e+00   1.41272035e+01\n",
      "    1.35557262e+01  -1.51007400e+01  -2.19452676e+01   1.49922562e+01\n",
      "    1.89365762e+01   1.04466164e+01  -1.02162491e+01  -1.08073442e+01\n",
      "   -9.83323379e+00   1.84807706e+01  -2.30766450e+01   2.57410044e+01\n",
      "    2.17862426e+01   4.04054160e+01   2.74379658e+01   2.00464698e+01\n",
      "   -7.80152544e+00  -1.48881829e+01   1.13785016e+01   2.53987768e+01\n",
      "    2.99903535e+01   2.88556516e+01  -1.16325389e+01   1.32425302e+01\n",
      "    2.19185898e+01   2.47094591e+01  -2.95497063e+01  -5.12811413e+00\n",
      "   -1.11136499e+01  -1.46293193e+00   2.41225310e+01   1.87481566e+01\n",
      "    2.23404350e+01  -4.03383223e+01   6.96948258e+01   3.60387694e+01\n",
      "    8.39691979e+01   3.30645783e+01   2.57884388e+01  -5.24272676e+01\n",
      "   -2.41526959e+01  -2.70471434e+01   5.38752977e+00   1.01706152e+01\n",
      "    9.59777741e+00  -1.16840304e+01  -8.22079214e+00   9.80706812e+00\n",
      "   -1.07896006e+01  -9.54189755e+00   1.15945730e+01  -9.58859085e+00\n",
      "    8.04358786e+00   1.57069528e+01   1.20239932e+01  -1.28661085e+01\n",
      "   -1.47072675e+01   1.04190366e+01   5.87038221e+00  -7.73984878e+00\n",
      "   -9.98800000e+00   1.38934831e+01  -1.39285059e+01  -1.01150556e+01\n",
      "    1.02126256e+01  -1.09824642e+01  -8.97800000e+00  -9.65198384e+00\n",
      "   -1.40819962e+01   1.54794330e+01  -9.85141879e+00   3.31974192e+00\n",
      "   -3.25417191e+00   1.13668069e+01  -1.17932369e+01   8.68121238e+00\n",
      "   -7.67764237e+00]]\n",
      "====Iteration 1  ====\n",
      "For  StochasticLogisticRegression  eta:  0.1 Iterations:  5000 Regularization:  L2  : Accuracy of:  0.292079207921\n",
      "confusion matrix\n",
      " [[ 9  0 19  0  0]\n",
      " [ 5  0 28  0  0]\n",
      " [ 2  0 49  0  0]\n",
      " [ 2  0 40  1  0]\n",
      " [ 0  0 47  0  0]]\n",
      "MultiClass Logistic Regression Object with coefficients:\n",
      "[[ -5.47101453e-02  -1.42320618e+01  -1.09302354e+01  -3.44000683e+01\n",
      "    1.81543203e+01  -6.94478396e+00   1.41273451e+01  -3.44613526e+01\n",
      "   -4.23053539e+01   1.08555696e+01   2.15639250e+01   1.07694377e+01\n",
      "   -2.91814748e+01   2.58616210e+01   2.41017056e+01   2.02770612e+01\n",
      "    2.47667097e+01  -2.40683069e+01  -1.80983924e+01  -1.06237900e+01\n",
      "   -2.53625570e+01   1.32274354e+01   1.46601614e+01  -9.23893233e+00\n",
      "   -3.49675885e+01   6.29028535e+00   1.98774675e+01  -1.79372068e+01\n",
      "   -2.45667627e+01   2.63155725e+01  -6.56817041e+00  -2.79237891e+01\n",
      "    2.02563799e+01   1.80061743e+01  -1.35709515e+01   1.44482069e+01\n",
      "    9.58770991e+00  -1.69138876e+01  -1.62933076e+01  -2.40918663e+01\n",
      "   -1.81593157e+01   4.47536772e+00  -2.31281648e+00   9.55926178e+00\n",
      "   -1.92429743e+01   9.23564608e+00  -2.61383829e+01  -2.11252179e+01\n",
      "    1.19187532e+01  -5.30910390e+00   2.13885231e+01  -2.73962009e+01\n",
      "    2.43726436e+01  -3.28718473e+00  -1.12972319e+01  -8.57477706e+00\n",
      "    1.45840328e+01  -4.54638948e+01  -7.50849491e+01   6.95384783e+00\n",
      "   -1.14879273e+01  -9.55739249e+00   4.94643709e+00  -2.12664851e+01\n",
      "   -8.63710931e+00  -2.46373861e+01  -2.34899794e+01  -7.11782812e+00\n",
      "   -3.57119488e+01  -3.35495552e+01  -3.56394192e+01  -2.45649886e+01\n",
      "   -3.42028918e+01  -1.39266528e+01   2.15531095e+00  -1.53002983e+01\n",
      "   -2.25412434e+01  -1.49770921e+01   1.59490923e+01  -1.34231946e+01\n",
      "   -1.78310848e+01  -4.03636763e+00  -1.22539185e+01  -2.94936409e+01\n",
      "    2.26662493e+01   1.79027273e+01  -1.52919923e+01  -1.32128167e+01\n",
      "    4.54512036e+00   1.59804838e+01   2.00864145e+01   2.03896499e+01\n",
      "    9.30159560e+00  -1.08516905e+01  -2.04490559e+01  -3.50156363e+01\n",
      "   -1.47018306e+01   7.81734032e+00   2.42831849e+01   2.18280555e+01\n",
      "    6.53157364e+00  -1.27063516e+01  -2.09550225e+01  -1.20089881e+01\n",
      "   -1.90443088e+01  -1.00312490e+01   2.54619520e+01  -1.48882768e+01\n",
      "    1.79728846e+01  -2.46940155e+01  -6.49987491e+00  -1.31681179e+01\n",
      "    1.04114777e+01  -1.10497954e+01   8.33988098e+00   1.41431357e+00\n",
      "   -3.15568733e+01  -2.38279543e+01   2.32806112e+01  -1.45679450e+01\n",
      "    1.29721101e+01  -1.68066682e+01   3.75972078e+01  -1.20521588e+01\n",
      "   -6.43764661e+00  -4.42105132e+00  -1.65125410e+00  -1.94850347e+01\n",
      "   -3.52261238e+01  -2.16341725e+01  -5.23596309e+01  -1.76158030e+01\n",
      "   -5.76796477e+01  -3.10782560e+01  -2.18166374e+01  -3.50646458e+00\n",
      "    1.81327805e+01  -1.46304627e+01   2.28240013e+01  -1.04760000e+01\n",
      "    9.47594928e+00   9.37582798e+00  -8.84848740e+00   1.51160001e+01\n",
      "   -1.25522644e+01   4.65555414e+00  -1.70944871e+01  -8.43622610e+00\n",
      "    1.56960030e+01   1.29197980e+01   1.15760000e+01  -1.56080000e+01\n",
      "   -8.95250813e+00   9.77146845e+00   9.20600290e+00  -8.88218150e+00\n",
      "   -9.65800000e+00  -1.31086778e+01   1.33719676e+01   7.96456578e+00\n",
      "   -7.92527592e+00  -5.50400000e+00  -9.06999710e+00  -8.31600000e+00\n",
      "   -1.16820000e+01   1.06080000e+01   7.01728695e+00   1.74838460e+01\n",
      "   -1.75365562e+01  -8.44122810e+00   6.97851796e+00   1.51146645e+01\n",
      "   -1.50813746e+01]\n",
      " [ -1.72992183e-01  -1.30873006e+01  -1.69461150e+01  -2.92247557e+01\n",
      "   -1.70435111e-01   1.31019044e+01   2.92595582e+01   1.62714989e+01\n",
      "    3.35104659e+00   1.47304356e+01   1.18696251e+01  -6.83045396e+00\n",
      "   -1.87250890e+01  -1.70293442e+01  -1.70182874e+01  -6.27592879e+00\n",
      "   -9.64488520e+00  -1.87325135e+01  -2.41991353e+01   2.60735560e+01\n",
      "    1.20559764e+01   8.80450828e-01   1.27034671e+01  -2.76361831e+01\n",
      "   -1.87530271e+01  -9.78226446e+00  -1.08814091e+01  -1.18816600e+01\n",
      "   -1.45972779e+01   3.11881601e+01   2.73164336e+01   8.32981402e+00\n",
      "    2.12276849e+01  -9.71128288e+00   1.30857725e+01  -2.29325310e+00\n",
      "    6.05488670e+00   2.23371516e+00   5.32771485e+00  -2.38221420e+01\n",
      "   -1.76055255e+01  -2.43199538e+01   2.87006560e+01   1.47246120e+01\n",
      "   -8.73165832e+00  -1.87414425e+01  -2.15539036e+01  -1.80968061e+01\n",
      "   -1.38266769e+01   2.07856589e+01  -6.20145646e+00  -2.02071722e+01\n",
      "   -8.92102999e+00  -5.20660948e+00  -1.94188856e+01  -1.44649996e+01\n",
      "   -2.44694675e+01  -2.83380774e+01  -5.82655826e+01   9.99157124e+00\n",
      "   -6.28858878e+00  -2.29266529e+01  -2.67712302e+01  -2.14807502e+01\n",
      "    2.02776141e+01  -2.13086517e+01  -2.32724425e+01   1.41322077e+01\n",
      "   -2.46981605e+01   1.56878779e+01   1.31189340e+01  -1.27660229e+01\n",
      "    4.42535512e+00   2.36161702e+01  -1.05882492e+01   1.04827778e+01\n",
      "   -6.86476148e+00  -6.29832087e+00  -1.01246048e+01   1.18920452e+00\n",
      "   -5.19946160e+00  -1.08105348e+01  -6.42708650e+00  -2.50398511e+01\n",
      "    4.78757756e+00  -2.34820175e+01   1.03695425e+01  -3.77704880e+00\n",
      "   -3.54825391e+00  -9.12688751e+00  -1.01388904e+01  -1.71675362e+01\n",
      "   -2.25364146e+01   2.17172682e+01   2.21897500e+01  -1.64390287e+01\n",
      "   -4.52706829e+00  -4.28220029e+00  -8.32568759e+00  -1.95960693e+01\n",
      "   -1.38816149e+01  -1.07179261e+01  -3.04354925e+00  -1.01268832e+01\n",
      "   -6.22843635e+00  -2.23323807e+01   1.70226126e+01   1.39651059e+01\n",
      "   -2.12522182e+01  -2.05555743e+01  -3.15974196e+01  -1.76007105e+01\n",
      "    1.21411301e+01  -1.01505569e+01  -1.34510971e+01  -7.47408157e+00\n",
      "   -1.27811680e+01   1.08128396e+01   1.52333392e+01  -1.04556514e+01\n",
      "   -1.72393967e+01  -1.41063353e+01  -1.19868143e+01  -1.24184856e+01\n",
      "   -4.11827922e+00   1.84179094e+01  -1.37594678e+01   1.66407897e+01\n",
      "   -1.86773362e+01   3.13543410e+01  -3.87378112e+01  -2.91993845e+01\n",
      "   -5.11585297e+01  -2.20533781e+01  -1.17299806e+01   4.36374708e+01\n",
      "   -4.32382831e+00   4.81947850e+00   1.28348717e+01  -1.35760110e+01\n",
      "   -9.80976716e+00   1.12820827e+01   1.19647033e+01  -1.46680571e+01\n",
      "   -7.84799999e+00   1.25690649e+01   7.59630633e+00  -1.19752903e+01\n",
      "    1.37499918e+01  -1.22760076e+01  -1.23360000e+01  -9.33831750e+00\n",
      "    1.55553329e+01  -1.39874498e+01   1.16820000e+01   1.18364576e+01\n",
      "    9.28600000e+00  -1.25415193e+01   1.16585271e+01  -6.04805429e+00\n",
      "   -1.38629379e+01  -1.30840000e+01  -9.46600000e+00  -9.18400000e+00\n",
      "    1.58404591e+01   9.89200000e+00   8.05454869e+00  -1.09772260e+01\n",
      "    1.07982338e+01  -8.65104253e+00   8.65805035e+00   1.18689568e+01\n",
      "   -1.27479490e+01]\n",
      " [  2.50069107e-01  -2.38685095e+01   1.48990468e+01   1.77668680e+01\n",
      "   -4.63477252e+00  -6.18426480e+00  -1.58522581e+01  -9.98688037e+00\n",
      "   -5.85502067e+00   1.86723365e+01   2.98560578e+01  -2.41556084e+00\n",
      "   -1.10998826e+00  -1.02358569e+01   2.53629145e+01  -1.37537280e+01\n",
      "    2.30310237e+01   1.65380493e+00  -7.16532102e+00   1.29711662e+01\n",
      "   -1.83716734e+01   1.50018431e+01   1.49668611e+01  -1.66198955e+01\n",
      "   -2.49988245e+00   1.98299353e+01   7.21758065e+00  -1.39647014e+01\n",
      "   -5.22051749e+00  -2.17960241e+01  -1.75504214e+01   1.12407647e+01\n",
      "   -1.94776335e+01   2.36163428e+01  -2.38905735e+01  -1.11296022e+01\n",
      "    9.78683614e+00  -2.65907390e+01   1.23117705e+01  -4.59001039e+00\n",
      "    2.07841075e+01   2.82475422e+01  -1.57634699e+01  -3.37926615e+01\n",
      "   -1.91854528e+01   2.14957897e+01   2.04979443e+01   2.66782657e+01\n",
      "   -7.74002682e+00  -9.32618195e+00  -1.50158360e+01  -1.61322516e+01\n",
      "    2.25837050e+01  -1.93841710e+01   1.44962396e+01  -1.66270471e+01\n",
      "    1.63262717e+01  -1.82743580e+01  -3.95677875e+01  -1.14690355e+01\n",
      "   -1.16129617e+01  -1.56489279e+01  -1.68915974e+01  -2.87523497e+01\n",
      "    1.94137248e+01   2.14255497e+01   9.19515588e+00   2.20881368e+01\n",
      "   -1.64410184e+01  -2.10765920e+01  -1.83900454e+01  -1.52433604e+01\n",
      "   -1.26494581e+01  -1.39818992e+01  -4.65130895e+00  -3.55760148e+01\n",
      "    6.78554696e+00  -2.08304016e+01  -1.98068862e+01   2.12024802e+00\n",
      "    2.99612339e+01  -1.98656781e+01  -9.09215133e+00   1.71595303e+01\n",
      "   -1.36784114e+01   2.63800322e+00   1.59885416e+01  -6.14354312e+00\n",
      "   -7.84787223e+00   1.91759986e+01  -1.28582672e+01  -1.11482336e+01\n",
      "   -2.21965899e+01  -1.14809256e+01  -1.65196071e+01   2.75546810e+01\n",
      "   -1.52257996e+01  -1.70287171e+01  -7.28912021e+00  -2.36052825e+01\n",
      "   -1.95542992e+01   2.73937127e+01  -6.15038779e+00  -1.07371602e+01\n",
      "    6.37467543e+00   1.33032354e+01  -9.87699545e+00  -1.74471789e+01\n",
      "   -1.70741725e+01  -1.60105443e+01  -1.76185284e+01  -1.36160649e+01\n",
      "   -1.71915393e+01  -1.55111175e+01  -8.91157923e+00  -5.09993890e+00\n",
      "   -1.67815571e+01  -2.35933569e+01  -2.19826323e+01  -7.89736438e+00\n",
      "   -1.84123095e+01   1.67009667e+01   1.50375460e+01  -1.33398595e+01\n",
      "   -1.63528857e+01  -2.79715917e+01   1.57206521e+01  -1.57923677e+01\n",
      "   -5.93052075e+00   5.34427544e+00  -1.71213553e+01   1.02000081e+01\n",
      "   -1.27366194e+01  -1.24039512e+01  -1.12610344e+01   1.75025526e+00\n",
      "    1.47619563e+01   2.52742466e+01  -8.60414993e+00   1.40940000e+01\n",
      "    9.75199715e+00  -1.08475399e+01  -1.29923881e+01  -1.52940000e+01\n",
      "   -1.05420000e+01   1.84400691e+01  -4.97952205e+00  -3.41193906e+00\n",
      "   -7.10446978e+00  -1.46799961e+01  -1.05760000e+01   1.68946715e+01\n",
      "   -1.16486062e+01  -1.14480136e+01   1.34340789e+01  -1.16139962e+01\n",
      "   -9.34800000e+00  -1.04661073e+01   1.12161764e+01  -8.13560086e+00\n",
      "    9.14566997e+00  -1.25799962e+01   9.16000000e+00  -1.00900000e+01\n",
      "   -9.84260322e+00   9.64399704e+00   1.38206714e+01   1.07961129e+01\n",
      "   -1.08080438e+01  -1.13485102e+01   1.20945793e+01  -1.23485891e+01\n",
      "    1.23946582e+01]\n",
      " [ -8.92152473e-02   1.36793977e+01   8.15672998e+00   2.20924992e+01\n",
      "   -1.03336370e+01  -6.71318026e+00   3.42038352e+00   2.74152091e+01\n",
      "    2.32637691e+01  -7.41524593e+00  -2.45853224e+01  -5.87637391e+00\n",
      "    1.95896962e+01   1.95834253e+01   6.93743981e+00   1.53366730e+01\n",
      "    3.42194090e+00   2.63025279e+01   1.81404070e+01   3.43138171e+00\n",
      "    1.93086442e+01   1.17642842e+01   1.02301679e+01   1.77942548e+01\n",
      "    2.90460425e+01  -4.59820339e+00   2.60760945e+01   8.44053566e+00\n",
      "    1.35202590e+01  -1.72666478e+01   1.79437392e+01   2.01459292e+01\n",
      "   -1.46558681e+01   1.01046015e+01  -7.28238579e+00   2.84280813e+00\n",
      "    9.96973378e+00   1.20527819e+01  -1.28568559e+01   2.84016961e+01\n",
      "    2.48935676e+01   1.10053307e+01  -1.60913038e+01   1.96787029e+01\n",
      "    1.84933294e+01   1.68043371e+01   1.55417491e+01  -4.48044083e+00\n",
      "    2.35905705e+01   7.90720913e+00  -1.29279258e+01   2.39372646e+01\n",
      "   -3.49728526e+01   5.35646583e+00   9.30050038e+00   3.54362672e+01\n",
      "    1.25300384e+01   1.85840767e+01   5.49078010e+01  -1.07997039e+01\n",
      "    2.15509349e+01   1.29903593e+01   3.11440980e+01   1.88884001e+01\n",
      "   -1.68073414e+01  -1.45018430e+01  -1.36479581e+01  -7.16185072e+00\n",
      "    2.37481379e+01   1.34100077e+01   1.30896769e+01  -1.18551848e+01\n",
      "    1.32805666e+01  -5.66077279e+00  -8.61362910e+00   8.02282571e+00\n",
      "   -7.99994141e+00   1.31263830e+01   7.77205516e+00  -2.95091927e+01\n",
      "   -1.85188858e+01   7.38065915e+00  -1.21514792e+01  -9.95518708e+00\n",
      "    1.36830690e+01   7.00378216e+00  -1.29976259e+01  -1.21099192e+01\n",
      "   -1.28671513e+01   1.92522531e+01  -2.64059590e+01   4.09082610e+00\n",
      "   -6.93478282e+00   1.06654359e+01  -1.55578950e+01   2.10233045e+01\n",
      "    1.44089083e+01   1.04281428e+01  -6.85117528e-01   2.09948925e+01\n",
      "    1.64425390e+01  -2.00485557e+01   1.99595304e+01   1.09385692e+01\n",
      "    1.53790331e+01   2.26784465e+01   2.00033615e+01  -1.52295823e+01\n",
      "   -1.56551491e+01   1.33997938e+01   1.47017378e+01   2.59700981e+01\n",
      "    2.19219199e+01   2.69928868e+01   5.88642238e+00  -4.61402334e+01\n",
      "    2.31538878e+01  -9.60305847e+00  -9.50416826e+00   8.74607132e+00\n",
      "    6.92817213e+00   1.14967859e+01  -2.29678245e+01   1.41232436e+01\n",
      "   -1.16963803e+01   9.69591663e+00   8.72635812e+00   4.83726474e+00\n",
      "    2.17353049e+01   2.53232842e+01   3.50710434e+01   2.92171671e+01\n",
      "    2.94176975e+01   2.96693206e+00  -6.86891120e+00  -1.75882230e+01\n",
      "   -2.87898130e+01  -1.73392793e+00  -1.39366804e+01  -9.15597676e+00\n",
      "    9.98155250e+00   1.05676524e+01   7.49355664e+00   1.44779955e+01\n",
      "    9.51156251e+00  -1.41667732e+01  -6.61807373e+00   3.51568212e+00\n",
      "    1.12691764e+01  -9.29200469e+00   9.58168721e+00  -1.23092415e+01\n",
      "    1.20223437e+01   1.14972790e+01   1.08275525e+01  -1.23920468e+01\n",
      "   -8.74000000e+00   7.41201487e+00  -6.97123011e+00  -1.30363203e+01\n",
      "    1.33091051e+01   9.79400000e+00  -8.12998999e+00  -8.71400000e+00\n",
      "   -1.20760451e+01  -1.04406572e+01   1.17694770e+01  -1.08123793e+01\n",
      "    1.06911641e+01  -1.45887698e+01   1.47835546e+01  -1.45887785e+01\n",
      "    1.51835632e+01]\n",
      " [ -1.13195499e-01   1.97285802e+01   2.14200181e+01   3.32547874e+01\n",
      "   -2.94264026e+01  -2.36187030e+01  -2.57749004e+01   1.01962160e+01\n",
      "    3.60120134e+01  -2.86051346e+01  -3.05003300e+01  -2.51437440e+01\n",
      "    2.96819152e+01  -2.21723764e+01  -2.87205934e+01  -2.84737408e+01\n",
      "   -4.65371554e+01  -3.08668534e+00   2.54802442e+01  -2.53687867e+01\n",
      "    2.25619192e+01   1.81351695e+01  -1.31868988e+01   2.54950722e+01\n",
      "    4.05504969e+01  -1.65485449e+01  -2.73880418e+01   1.91487649e+01\n",
      "    1.46037551e+01  -2.33674493e+01  -3.15213761e+01  -2.01779572e+01\n",
      "   -1.70654858e+01  -2.76915244e+01  -1.60622444e+01  -1.69038171e+01\n",
      "   -1.94744940e+01   3.28052969e+01   2.27651976e+01   2.27125878e+01\n",
      "   -1.18095691e+01  -1.50688460e+01  -7.75038067e+00   1.42635727e+01\n",
      "    3.66548196e+01  -1.51455521e+01   1.85356260e+01   2.09061803e+01\n",
      "    1.31915137e+01  -1.92775607e+01  -1.32626732e+01   3.56814303e+01\n",
      "   -1.34542519e+01   1.10285712e+01  -6.39896831e-01   2.17978390e+01\n",
      "    8.55945716e+00   5.90088223e+01   1.05442961e+02   1.98760001e+01\n",
      "   -1.25571061e+01   1.79574460e+01   1.53342629e+01   2.46852888e+01\n",
      "   -2.62033012e+01   2.60656681e+01   3.41120969e+01   1.63499925e+01\n",
      "    3.85381705e+01   2.96200060e+01   3.10246853e+01   3.71610143e+01\n",
      "    3.31022211e+01  -1.59236446e+01   1.80021763e+01   2.75214383e+01\n",
      "   -1.88365215e+01   7.86741161e+00   9.43263149e+00  -3.77668537e+00\n",
      "   -1.30084050e+01   1.45973829e+01  -1.33891212e+01   3.96795136e+01\n",
      "   -2.60017989e+01   2.62740390e+01  -9.55341739e+00   2.87792989e+00\n",
      "   -2.29887654e+01  -8.14073197e+00   1.10507842e+01   1.73494450e+01\n",
      "    3.32660730e+01   2.69904817e+00   7.94432169e+00   1.56661292e+01\n",
      "    1.79463820e+01  -9.32318062e+00   8.79486430e+00   1.41423152e+01\n",
      "    1.11986715e+01  -1.19257870e+01  -1.39790555e+01   1.14787861e+01\n",
      "   -8.39652104e-02   5.99884741e+00  -2.61416072e+01   2.72828521e+01\n",
      "    1.36575663e+01   4.86620722e+01   4.88849257e+01   6.53251734e+00\n",
      "    1.68300654e+01   1.27528177e+01   1.90155520e+01   2.31834455e+01\n",
      "    3.32286631e+01   3.63468176e+01  -1.78275686e+01   1.53092663e+01\n",
      "    1.49986329e+01   1.96858709e+01  -2.49524307e+01   1.74908654e+01\n",
      "   -1.52521071e+01   2.49006923e+01   2.14329239e+01   2.25679245e+01\n",
      "    1.99011113e+01  -4.28609037e+01   7.74342755e+01   3.81738679e+01\n",
      "    8.88191771e+01   3.31877286e+01   2.73272209e+01  -4.32258495e+01\n",
      "   -2.27377276e+01  -3.12475072e+01  -1.97691019e+01   1.04419999e+01\n",
      "   -9.36400000e+00  -1.37487087e+01   1.15635133e+01  -1.16481378e+01\n",
      "   -1.04720000e+01   1.11329215e+01  -1.43464936e+01   1.33856927e+01\n",
      "   -8.20639464e+00  -4.68878809e+00   1.12180008e+01   8.63123734e+00\n",
      "   -1.50636528e+01   1.59438227e+01  -1.56316132e+01  -9.95340504e+00\n",
      "   -8.95600000e+00   1.11342285e+01  -1.15494240e+01   9.66600262e+00\n",
      "   -9.55519812e+00   1.17229553e+01  -9.88797919e+00  -9.46800000e+00\n",
      "   -1.36720000e+01   1.13420000e+01  -1.03381716e+01  -1.94837781e+01\n",
      "    1.93965826e+01  -7.15341986e+00   7.35622437e+00   1.13315520e+01\n",
      "   -1.12207475e+01]]\n",
      "====Iteration 2  ====\n",
      "For  StochasticLogisticRegression  eta:  0.1 Iterations:  5000 Regularization:  L2  : Accuracy of:  0.262376237624\n",
      "confusion matrix\n",
      " [[26  3  1  0  2]\n",
      " [24  0  1  0  4]\n",
      " [35  1  0  0 11]\n",
      " [22  4  0  2 20]\n",
      " [20  1  0  0 25]]\n",
      "MultiClass Logistic Regression Object with coefficients:\n",
      "[[ -3.25361269e-01  -1.62845019e+01  -1.47394847e+01  -2.51041092e+01\n",
      "    2.07179234e+01   1.75088397e+01   2.03322812e+01  -1.41070102e+01\n",
      "   -4.12246162e+01  -1.89322579e+01   2.39784898e+01  -1.12202343e+01\n",
      "   -3.21956032e+01   1.19781961e+01   1.93456736e+01   1.80430775e+01\n",
      "    2.69647356e+01  -1.92282050e+01  -2.23580914e+01   1.70724498e+01\n",
      "   -2.11264379e+01   6.56001162e+00   3.76795084e+00  -1.37077594e+01\n",
      "   -3.68746561e+01  -1.16623733e+01   1.43874045e+01  -1.60164785e+01\n",
      "   -2.32780723e+01   2.71902141e+01   1.73095133e+01  -2.92685296e+01\n",
      "    1.53641590e+01   1.37650061e+01   1.35153343e+01   1.30485519e+01\n",
      "    1.45487482e+01  -1.80905025e+01   3.26979090e+00  -1.56786238e+01\n",
      "   -1.69637821e+01  -9.07684163e+00   1.53048401e+01   9.48382635e+00\n",
      "   -2.65535154e+01   1.07163350e+01  -2.22468649e+01  -1.95562761e+01\n",
      "    2.13427180e+01   1.93819755e+01   2.15158194e+01  -2.32329503e+01\n",
      "    2.00096778e+01   1.82260416e+01  -1.89307949e+01  -1.07934196e+01\n",
      "   -3.31225746e+00  -4.58538763e+01  -7.56938336e+01   1.22533477e+01\n",
      "   -6.34283463e+00  -9.56855471e+00  -8.87944138e+00  -1.80917149e+01\n",
      "    9.52436211e+00  -2.34795030e+01  -1.63569612e+01  -1.05882218e+01\n",
      "   -3.53454593e+01  -3.59976694e+01  -2.24215737e+01  -1.36469631e+01\n",
      "   -2.67376955e+01  -1.10211902e+01  -2.03583269e+01   6.17473771e+00\n",
      "   -1.73578045e+01  -1.46162916e+01  -4.81268309e+00   1.45340584e+01\n",
      "   -1.36144956e+01  -9.97553930e+00  -1.25481013e+01  -2.60876985e+01\n",
      "   -1.05606354e+01   6.98880745e+00  -1.57281552e+01  -1.55033210e+01\n",
      "   -9.23771905e+00   2.63151606e+01  -1.04283554e+01  -5.04085446e+00\n",
      "    9.73289267e+00  -1.73876634e+01  -9.52485363e+00  -3.22478984e+01\n",
      "   -1.57966893e+01  -1.63854280e+01   7.79804100e+00   1.52857749e+01\n",
      "   -7.26353954e+00  -1.39308213e+01  -2.35462574e+01  -1.67110169e+01\n",
      "   -1.33395436e+01  -1.62303020e+01   1.60088485e+01  -2.69915934e+01\n",
      "   -3.72355098e+00  -2.10858439e+01  -2.40990546e+01  -1.68522394e+01\n",
      "    1.26822322e+01  -1.25982312e+01  -5.13744009e+00  -1.18593737e+01\n",
      "   -3.07816885e+01  -1.53640075e+01   1.59870591e+01  -9.38503453e+00\n",
      "    1.28564780e+01  -2.35563741e+01   2.26098055e+01  -1.28144205e+01\n",
      "   -1.59337434e+01  -1.86764581e+01  -1.27763830e+01  -1.99874630e+01\n",
      "   -2.93846316e+01  -1.88724837e+01  -4.38622225e+01   5.89464384e+00\n",
      "   -5.21806491e+01  -3.61481227e+01  -2.60780213e+01  -5.34332292e+00\n",
      "    6.57910704e+00   2.14113092e+00   2.02989766e+01  -1.11937707e+01\n",
      "   -1.18319971e+01  -1.11856392e+01   1.41860458e+01   1.51009705e+01\n",
      "    8.97200000e+00  -1.45243318e+01  -1.33573659e+01  -1.16604573e+01\n",
      "    1.48424620e+01   1.04339707e+01  -7.13916015e+00   3.06616134e+00\n",
      "   -6.90233320e+00  -9.19634117e+00  -1.03420232e+01   9.33700311e+00\n",
      "   -7.68800000e+00  -1.38857966e+01   1.32624353e+01  -1.07660609e+01\n",
      "   -9.18407329e+00   1.30248608e+01  -8.93800000e+00  -9.51403164e+00\n",
      "    8.86600592e+00  -1.08640000e+01  -1.12821964e+01   1.32565060e+01\n",
      "   -1.38198673e+01   9.95663270e+00  -1.15959940e+01   1.12846643e+01\n",
      "   -1.10440256e+01]\n",
      " [  6.87944747e-02   6.20267382e+00  -1.79255524e+01  -3.42911552e+01\n",
      "    1.15433437e+01  -1.56507615e+01   2.01036085e+01   4.85685900e+00\n",
      "   -5.12265078e+00   2.29282622e+01   1.99693275e+01   1.14705618e+01\n",
      "   -2.12094074e+01  -9.31007697e+00  -6.41639934e+00   4.71776112e+00\n",
      "   -2.48542515e+00   5.94345496e+00  -3.09899071e+01   3.35058636e+01\n",
      "   -5.93080684e+00  -1.70854987e+01  -1.52845688e+01  -2.34127678e+01\n",
      "   -2.16907704e+01   1.99244328e+01  -8.43861914e+00  -1.16953526e+01\n",
      "   -1.95828840e+01   3.16336201e+01   2.08892454e+01   9.34722475e+00\n",
      "    1.90534175e+01  -1.02301177e+01   1.98578733e+01   1.95523317e+01\n",
      "    1.30812475e+01  -1.92222587e+01   8.34384173e+00  -3.07559920e+01\n",
      "   -3.05953477e+01  -2.30979199e+01  -9.10767148e+00   6.82936943e+00\n",
      "   -1.69324956e+01  -2.02290331e+01  -1.36665658e+01  -2.93436750e+01\n",
      "   -1.56227875e+01  -2.26865956e+00  -1.11376618e+01  -2.66207555e+01\n",
      "   -2.48292970e+01  -2.71621087e+01  -2.71866682e+01  -1.45843963e+01\n",
      "   -3.01558858e+01  -2.97871408e+01  -5.93214426e+01   6.21239912e+00\n",
      "   -1.17174348e+01  -2.22053033e+01  -2.80406646e+01  -3.05497060e+01\n",
      "   -1.06136916e+01  -1.51104770e+01  -2.08200427e+01   1.84979190e+01\n",
      "   -3.01572960e+01  -1.30377112e+01  -1.27813240e+01  -1.43772619e+01\n",
      "   -1.37122627e+01  -4.63000843e+00  -2.98801712e+00  -1.03520207e+01\n",
      "   -1.59032194e+01   1.25158147e+01   1.25468717e+01   1.66073456e+01\n",
      "   -1.80670548e+01   6.67127181e+00   8.49967767e+00  -2.70923814e+01\n",
      "    1.10209328e+01  -1.94150293e+01  -1.12561335e+01   1.39549164e+01\n",
      "    1.27921817e+01  -9.98537312e+00   2.29581867e+01  -9.72718444e+00\n",
      "   -1.13603771e+01  -8.75938990e+00   1.58952478e+01  -2.68862965e+01\n",
      "   -2.07733539e+01   1.80712820e+01  -1.09183381e+01  -1.97845357e+01\n",
      "   -2.10276359e+01  -9.18967921e+00  -1.70516740e+01  -7.27201984e+00\n",
      "   -1.12011592e+01  -2.02079769e+01   1.41897690e+01   2.03222949e+01\n",
      "    1.37953832e+01  -2.21383272e+01  -2.10646499e+01  -1.19620305e+01\n",
      "    1.10898341e+01  -1.98424189e+01  -7.54403757e+00   2.34327424e+01\n",
      "   -1.42458468e+01  -1.22600838e+01   8.63227220e+00  -2.77694929e+01\n",
      "   -1.85207899e+01  -1.41433298e+01  -1.33663772e+01  -2.31425130e+01\n",
      "    2.26679248e+01  -6.11254169e+00  -1.15875279e+01   7.89048196e+00\n",
      "   -2.12679861e+01   2.92188922e+01  -4.53867610e+01  -3.40816307e+01\n",
      "   -4.83804373e+01  -1.63356699e+01  -8.55091369e+00   3.28897494e+01\n",
      "    8.19607607e+00  -9.81845148e+00   5.68297852e+00  -1.52319999e+01\n",
      "    1.12410285e+01   1.29583364e+01  -7.63463647e+00  -1.52699339e+01\n",
      "    9.20407269e+00   1.66706557e+01  -8.45316225e+00  -1.23357007e+01\n",
      "    1.14136574e+01  -1.11589524e+01  -9.74399992e+00   5.64409271e+00\n",
      "   -4.58634597e+00  -1.04460388e+01   8.60483324e+00  -8.86000000e+00\n",
      "    9.94000000e+00  -1.07162440e+01   1.02650385e+01  -1.25439144e+01\n",
      "    1.08147089e+01   1.19697341e+01  -8.37400000e+00  -9.73400000e+00\n",
      "    1.34633350e+01  -9.96570933e+00  -1.39605653e+01  -1.19285572e+01\n",
      "    1.22633516e+01   1.19896525e+01  -1.17688580e+01   1.14129925e+01\n",
      "   -1.13381980e+01]\n",
      " [  2.43344915e-01  -2.04781267e+01   1.63171942e+01   4.05208481e+00\n",
      "    1.26388810e+01   1.56962590e+01   2.07397819e+00  -1.64235697e+01\n",
      "   -1.75406937e+01   2.88589101e+01   3.01784878e+01   1.32815903e+01\n",
      "   -7.39269731e+00   8.41749190e+00   1.54806642e+01  -3.02915124e+00\n",
      "    1.78620518e+01  -9.67772843e+00   1.02943226e+00   1.23262921e+01\n",
      "   -1.91023105e+01   1.12302993e+01   1.16654326e+01  -1.18735370e+01\n",
      "   -5.07691233e+00   1.47706320e+01   1.34158433e+01  -6.27233016e+00\n",
      "    1.33440117e+01  -2.46023547e+01   4.10988391e+00   1.42052999e+01\n",
      "   -5.66237330e+00   1.91464255e+01  -2.83805336e+01  -2.39930017e+01\n",
      "   -1.05695566e+01  -2.60734082e+01   4.97770586e+00  -9.72017523e+00\n",
      "    1.72685013e+01   1.57534365e+01   2.02150133e+01  -3.48322930e+01\n",
      "   -1.16871710e+01  -6.54242106e+00  -6.26424643e+00   2.78983248e+01\n",
      "   -1.18551087e+01  -1.23805484e+01   1.98760423e+01  -1.26381539e+01\n",
      "    1.56920326e+01  -1.67571238e+01   1.63046309e+01  -2.07355935e+01\n",
      "    1.63856874e+01  -2.33490483e+01  -2.60061381e+01  -1.44667534e+01\n",
      "    4.31259988e+00  -7.95925923e+00   5.85348633e+00  -3.66612977e+01\n",
      "   -1.21673508e+01   2.11725472e+01   2.90371714e+01  -1.12813398e+01\n",
      "   -1.95691568e+01  -1.11656422e+01  -8.20343701e+00  -1.99109556e+01\n",
      "   -4.85228528e+00  -1.66843677e+01  -1.43945089e+01  -3.35742259e+01\n",
      "   -5.23713068e+00  -1.78298727e+01  -2.55112966e+01  -1.56235282e+01\n",
      "    1.34888394e+01  -7.69635477e+00  -6.90340605e-01   1.65148811e+01\n",
      "   -1.16012432e+01   4.37602606e+00   1.94989045e+01   1.85964868e+01\n",
      "   -2.03266421e+01  -1.75634605e+01  -1.49362927e+01  -9.09279699e+00\n",
      "    1.46716872e+01  -6.60487111e+00  -1.91343032e+01   2.98437753e+01\n",
      "   -1.31602954e+01  -1.66695186e+01   4.03688336e+00   7.55781526e+00\n",
      "   -1.16164993e+01   2.45975160e+01   2.29860467e+01  -9.74417122e+00\n",
      "    1.69439678e+01   1.00580044e+01  -7.71781552e+00  -1.40741967e+01\n",
      "   -1.50967845e+01  -9.17820224e+00  -1.91628302e+01  -1.70245281e+01\n",
      "   -2.80943993e+01  -2.03607082e+01  -1.92670557e+01  -9.48729442e+00\n",
      "   -2.08331317e+01  -1.64732614e+01  -9.32606711e+00   2.85608010e+00\n",
      "   -2.06671441e+01  -7.76000084e+00   1.11841634e+01   9.03784252e+00\n",
      "   -3.26476741e+00  -1.33785988e+00   8.52341732e+00  -1.32009952e+01\n",
      "   -8.20956973e+00   1.67005798e+01  -2.50454955e+01  -9.76396838e-01\n",
      "   -1.28248084e+01  -1.10611269e+01   6.84559673e+00  -1.86091078e+01\n",
      "    3.37731368e+00   1.33027578e+00   8.50375022e+00   1.05224136e+01\n",
      "   -7.78800559e+00   9.53922022e+00  -1.17882833e+01   7.22241425e+00\n",
      "   -8.48565697e+00  -7.50141236e+00   2.02491963e+01  -9.83597815e+00\n",
      "   -2.00558733e+01  -1.22261832e+01  -1.28820000e+01  -3.54787069e+00\n",
      "    9.40139888e+00  -9.63633428e+00  -6.32031968e+00   6.73599887e+00\n",
      "   -9.98400000e+00  -9.09229206e+00   9.83763697e+00  -1.02120001e+01\n",
      "   -8.53065502e+00  -1.95841810e+01  -1.09100017e+01  -1.02260000e+01\n",
      "    1.12000005e+01   1.09897898e+01   1.72617373e+01  -6.43984312e+00\n",
      "   -1.40508120e+01  -1.30375347e+01   1.39288796e+01  -1.14843353e+01\n",
      "    1.13276803e+01]\n",
      " [ -7.83105580e-02   1.16580103e+01  -1.64869391e+01   2.65558014e+01\n",
      "   -6.22030529e+00  -3.14894154e+00   1.32737651e+01   2.97245168e+01\n",
      "    2.22902315e+01  -1.22734648e+01  -3.35895476e+01  -1.42081027e+01\n",
      "    1.97834260e+01   1.96490767e+01   1.12276736e+01  -6.04830699e+00\n",
      "    2.09993362e+01   2.59766209e+01   2.16932715e+01  -1.56070190e+01\n",
      "    1.85133480e+01  -1.48582715e+01   1.59446424e+01   1.23521022e+01\n",
      "    2.79028063e+01  -1.03828010e+01   2.21118485e+01  -5.17460787e+00\n",
      "    2.97854059e+01  -1.19423386e+01   1.02859531e+01   2.73599936e+01\n",
      "   -2.21795764e+01  -1.98133271e+01   1.27284659e+01   7.67066406e+00\n",
      "   -4.01932524e+00   1.60538207e+01   1.18562093e+01   2.31386152e+01\n",
      "    1.65256988e+01   1.14071892e+01   6.26539584e+00   2.46829743e+01\n",
      "    2.49188926e+01   2.03480561e+01  -8.98796676e+00  -1.68276055e+01\n",
      "    1.27889415e+01   3.33182273e+00  -1.71972395e+01   2.20549238e+01\n",
      "   -2.87363641e+01   8.90468603e+00  -5.16063205e-02   2.68344152e+01\n",
      "   -9.42468914e+00   1.71520034e+01   5.20163533e+01  -2.01594803e+01\n",
      "    1.36823004e+01  -1.51314910e+01   2.32299102e+01   4.58905050e+00\n",
      "   -1.19225118e+01  -2.33318711e+01  -1.99136988e+01  -2.06591730e+01\n",
      "    2.88999168e+01   3.44847950e+01  -4.59973948e+00   1.15507310e+01\n",
      "    1.10990025e+01   1.34714093e+01  -1.02206291e+01   1.02339148e+01\n",
      "    2.20734807e+01   2.07702848e+01   1.45897620e+01  -2.73110641e+01\n",
      "    1.04318275e+00  -2.00764243e+01   1.66741384e+01   1.55268646e+00\n",
      "   -8.26057059e+00  -1.00913056e+01   1.57593798e+01   3.35911845e+00\n",
      "    5.14208019e+00  -1.08351703e+01  -1.58047710e+01   5.51819499e+00\n",
      "   -7.60720144e+00  -3.00594864e+00  -9.61100079e+00  -1.36340698e+00\n",
      "   -7.06578823e+00  -1.04253219e+01   1.40587003e+01   1.16209444e+01\n",
      "    1.02559177e+01  -4.29308632e+00   2.97327331e+01   1.81534731e+01\n",
      "    1.91527252e+01   1.59105424e+01  -6.13774306e+00  -2.42394956e+01\n",
      "    1.08947741e+01   1.39550175e+01   1.18887193e+01   2.20045181e+01\n",
      "   -1.17891033e+01   1.58355863e+01  -1.54041559e+01  -3.36099768e+01\n",
      "    2.43230294e+01  -1.68255530e+01  -2.35266496e+01  -1.14186177e+01\n",
      "    8.83729767e+00  -1.17270987e+01   8.82652617e+00   1.75502325e+01\n",
      "    1.35262473e+01   9.39852997e+00  -9.54684339e+00  -1.51474200e+01\n",
      "    2.18363297e+01   1.04186682e+01   2.90018850e+01   1.37602538e+01\n",
      "    1.81628649e+01   1.61355227e+01  -1.49798553e+01   3.15223115e+00\n",
      "   -1.25218229e+01  -1.68520867e+01   6.84535074e+00   1.15056407e+01\n",
      "    1.28464821e+01  -8.35598423e+00  -1.47724491e+01   1.58977801e+01\n",
      "    9.78201577e+00  -1.60081064e+01  -7.24824443e+00  -1.54559272e+01\n",
      "    1.23578611e+01   1.10962063e+01  -1.16382126e+01  -8.53859983e+00\n",
      "   -1.00877044e+01   7.65004857e+00   1.56237795e+01  -1.31921386e+01\n",
      "   -8.23600000e+00  -9.45796605e+00  -1.03463445e+01   9.15626502e+00\n",
      "   -8.72857558e+00  -3.68806689e+00   8.87000000e+00   1.07740000e+01\n",
      "    1.07940000e+01  -9.17366336e+00  -1.87745803e+01   9.45553593e+00\n",
      "   -9.02184649e+00  -1.67360421e+01   1.70557316e+01  -2.00918095e+01\n",
      "    2.01094989e+01]\n",
      " [  1.36969930e-01   2.12872504e+01   2.28836996e+01   3.07205997e+01\n",
      "   -1.85621863e+01  -1.36373474e+01  -1.45012491e+01   2.16311133e+01\n",
      "    3.47070185e+01  -4.10899371e+01  -3.95171462e+01  -2.45039390e+01\n",
      "    1.91715236e+01  -1.47816944e+01  -2.59932944e+01  -3.02122057e+01\n",
      "   -3.76017814e+01   9.91498715e+00   1.85110324e+01  -1.77298522e+01\n",
      "    2.71150820e+01   1.05726175e+01   1.53935845e+01   2.27950192e+01\n",
      "    3.45542184e+01  -2.44643575e+01  -1.21659899e+01   1.23998775e+01\n",
      "    7.07770934e+00  -2.52292069e+01  -2.82812050e+01   1.33902760e+01\n",
      "   -9.79365089e+00  -2.67581188e+01  -1.02966788e+01  -1.77414311e+01\n",
      "   -2.26332879e+01   2.76394526e+01   3.91523107e+00   2.53567606e+01\n",
      "   -1.70982802e+01  -1.77491216e+01   9.43013304e+00   1.74093631e+01\n",
      "    2.42122143e+01  -2.46949845e+01   1.85539015e+01   1.72945611e+01\n",
      "    2.43404700e+00  -9.96456768e+00  -1.55918403e+01   3.76657184e+01\n",
      "    1.02822186e+01   1.78719656e+01   1.78272170e+01   1.70960953e+01\n",
      "   -6.00762902e+00   6.56149964e+01   1.03542705e+02   2.57664721e+01\n",
      "    1.14045098e+01   2.03639497e+01   2.29848918e+01   3.47898515e+01\n",
      "   -1.62869162e+01   2.62175994e+01   2.70287713e+01   7.00978747e+00\n",
      "    4.84454420e+01   2.42835597e+01   3.01539828e+01   2.94247308e+01\n",
      "    3.49174175e+01   6.75003094e+00   1.17944233e+01   3.51380490e+01\n",
      "   -8.89394076e+00   1.48893178e+01  -1.09514037e+01  -8.50926049e+00\n",
      "    1.70996231e+01   1.79521170e+01  -1.09908236e+01   4.59706995e+01\n",
      "   -2.30399566e+01   2.78837388e+00  -1.92686097e+01   1.53231215e+01\n",
      "   -8.51825543e+00  -1.57130564e+01  -5.35790843e-01   1.25881873e+01\n",
      "    1.81891682e+00  -2.29333688e+01   1.99651667e+01   1.28721408e+01\n",
      "   -4.39708889e+00   1.29883996e+01  -1.27405711e+01   1.85146910e+01\n",
      "    1.46435917e+01   1.01906948e+01  -7.68775209e+00   1.53664102e+01\n",
      "   -1.26810179e+01   2.09623185e+01  -2.37961335e+01   2.34998402e+01\n",
      "   -2.84916220e+00   3.48178042e+01   4.42888672e+01   2.00699740e+01\n",
      "    1.30995434e+01   1.16025569e+01   9.15478517e+00   2.67124756e+01\n",
      "    2.52097904e+01   3.71325823e+01  -7.70928801e+00   1.85452635e+01\n",
      "    1.71744737e+01   2.36148343e+01  -2.49590942e+01  -6.42637814e+00\n",
      "   -1.49141263e+01   1.76463189e+01   2.40364164e+01   2.51451077e+01\n",
      "    3.01384984e+01  -4.08582641e+01   6.80439704e+01   3.48507807e+01\n",
      "    8.13542227e+01   3.76533203e+01   2.55128059e+01  -2.73757219e+01\n",
      "   -1.31598763e+01  -3.56708913e+01  -1.27093160e+01  -8.79150239e+00\n",
      "   -1.13264657e+01  -9.14776998e+00   1.10207080e+01  -1.27897577e+01\n",
      "    9.76945462e+00   1.25572730e+01  -1.09468492e+01  -8.76807518e+00\n",
      "    1.03278943e+01   1.40040000e+01  -8.97835015e+00   7.89594406e+00\n",
      "   -1.27006240e+01   1.28348417e+01  -1.47878726e+01  -7.49599910e+00\n",
      "   -1.02240000e+01   1.49350396e+01  -1.42960696e+01   9.80200000e+00\n",
      "   -9.52503007e+00   8.06007689e+00   1.04980000e+01   9.51800000e+00\n",
      "   -1.30379972e+01  -7.69591097e+00   1.14408012e+01  -1.14905689e+01\n",
      "    1.20115388e+01  -8.33613850e+00   8.50710843e+00   8.80157541e+00\n",
      "   -8.36260548e+00]]\n",
      "====Iteration 0  ====\n",
      "For  LineSearchLogisticRegression  eta:  0.001 Iterations:  150 Regularization:  L1 and L2  : Accuracy of:  0.326732673267\n",
      "confusion matrix\n",
      " [[ 0  0 15  6  0]\n",
      " [ 0  0 15 13  0]\n",
      " [ 0  2 24 20  0]\n",
      " [ 0  0 16 42  0]\n",
      " [ 0  0  7 42  0]]\n",
      "MultiClass Logistic Regression Object with coefficients:\n",
      "[[ -1.44812532e-04  -2.87727557e-03  -2.07547930e-03  -5.01791074e-03\n",
      "   -1.70773841e-03  -7.58378564e-04  -7.58280912e-04  -4.68586996e-03\n",
      "   -7.12889919e-03  -6.86069778e-04   5.61428566e-03   2.25862125e-03\n",
      "   -5.29979224e-03   3.11896346e-03   3.14496616e-03   3.05170464e-03\n",
      "    3.60644548e-03  -4.55792371e-03  -3.44306173e-03  -1.52532263e-03\n",
      "   -4.60049934e-03  -1.48710374e-03  -1.39709998e-03  -2.32901937e-03\n",
      "   -7.59194572e-03  -1.73961535e-03  -8.85384417e-04  -3.85120774e-03\n",
      "   -3.80148024e-03   1.71933834e-03   2.78527674e-03  -3.54591584e-03\n",
      "   -1.12902167e-03  -1.13292764e-03  -9.10704657e-04   2.66404857e-03\n",
      "    3.41482168e-03  -3.17090195e-03  -1.72431125e-03  -4.29136026e-03\n",
      "   -3.15687505e-03  -1.08678857e-03  -1.03078744e-03  -1.66558324e-03\n",
      "   -5.08956421e-03  -2.20530109e-03  -4.66850655e-03  -3.35015058e-03\n",
      "   -1.51547530e-03  -1.97060365e-03  -8.00334815e-04  -5.77763194e-03\n",
      "    4.18001269e-03   2.08047713e-03  -2.83807362e-03  -2.17666788e-03\n",
      "   -4.46556216e-04  -8.86339650e-03  -1.43460645e-02  -1.15366783e-03\n",
      "   -2.06858721e-03  -1.92328180e-03  -1.75592241e-03  -2.51778830e-03\n",
      "   -1.44619664e-03  -4.23989371e-03  -3.99504526e-03  -2.52974496e-03\n",
      "   -7.20330330e-03  -6.92173964e-03  -6.42270324e-03  -2.53172327e-03\n",
      "   -6.67056008e-03  -1.88726334e-03  -4.15433700e-03  -3.31044457e-03\n",
      "   -3.26049057e-03  -3.88343226e-03  -1.17939351e-03  -9.97521207e-04\n",
      "   -3.51756176e-03  -1.06485013e-03  -1.41742499e-03  -4.32309270e-03\n",
      "   -1.22999722e-03  -7.42868057e-04  -2.88893504e-03  -2.06189806e-03\n",
      "   -2.12591531e-03   2.86573691e-03  -7.79616949e-04  -1.01413907e-03\n",
      "   -1.41967647e-03  -3.53763191e-03  -1.58432428e-03  -7.05132176e-03\n",
      "   -2.91026960e-03  -2.43994300e-03  -9.72113940e-04  -2.78631379e-03\n",
      "   -2.84756300e-03  -3.60431985e-03  -6.25849368e-03  -3.35517236e-03\n",
      "   -3.64276107e-03  -3.72978659e-03  -9.22881801e-04  -3.84691271e-03\n",
      "   -1.25573167e-03  -5.58209673e-03  -3.90205923e-03  -3.22436558e-03\n",
      "    1.44293463e-03  -3.50003645e-03  -1.28802768e-03  -2.78145953e-03\n",
      "   -6.69642087e-03  -3.36942248e-03  -1.23040674e-03  -2.75859770e-03\n",
      "   -1.79523555e-03  -3.81303415e-03   4.76152258e-03  -2.79015651e-03\n",
      "   -2.50539463e-03  -1.73614243e-03  -3.98899822e-03  -2.92314536e-03\n",
      "   -4.49515957e-03  -3.24613866e-03  -9.65370415e-03  -3.67281559e-03\n",
      "   -1.01940058e-02  -5.66647849e-03  -4.89392029e-03   1.00258868e-03\n",
      "   -7.55599842e-03   8.09751725e-03  -4.62419408e-04  -1.44374189e-03\n",
      "   -1.58751780e-03  -1.49685695e-03  -1.55420557e-03  -5.39997972e-04\n",
      "   -1.73153304e-03  -2.38792262e-03  -2.61113751e-03  -9.39945913e-04\n",
      "   -9.88207190e-04  -1.34534635e-03  -1.18231318e-03  -2.13577727e-03\n",
      "   -1.32656379e-03  -1.74353635e-03  -1.40725571e-03  -1.34964254e-03\n",
      "   -1.50357738e-03  -2.37021106e-03  -6.53161971e-04  -1.49819671e-03\n",
      "   -1.53893848e-03  -1.05841155e-03  -1.36614374e-03  -1.51816698e-03\n",
      "   -1.51411075e-03  -1.58009848e-03  -1.88516703e-03  -7.72002018e-04\n",
      "   -2.27743965e-03  -1.62700961e-03  -1.60406868e-03  -9.58593332e-04\n",
      "   -2.06518449e-03]\n",
      " [ -1.33187852e-04  -2.03808715e-03  -3.05612060e-03  -4.63521393e-03\n",
      "   -4.00852417e-04  -1.04099610e-03   2.17339059e-03  -2.17985262e-03\n",
      "   -3.66676631e-03  -1.10524988e-04   3.88740314e-03  -9.89542165e-06\n",
      "   -2.51265875e-03  -1.84099832e-03  -1.59153630e-03  -6.36833034e-04\n",
      "   -1.17086655e-03  -2.68814379e-03  -3.51015819e-03   3.72471043e-03\n",
      "   -1.88171352e-03  -1.67560588e-03  -1.58464029e-03  -4.07356328e-03\n",
      "   -4.05350394e-03   2.60298460e-03  -6.99273846e-04  -2.66041719e-03\n",
      "   -2.80837367e-03   4.58846147e-03   2.98925244e-03  -8.93263859e-04\n",
      "   -1.56993760e-04  -2.37175416e-03  -6.17013608e-04   3.52583034e-03\n",
      "    2.61106566e-03  -1.85033245e-03   2.07688750e-03  -4.06804023e-03\n",
      "   -3.56435085e-03  -3.04051697e-03  -4.96598467e-04  -2.07376134e-03\n",
      "   -2.60924757e-03  -2.47701445e-03  -3.24452255e-03  -2.90702279e-03\n",
      "   -3.52644901e-03  -8.79200709e-04  -1.96382774e-03  -4.31628884e-03\n",
      "   -2.41686630e-03  -2.54911765e-03  -3.52800326e-03  -2.57026244e-03\n",
      "   -4.62747964e-03  -5.65939673e-03  -1.07718198e-02  -1.16461861e-03\n",
      "   -2.94053183e-03  -3.71630999e-03  -3.87467636e-03  -3.74300142e-03\n",
      "   -1.97717791e-03  -3.77512980e-03  -4.64007783e-03  -1.80361459e-03\n",
      "   -5.64099741e-03  -3.63283632e-03  -3.45902959e-03  -2.75066359e-03\n",
      "   -3.72038398e-03  -8.51696404e-05  -1.44282775e-03  -1.79071348e-03\n",
      "   -1.40133691e-03  -1.91982942e-03  -1.69885892e-03  -5.95358877e-05\n",
      "   -2.96142965e-03  -2.24263442e-03  -1.16006911e-03  -4.05779048e-03\n",
      "   -1.55374168e-03  -3.70015415e-03  -1.55094608e-03  -1.17319032e-03\n",
      "   -5.14993488e-04  -1.22628718e-03  -1.66838175e-03  -2.37209672e-03\n",
      "   -4.00210542e-03  -1.76117214e-03   1.62058952e-03  -4.05137703e-03\n",
      "   -1.92100779e-03  -6.47130634e-05  -1.57493649e-03  -3.21771289e-03\n",
      "   -3.18881828e-03  -2.91112078e-03  -2.25776949e-03  -1.79483049e-03\n",
      "   -2.08385145e-03  -3.97482955e-03  -1.79433774e-03  -2.36357091e-03\n",
      "   -2.52971580e-03  -4.11419669e-03  -4.95359307e-03  -2.92775432e-03\n",
      "   -1.54848913e-03  -3.61624811e-03  -2.57210953e-03  -1.15998533e-03\n",
      "   -2.97367390e-03  -8.49326376e-04  -8.73429229e-04  -4.76138489e-03\n",
      "   -2.77294184e-03  -3.21140448e-03  -7.14976691e-04  -3.16181237e-03\n",
      "   -1.58158728e-03  -2.74322434e-03  -2.57610245e-03  -1.94741428e-03\n",
      "   -4.35370212e-03   3.20032872e-03  -5.92728221e-03  -4.17434524e-03\n",
      "   -8.42792630e-03  -3.48298252e-03  -1.23136471e-03   4.29397311e-03\n",
      "   -6.58515262e-03   1.56274134e-02  -8.29155572e-04  -1.76231629e-03\n",
      "   -1.33150843e-03  -1.19267896e-03  -1.33649836e-03  -1.84366178e-03\n",
      "   -1.50808380e-03  -7.92864529e-04  -1.38480069e-03  -1.99081194e-03\n",
      "   -8.44270702e-04  -1.63775456e-03  -1.42913844e-03  -1.40123237e-03\n",
      "   -1.09587095e-03  -1.89070385e-03  -1.29603913e-03  -1.06995039e-03\n",
      "   -1.32532462e-03  -2.45897896e-03  -5.04729941e-04  -1.38288155e-03\n",
      "   -1.68374146e-03  -1.71981687e-03  -1.46280810e-03  -1.34976571e-03\n",
      "   -6.76029129e-04  -1.68246298e-03  -1.40186820e-03  -1.97943606e-03\n",
      "   -8.48031544e-04  -7.96355059e-04  -2.03066438e-03  -8.38140757e-04\n",
      "   -2.12850121e-03]\n",
      " [ -3.72432984e-05  -1.97560694e-03  -9.40538914e-04  -1.15559432e-03\n",
      "   -3.23913709e-04  -3.36561635e-04  -1.94474116e-03  -1.35905603e-03\n",
      "   -1.42849693e-03  -2.28284527e-04   2.71355578e-03  -1.52652160e-05\n",
      "   -1.24551441e-03  -9.92191599e-04  -9.77934459e-04  -1.84802613e-03\n",
      "    1.73739717e-03  -2.29562516e-03  -1.20602527e-03  -1.42020074e-03\n",
      "   -1.88554409e-03  -1.17220923e-03  -1.07058671e-04  -1.30409789e-03\n",
      "   -1.24290527e-03   1.30593426e-03  -7.71810518e-04  -1.09081326e-03\n",
      "   -6.52419378e-04  -2.47541465e-03  -1.43143434e-03  -2.51350001e-04\n",
      "   -5.51582406e-04   1.10511972e-03  -2.21021204e-03  -2.13031322e-03\n",
      "   -1.63607887e-03  -3.17288859e-03  -1.48939221e-03  -9.14890184e-04\n",
      "   -8.95273846e-05   8.77815312e-04  -1.32152734e-03  -1.53860997e-03\n",
      "   -2.55845231e-03  -4.12374582e-04   1.86912363e-03   3.20732046e-03\n",
      "   -1.35814454e-03  -1.13601375e-03  -2.02978760e-04  -1.48630008e-03\n",
      "    7.94148531e-04  -2.12672066e-03  -1.15254593e-04  -2.28066159e-03\n",
      "    1.55878253e-03  -3.02660760e-03  -3.66382085e-03  -2.29212873e-03\n",
      "   -9.90802752e-04  -1.14153622e-03  -8.15037986e-04  -2.86931004e-03\n",
      "   -5.52869230e-04   1.85327021e-03   2.07272221e-06  -8.33022829e-04\n",
      "   -1.71851652e-03  -1.32612819e-03  -2.06707089e-03  -3.47783393e-03\n",
      "   -1.16347737e-03  -2.17640408e-03  -1.28193966e-03  -3.23551155e-03\n",
      "   -5.77942787e-04  -2.34677861e-03  -2.10094189e-03  -1.73171926e-03\n",
      "   -2.02430504e-04  -1.22246750e-03  -7.45577038e-04  -5.11988390e-04\n",
      "   -1.07013618e-03  -9.85555653e-04  -5.94812170e-04  -9.09996786e-08\n",
      "   -1.45947358e-03  -1.48873204e-03  -1.03065960e-03  -1.28396053e-03\n",
      "   -1.38228514e-03  -4.45605722e-04  -2.17968094e-03   3.39346018e-03\n",
      "   -1.83000986e-03  -1.71590328e-03  -1.48146956e-03  -1.89909269e-03\n",
      "   -1.76192895e-03  -2.37992027e-04   2.05362848e-03  -1.02970733e-03\n",
      "    2.24210046e-03  -2.50978838e-04  -8.44876457e-04  -2.73118549e-04\n",
      "   -2.45732972e-03  -1.93755793e-03  -1.33820740e-03  -1.71297816e-03\n",
      "   -3.06081277e-03  -1.78939210e-03  -1.79301521e-03  -2.36754386e-03\n",
      "   -1.50370339e-03  -3.04220688e-03  -1.98855191e-03  -1.91155916e-03\n",
      "   -1.79070249e-03  -1.95165398e-04  -5.42696029e-05  -1.25737044e-03\n",
      "    1.89576966e-03  -2.55739993e-03   1.24731299e-03  -1.57460292e-03\n",
      "   -2.85318689e-04  -5.74996297e-04  -2.02877859e-03  -2.05628998e-03\n",
      "   -2.03987627e-03  -1.57020058e-03  -1.02809245e-03  -3.07984234e-03\n",
      "   -1.15797950e-03   4.01078067e-03  -1.36832844e-03  -1.09764015e-03\n",
      "   -1.07097192e-03  -9.48988908e-04  -7.59324910e-04  -1.58369943e-03\n",
      "   -6.80719181e-04  -5.78013102e-04  -9.04649078e-05  -8.58986928e-04\n",
      "   -1.96614432e-03  -1.43800434e-03  -1.15738836e-03  -2.01249564e-04\n",
      "   -1.12301435e-03  -1.19217688e-03  -6.08838827e-04  -1.13024547e-03\n",
      "   -9.43755184e-04  -1.33461551e-03  -6.22523883e-04  -8.38239752e-04\n",
      "   -1.07484473e-03  -1.21272282e-03  -1.00121664e-03  -1.01723037e-03\n",
      "   -9.89430009e-04  -9.96653246e-04  -5.62130300e-04  -1.01573844e-03\n",
      "   -1.03092741e-03  -1.21665019e-03  -7.10121514e-04  -1.06660563e-03\n",
      "   -9.49813845e-04]\n",
      " [  5.99193371e-06  -8.59601955e-04  -1.34060131e-03   2.52190002e-03\n",
      "    2.00973193e-03  -1.47567660e-03  -9.83600074e-05   2.75171555e-03\n",
      "    2.54081310e-03  -1.17021532e-03  -3.45260204e-03  -1.96729139e-03\n",
      "   -5.40832796e-04  -1.33607741e-03  -6.90891643e-04  -3.45190839e-04\n",
      "    2.38887596e-03   3.85833180e-03   2.10955184e-03  -4.20670590e-04\n",
      "   -1.13154135e-05  -2.14187171e-03  -1.63116932e-03  -9.05978955e-04\n",
      "    2.69534767e-03  -9.50684002e-04  -5.89435299e-04  -9.78913734e-04\n",
      "    1.82353110e-03  -3.53627983e-04  -6.15408739e-04  -2.34387283e-04\n",
      "   -1.38178520e-03  -1.91945246e-03  -2.60740657e-04   1.83163522e-03\n",
      "    2.32271117e-03  -3.29447723e-04  -1.27478421e-03   2.85142368e-03\n",
      "    2.16622257e-03  -5.24948611e-04  -2.64534415e-03   2.85799715e-03\n",
      "    2.64858011e-03   3.55565796e-03   1.21139663e-03  -1.04299597e-03\n",
      "    3.13698187e-03   2.13223981e-03  -9.83870162e-04   1.55858602e-03\n",
      "   -1.80205688e-03  -8.52033486e-04  -7.53702466e-04   2.74824355e-03\n",
      "   -2.41404545e-04   2.74769165e-03   6.99014210e-03  -6.73464096e-04\n",
      "   -2.01004639e-04  -1.09633224e-03   2.25397662e-03  -7.64239885e-05\n",
      "   -1.04131699e-03  -1.50596627e-03  -1.77285358e-03  -1.21234035e-03\n",
      "    2.37849062e-03   3.04164401e-03   2.38582307e-03  -9.65912409e-04\n",
      "   -7.35501198e-04  -1.37992656e-03   1.13875365e-03  -1.70459476e-04\n",
      "    2.17034987e-03   2.68373290e-03   2.41399890e-03  -1.99284233e-03\n",
      "   -6.78547411e-04  -1.12354291e-03  -1.52806572e-03  -1.31282589e-03\n",
      "    1.94577066e-03  -1.15190013e-03  -1.05841050e-03  -2.48788681e-03\n",
      "   -9.84495491e-04  -2.56209862e-04  -1.72840376e-03  -1.81507150e-03\n",
      "   -1.08742162e-03  -6.23086958e-04  -1.47641320e-03   2.24380671e-03\n",
      "   -5.38142229e-04  -9.16421908e-04  -1.77067262e-03  -1.07602501e-03\n",
      "   -1.01785993e-04  -1.40775653e-03   3.09090075e-03  -5.12367122e-04\n",
      "    2.30398097e-03   2.45914521e-03   2.07291766e-03  -8.45278705e-04\n",
      "   -1.04874753e-03  -7.40775925e-04   1.16796692e-03   1.00723268e-03\n",
      "   -5.18928156e-04   3.38127087e-03  -9.94185595e-04  -3.60526784e-03\n",
      "    2.36162183e-03  -2.59654344e-03  -1.71235256e-03  -6.11820490e-04\n",
      "    1.82728526e-03  -8.17545714e-04  -1.45667615e-03   2.07205952e-03\n",
      "   -2.45800843e-04  -1.35335782e-03  -6.92381314e-04  -6.91255448e-04\n",
      "    1.93851417e-03   3.08089676e-03   3.23191448e-03   2.88003897e-03\n",
      "    2.95169314e-03   2.64411882e-03  -1.18241716e-03  -5.39937095e-04\n",
      "   -1.76768000e-03  -3.01019065e-03  -7.39716106e-04  -9.15324416e-04\n",
      "   -8.41680363e-04  -8.75621743e-04  -1.45853849e-03  -5.81829868e-04\n",
      "   -1.11573106e-03  -1.44687551e-03  -1.07261438e-03  -1.40798371e-03\n",
      "   -6.73208763e-04  -9.94844032e-04  -1.01939898e-03  -1.17930446e-03\n",
      "   -9.98859510e-04  -9.85945117e-04  -7.88452092e-04  -1.40135309e-03\n",
      "   -1.03130423e-03  -9.82881507e-04  -1.12466656e-03  -1.06189935e-03\n",
      "   -9.95893263e-04  -7.09925694e-04  -1.09191116e-03   1.12534993e-03\n",
      "   -1.05158318e-03  -1.20976036e-03  -1.25988372e-03  -5.74470125e-04\n",
      "   -1.49683262e-03  -1.24672478e-03  -8.24976733e-04  -1.72944293e-03\n",
      "   -3.11547687e-04]\n",
      " [  3.65528679e-05   2.35898771e-03   2.43510986e-03   4.40906595e-03\n",
      "   -4.12574906e-03  -2.36830301e-03  -3.09201666e-03  -3.54650033e-04\n",
      "    5.14755750e-03  -4.04492880e-03  -6.26190189e-03  -3.75061440e-03\n",
      "    4.43390423e-03  -2.19489242e-03  -3.20464160e-03  -3.29958224e-03\n",
      "   -6.48267381e-03   1.78058322e-03   3.04720236e-03  -3.52584669e-03\n",
      "    2.64514065e-03   2.30954460e-03  -1.50329074e-03   3.22012680e-03\n",
      "    4.90007813e-03  -3.28613185e-03  -2.51098808e-03   2.68823336e-03\n",
      "   -8.26432827e-04  -4.36877459e-03  -3.42983193e-03  -1.30809515e-03\n",
      "   -2.62940545e-03  -1.53415849e-03  -1.34052867e-03  -3.99922062e-03\n",
      "   -4.42003835e-03   3.88586761e-03  -4.51210662e-04   2.99084258e-03\n",
      "   -1.05909112e-03  -2.14645851e-03  -1.17371441e-03  -2.04575118e-03\n",
      "    3.74248355e-03  -3.44274480e-03   1.84840237e-03  -3.80547615e-04\n",
      "   -1.92051902e-03  -2.62784048e-03  -2.84221190e-03   5.47610619e-03\n",
      "   -2.94116504e-03  -4.27798830e-04   2.06920024e-03   1.68523223e-03\n",
      "   -1.79896707e-03   9.83167809e-03   1.41131854e-02   6.64634854e-04\n",
      "   -1.32164006e-03   2.43335845e-03  -4.50028919e-04   3.95272448e-03\n",
      "   -1.70382434e-03   3.27725199e-03   4.22581206e-03  -4.50026875e-04\n",
      "    6.87325681e-03   4.13830086e-03   5.28421449e-03   5.06903504e-03\n",
      "    5.64844484e-03  -1.01814422e-03   1.30526924e-03   4.44775557e-03\n",
      "   -1.97813736e-03   1.90199699e-03  -1.74659584e-03  -1.08955993e-03\n",
      "    1.83775329e-03  -9.52004482e-04  -1.62691918e-03   4.72069283e-03\n",
      "   -3.31912885e-03   2.17195537e-03  -5.00030010e-04  -4.73867738e-04\n",
      "   -1.43080818e-03  -3.06114417e-03  -1.31293978e-03   1.32683121e-03\n",
      "    3.27283063e-03  -1.30646240e-03  -6.11937198e-04   1.97578759e-03\n",
      "    1.76152518e-03  -1.47338081e-03  -5.86901506e-04   3.84342439e-03\n",
      "    2.67420119e-03   2.62430760e-03  -1.59590933e-03  -4.12651891e-04\n",
      "   -2.27361021e-03   1.37886029e-03  -3.20021146e-03   1.64291702e-03\n",
      "    2.24962433e-03   6.36033932e-03   4.57817024e-03   2.78115964e-03\n",
      "   -1.02398469e-03   1.13884784e-03   2.01048521e-03   5.34662289e-03\n",
      "    4.77511702e-03   5.02234209e-03  -7.56306440e-04   3.66068781e-03\n",
      "   -6.90707846e-04   2.41976336e-03  -4.94951788e-03   1.32500742e-03\n",
      "   -3.41738288e-03   3.69542805e-03   1.40523220e-03   1.94138565e-03\n",
      "    2.91887680e-03  -5.06693468e-03   9.71467330e-03   4.00443266e-03\n",
      "    1.17609957e-02   4.97571651e-03   3.03985231e-03  -6.76541550e-03\n",
      "   -3.75005025e-03  -1.35557286e-02  -2.40981842e-03  -8.45787966e-04\n",
      "   -1.17365145e-03  -1.50267471e-03  -8.91481326e-04  -1.18062203e-03\n",
      "   -1.05871777e-03  -1.10418393e-03  -1.24750060e-03  -8.11922387e-04\n",
      "   -1.22341963e-03  -5.28346891e-04  -1.09419854e-03  -1.25997469e-03\n",
      "   -1.49359432e-03  -4.49882602e-04  -1.96590381e-03  -8.25701603e-04\n",
      "   -1.14782323e-03   2.05642382e-03  -2.04419971e-03  -1.16692264e-03\n",
      "   -9.67465111e-04  -1.27673614e-03  -1.00944447e-03  -1.08190025e-03\n",
      "   -1.55732427e-03  -6.32885905e-04  -1.09607504e-03  -1.70588704e-03\n",
      "   -4.41092362e-04  -1.10971199e-03  -1.03815531e-03  -1.14491953e-03\n",
      "   -9.69291271e-04]]\n",
      "====Iteration 1  ====\n",
      "For  LineSearchLogisticRegression  eta:  0.001 Iterations:  150 Regularization:  L1 and L2  : Accuracy of:  0.227722772277\n",
      "confusion matrix\n",
      " [[ 0  0  3 15  0]\n",
      " [ 0  0 10 31  0]\n",
      " [ 0  0  5 47  0]\n",
      " [ 0  0  3 41  0]\n",
      " [ 0  0  3 44  0]]\n",
      "MultiClass Logistic Regression Object with coefficients:\n",
      "[[ -1.70204922e-04  -2.95998307e-03  -2.19892748e-03  -4.30413590e-03\n",
      "   -1.11572225e-03  -6.71920787e-04  -3.78167420e-04  -4.18487357e-03\n",
      "   -6.69398031e-03  -7.80836940e-04   4.15798831e-03  -5.42894391e-04\n",
      "   -5.12829872e-03  -2.10080399e-04   3.76631749e-03   2.64867257e-03\n",
      "    3.61241704e-03  -3.96114588e-03  -2.96625265e-03  -6.31416044e-04\n",
      "   -4.21057198e-03  -1.16777768e-03  -1.75306681e-03  -2.28848232e-03\n",
      "   -6.65734712e-03  -1.08578030e-03  -2.18724367e-04  -3.79565962e-03\n",
      "   -3.34020467e-03   2.51409043e-03  -3.21222209e-04  -3.62193844e-03\n",
      "   -5.63412137e-04  -1.28386174e-03  -1.18645597e-03   2.11574716e-03\n",
      "    2.26171145e-03  -2.78647772e-03  -1.37784840e-03  -3.11317445e-03\n",
      "   -3.26351913e-03  -1.85689774e-03  -9.78235076e-04  -1.25222470e-03\n",
      "   -4.05981854e-03  -2.39658848e-03  -3.57520080e-03  -3.03162570e-03\n",
      "   -7.52600039e-04  -1.30105099e-03  -7.00791913e-04  -5.10808236e-03\n",
      "    2.33663384e-03   2.35388380e-03  -3.08817533e-03  -2.35232737e-03\n",
      "   -5.82080429e-04  -7.44263756e-03  -1.23876102e-02  -2.24149383e-04\n",
      "   -8.70666735e-04  -2.11960664e-03  -1.57429046e-03  -4.11124849e-03\n",
      "   -1.38569039e-03  -3.53468741e-03  -3.94407924e-03  -2.22957062e-03\n",
      "   -6.03657529e-03  -6.47810827e-03  -5.00378169e-03  -2.94977080e-03\n",
      "   -5.40112545e-03  -1.55963413e-03  -3.49406909e-03  -2.30417306e-03\n",
      "   -2.99612774e-03  -3.04364311e-03  -9.22734924e-04  -2.01971432e-03\n",
      "   -3.15571431e-03  -9.55242207e-04  -1.63907963e-03  -5.05351694e-03\n",
      "   -6.01974488e-04  -7.79252318e-05  -1.81508010e-03  -2.03381314e-03\n",
      "   -2.77425662e-03   2.03542850e-03  -1.18720008e-03  -1.66914622e-03\n",
      "   -1.76408269e-03  -2.59855421e-03  -2.88928038e-03  -5.27667735e-03\n",
      "   -2.70239616e-03  -2.07348213e-03  -6.92506375e-04  -1.69619168e-03\n",
      "   -3.04587429e-03  -2.42283298e-03  -4.42060833e-03  -2.24431595e-03\n",
      "   -3.17617282e-03  -2.98533607e-03  -5.79410078e-04  -2.80288158e-03\n",
      "   -1.41444736e-03  -4.61059828e-03  -2.73954024e-03  -2.75415749e-03\n",
      "   -1.31363417e-03  -3.18630236e-03  -1.19560996e-03  -2.48907542e-03\n",
      "   -4.83776618e-03  -2.95251695e-03  -8.95389623e-04  -2.72663246e-03\n",
      "   -1.64094436e-03  -3.16269708e-03   4.15156151e-03  -2.12613913e-03\n",
      "   -2.14402707e-03  -2.17363434e-03  -2.84290291e-03  -2.73374986e-03\n",
      "   -4.05356858e-03  -3.32254418e-03  -7.80484177e-03  -2.92060073e-03\n",
      "   -8.65017448e-03  -3.93388020e-03  -2.87606406e-03  -1.01039953e-03\n",
      "   -8.67941319e-03   1.04309701e-02  -1.03411592e-03  -1.30096761e-03\n",
      "   -1.46544811e-03  -1.12666901e-03  -1.02164199e-03  -6.59740065e-04\n",
      "   -1.38084715e-03  -1.72515416e-03  -1.90916104e-03  -8.86228737e-04\n",
      "   -9.07241566e-04  -1.12662987e-03  -9.03280746e-04  -1.81674887e-03\n",
      "   -1.03722689e-03  -1.35344328e-03  -1.29462581e-03  -1.05261972e-03\n",
      "   -1.20618793e-03  -2.04744090e-03  -5.11967492e-04  -1.14240676e-03\n",
      "   -1.37624337e-03  -7.22632756e-04  -1.11811120e-03  -1.24161971e-03\n",
      "   -1.17392544e-03  -1.27370121e-03  -1.73560524e-03  -5.32749531e-04\n",
      "   -1.98512153e-03  -1.15709577e-03  -1.43514737e-03  -6.21251984e-04\n",
      "   -1.88553174e-03]\n",
      " [ -1.24794762e-04  -1.55302732e-03  -3.14054036e-03  -4.26915920e-03\n",
      "   -5.25459051e-04  -1.05745563e-03   3.88837968e-03  -1.96998474e-03\n",
      "   -3.07932780e-03   2.32715042e-03   3.09574810e-03   2.50268182e-03\n",
      "   -3.75804876e-03  -2.25152394e-03  -1.45031997e-03  -1.30494010e-03\n",
      "   -1.25450766e-03  -2.12077528e-03  -3.05301348e-03   2.69601119e-03\n",
      "   -1.44326939e-03  -2.41938349e-03  -1.42309200e-03  -3.34256897e-03\n",
      "   -4.61173255e-03   2.04669134e-03  -1.95672150e-04  -1.27836737e-03\n",
      "   -1.35175186e-03   3.93097330e-03   2.39584585e-03  -4.93208517e-04\n",
      "   -6.11795582e-04  -1.46560965e-03  -1.46156185e-03   2.78590695e-03\n",
      "    2.90159972e-03  -2.19243779e-03  -8.77683058e-04  -5.35560502e-03\n",
      "   -2.63515825e-03  -2.37730330e-03  -1.24260696e-03  -1.22186799e-03\n",
      "   -3.16736651e-03  -1.21352233e-03  -4.50236956e-03  -1.81020561e-03\n",
      "   -2.27185911e-03  -3.25469125e-04  -1.00642376e-03  -4.80063675e-03\n",
      "   -2.22373795e-03  -1.76549685e-03  -3.53476982e-03  -2.69282682e-03\n",
      "   -4.72180726e-03  -5.55425702e-03  -9.84247795e-03  -9.01022631e-04\n",
      "   -2.91368865e-03  -3.37165431e-03  -3.56846394e-03  -3.93268595e-03\n",
      "   -1.53560798e-03  -3.56935012e-03  -4.04512081e-03  -1.15483560e-03\n",
      "   -6.49527199e-03  -3.14051503e-03  -2.94646446e-03  -3.75110809e-03\n",
      "   -3.12929456e-03   3.61556547e-03  -1.41147728e-03  -2.44186385e-03\n",
      "   -1.92209289e-03  -2.97407105e-03  -1.15300798e-03   1.84166850e-03\n",
      "   -3.41418669e-03  -2.23400556e-03  -1.31690877e-03  -3.45376555e-03\n",
      "   -2.51185328e-03  -3.20012567e-03  -8.04631444e-04  -2.44144837e-03\n",
      "   -5.86338621e-04  -1.26972278e-03  -1.42434234e-03  -2.23391882e-03\n",
      "   -3.37156580e-03  -1.64180831e-03   3.05520963e-03  -3.08522674e-03\n",
      "   -2.82663897e-03  -7.33008582e-05  -1.16755187e-03  -3.39135989e-03\n",
      "   -3.06299956e-03  -3.29823317e-03  -1.71919099e-03  -1.34446440e-03\n",
      "   -2.21255929e-03  -3.83707486e-03  -1.96351066e-03  -2.19970579e-03\n",
      "   -1.98376783e-03  -3.83196874e-03  -4.60811241e-03  -3.16841660e-03\n",
      "   -1.42508717e-04  -3.39698574e-03  -3.05179173e-03  -2.33178793e-03\n",
      "   -3.18417719e-03  -5.06442509e-04  -1.04595960e-03  -4.69156248e-03\n",
      "   -2.86607432e-03  -3.31578191e-03  -9.39727253e-04  -2.68588672e-03\n",
      "   -1.23437596e-03  -2.31955319e-03  -2.46288142e-03  -2.45355485e-03\n",
      "   -3.39004591e-03   2.45717388e-03  -6.18198419e-03  -4.00278639e-03\n",
      "   -7.74392467e-03  -3.27267227e-03  -2.02261447e-03   2.04203238e-03\n",
      "   -8.62813681e-03   1.04464794e-02  -9.90377409e-04  -1.88690791e-03\n",
      "   -1.54511947e-03  -8.53382387e-04  -1.07335830e-03  -1.53248984e-03\n",
      "   -1.13775789e-03  -1.28336097e-03  -1.20879401e-03  -1.82631382e-03\n",
      "   -9.31658843e-04  -1.54235660e-03  -1.39218432e-03  -1.55417475e-03\n",
      "   -8.43171567e-04  -1.85852778e-03  -1.31614131e-03  -8.69599741e-04\n",
      "    1.33188340e-03  -2.67688833e-03   2.34479475e-03  -1.16735553e-03\n",
      "   -1.67085523e-03  -1.30302069e-03  -1.39270064e-03  -1.28308139e-03\n",
      "   -8.47549006e-04  -1.35029136e-03  -1.67116453e-03  -1.65266422e-03\n",
      "   -1.02427267e-03  -8.03834120e-04  -1.87346650e-03  -1.06557817e-03\n",
      "   -1.67765709e-03]\n",
      " [ -8.65975227e-05  -2.66729440e-03  -1.35712510e-03  -1.56111889e-03\n",
      "   -2.62619916e-04  -2.23868194e-05  -2.00880085e-03  -1.66177773e-03\n",
      "   -1.88397865e-03  -4.73145691e-04   2.58487117e-03  -6.24253540e-04\n",
      "   -1.21191747e-03  -1.57428214e-03  -1.09398193e-03  -1.17766821e-03\n",
      "   -2.42302091e-04  -1.68484240e-03  -1.48456824e-03  -1.02000090e-03\n",
      "   -2.33954595e-03  -1.41648118e-03  -7.37726384e-04  -1.58380421e-03\n",
      "   -1.11597645e-03   1.68541232e-03  -6.46561571e-04  -2.15238260e-03\n",
      "   -1.30806547e-03  -2.50946560e-03  -9.82833018e-04   1.24811506e-03\n",
      "   -1.27640058e-03  -3.64216791e-04  -1.55453567e-03  -1.64126553e-03\n",
      "   -1.13509814e-03  -2.96518877e-03  -1.24657313e-03   1.04505995e-03\n",
      "    7.07280779e-06   1.06799166e-04  -8.59079154e-04  -2.24599600e-03\n",
      "   -2.13286658e-03  -9.93461011e-04   1.57395174e-03   2.51114440e-03\n",
      "   -1.20755504e-03  -1.18705955e-03  -6.55894144e-04  -1.55082725e-03\n",
      "    2.66010065e-03  -2.38266883e-03  -8.11268645e-04  -4.07640152e-03\n",
      "   -2.93041998e-04  -2.20517523e-03  -4.27060967e-03  -2.35698549e-03\n",
      "   -1.92967670e-03  -1.69701392e-03  -1.96053765e-03  -2.34404687e-03\n",
      "   -1.20162067e-03  -4.25978362e-05   5.40036441e-04  -8.07223960e-04\n",
      "   -3.85553309e-04  -5.50693130e-04  -1.44785788e-03  -3.29192753e-03\n",
      "   -1.90911784e-03  -2.18272146e-03  -1.76144633e-03  -3.54720928e-03\n",
      "   -8.44430244e-04  -2.80085812e-03  -3.42007059e-03  -1.85508802e-03\n",
      "    2.80326963e-03  -1.71712913e-03  -7.54267839e-04  -1.09702028e-03\n",
      "   -1.68723733e-03  -1.14394954e-03  -7.72102479e-05  -3.81576556e-04\n",
      "   -8.76366798e-04  -6.20850359e-04  -4.91898020e-04  -1.36447727e-03\n",
      "   -1.50475385e-03  -1.00601166e-03  -2.66827172e-03  -9.49581706e-05\n",
      "   -2.11895735e-03  -2.55173402e-03  -1.74675263e-03  -2.85244130e-03\n",
      "   -1.63786136e-03   2.06820341e-03  -5.96913992e-04  -1.33433895e-03\n",
      "    1.63591388e-03  -5.16171600e-04  -1.06084200e-03  -1.84217875e-03\n",
      "   -2.48949177e-03  -2.42140999e-03  -2.48160444e-03  -1.42146508e-03\n",
      "   -1.60374954e-03  -1.98464741e-03  -1.90810528e-03  -1.60094584e-03\n",
      "   -2.66656093e-03  -2.54040275e-03  -1.68778914e-03  -1.73704926e-03\n",
      "   -2.03054238e-03  -1.14958392e-03  -7.75035205e-04  -1.45567873e-03\n",
      "    4.11619673e-04  -1.80428173e-03  -7.93962796e-04  -1.44534251e-03\n",
      "   -1.19516363e-03  -7.52957921e-05  -2.25764482e-03  -1.76253854e-03\n",
      "   -2.32678304e-03  -1.33975070e-03  -1.67574292e-03  -4.44924523e-03\n",
      "   -4.54703423e-03   1.09495315e-02  -1.26939370e-03  -7.66785913e-04\n",
      "   -1.09806377e-03  -1.47679319e-03  -7.37486466e-04  -1.53352501e-03\n",
      "   -9.71775986e-04  -5.07601953e-04  -1.69076036e-04  -1.09280376e-03\n",
      "   -1.76530062e-03  -1.49972998e-03  -1.24931041e-03  -2.62875343e-04\n",
      "   -1.06415402e-03  -1.12127186e-03  -8.85805406e-04  -1.01870727e-03\n",
      "   -1.01977127e-03  -1.53636035e-03  -4.56428860e-04  -9.29246813e-04\n",
      "   -1.10902936e-03  -1.13806263e-03  -1.04405054e-03  -1.00810289e-03\n",
      "   -1.20883501e-03  -1.25297212e-03  -3.59144809e-04  -1.09403231e-03\n",
      "   -1.06679882e-03  -1.08198474e-03  -9.55669866e-04  -1.17561928e-03\n",
      "   -9.70133427e-04]\n",
      " [  3.04656281e-05  -5.83441359e-04  -1.07076417e-03   2.25851119e-03\n",
      "   -4.76116636e-04  -1.83676252e-03  -1.07516454e-03   1.85097594e-03\n",
      "    2.69277428e-03  -1.31055726e-03  -3.14596758e-03  -1.22780754e-03\n",
      "    2.21262440e-03  -6.98093000e-04  -1.13471176e-03  -1.25959851e-03\n",
      "   -6.29719403e-05   2.81823303e-03   2.70092208e-03  -1.14357527e-03\n",
      "    1.97190208e-03  -1.95332288e-03  -1.27235500e-03  -1.04076624e-03\n",
      "    2.80325751e-03  -6.77255307e-04  -1.64994895e-03  -6.56927668e-04\n",
      "   -3.47383616e-04  -8.11178348e-04  -2.01816522e-04   4.73734488e-05\n",
      "   -1.79055358e-03  -1.26854697e-03   1.64763160e-03  -2.90087503e-04\n",
      "   -3.84770113e-04  -2.50428571e-04  -1.12415136e-03   2.97665047e-03\n",
      "    2.48699031e-03   2.23370383e-03  -1.96998860e-03   2.60921289e-03\n",
      "    3.19753069e-03   3.13294011e-03   2.25830373e-03  -1.13586376e-03\n",
      "    1.90261468e-03   1.44909246e-03  -1.59532366e-03   2.64482639e-03\n",
      "   -2.71646816e-03  -1.29653256e-03  -1.06785415e-04   3.38308950e-03\n",
      "   -1.56102686e-04   2.34509825e-03   6.75332309e-03  -1.20093059e-03\n",
      "   -9.43364885e-04  -1.01462974e-03   2.52970364e-03  -2.16189368e-04\n",
      "   -9.68144264e-04  -1.54325446e-03  -1.62753808e-03  -1.84885714e-03\n",
      "    1.97499720e-03   2.67387703e-03  -1.36572567e-03  -7.59442592e-04\n",
      "   -5.21905758e-04  -2.19650038e-03   1.62468697e-03   2.44140044e-03\n",
      "    1.86070325e-03   2.82381902e-03   2.52161294e-03  -1.80428113e-03\n",
      "   -7.12264302e-04  -1.31313336e-03  -1.72449638e-03   1.19739677e-03\n",
      "    1.58820778e-03  -1.25333222e-03  -9.96619850e-04  -1.06206914e-03\n",
      "   -1.36227192e-03  -1.04940795e-03  -1.94559049e-03  -1.61540002e-03\n",
      "   -1.14737165e-03  -1.70825077e-04  -6.54260902e-04  -1.28033325e-04\n",
      "    1.69593815e-03  -1.24730164e-03  -1.32872874e-03  -2.12063781e-04\n",
      "   -4.72618464e-04  -1.69636690e-03   2.82460778e-03  -7.08441507e-04\n",
      "    2.48403337e-03  -3.85367804e-04   2.08613425e-03  -9.09169072e-04\n",
      "   -1.23286470e-03  -1.31390828e-04  -1.51462610e-04   1.52967612e-03\n",
      "   -1.46465021e-03   2.63315726e-03  -2.42619273e-04  -2.68082548e-03\n",
      "    2.34610415e-03  -3.23050713e-03  -1.85304043e-03  -4.59673283e-04\n",
      "    1.47161093e-03  -6.54188895e-04  -2.09099603e-03  -2.06927128e-04\n",
      "   -7.96099300e-04  -1.41585431e-03  -5.87785114e-04  -3.29715972e-04\n",
      "    2.16299584e-03   2.37976220e-03   3.28815019e-03   1.51071800e-03\n",
      "    3.28413584e-03  -2.43407667e-04  -1.18015788e-03   2.43990722e-03\n",
      "   -5.85247742e-04  -6.38196390e-03  -1.18783958e-03  -9.21779769e-04\n",
      "   -4.86777703e-04  -8.11856875e-04  -1.61354963e-03  -4.46123992e-04\n",
      "   -1.06857089e-03  -1.43388077e-03  -1.12322165e-03  -1.13022160e-03\n",
      "   -7.71054552e-04  -8.55387801e-04  -9.48038081e-04  -8.26361434e-04\n",
      "   -1.26149042e-03  -8.66109113e-04  -6.85035392e-04  -1.41134812e-03\n",
      "    1.01264592e-03  -7.68887942e-04  -1.16349011e-03  -1.10645658e-03\n",
      "   -8.09257467e-04  -1.04266412e-03  -9.25159059e-04  -9.27617089e-04\n",
      "   -7.67620052e-04  -1.15170157e-03  -1.06265435e-03  -1.15229641e-03\n",
      "   -7.62177743e-04  -1.44149016e-03  -4.73014175e-04  -1.53486682e-03\n",
      "   -3.62336166e-04]\n",
      " [  5.39510119e-05   2.74954717e-03   3.16077538e-03   4.60361407e-03\n",
      "   -3.69962894e-03  -2.10250278e-03  -3.36521272e-03   2.49136823e-03\n",
      "    5.33373441e-03  -3.77677009e-03  -5.17179843e-03  -3.54511559e-03\n",
      "    4.86667741e-03  -1.29004556e-03  -3.64501602e-03  -2.72648075e-03\n",
      "   -5.78060297e-03   1.32186481e-03   2.38501545e-03  -3.23605965e-03\n",
      "    2.44516363e-03   3.04002875e-03  -7.31684015e-04   3.21387232e-03\n",
      "    4.99080134e-03  -3.76389075e-03  -2.17399786e-03   2.67266215e-03\n",
      "   -7.55878903e-04  -4.10000293e-03  -3.55241169e-03  -1.56089148e-03\n",
      "   -1.30984065e-03  -2.11738617e-03  -1.43934912e-03  -3.73630186e-03\n",
      "   -4.00471842e-03   3.78554644e-03  -2.67701668e-04   2.15954107e-03\n",
      "   -1.71932777e-03  -2.69592911e-03  -1.71834096e-03  -2.02199669e-03\n",
      "    2.72839786e-03  -3.05421147e-03   2.43890051e-03   1.15270504e-03\n",
      "   -2.57987980e-03  -3.02269830e-03  -2.41872651e-03   5.01350091e-03\n",
      "   -2.06533736e-03  -4.87285371e-04   2.87306831e-03   3.52839531e-03\n",
      "   -1.13456137e-03   8.84181981e-03   1.39837551e-02  -2.01374669e-04\n",
      "    1.41439830e-03   3.02934417e-03   2.18822774e-03   5.34122163e-03\n",
      "   -1.23290103e-03   3.62101551e-03   4.14428885e-03   1.63143697e-03\n",
      "    6.31650830e-03   3.61240192e-03   5.62389342e-03   5.88887437e-03\n",
      "    5.45995541e-03  -1.25902766e-03   1.85044446e-03   3.71029583e-03\n",
      "   -8.05476072e-04   2.84957333e-03  -1.13747635e-03  -3.07349012e-04\n",
      "   -6.68216306e-04   1.34597234e-03  -7.88200669e-04   4.76028371e-03\n",
      "   -2.16684587e-03  -2.67623757e-04  -2.15043041e-03   1.67448161e-03\n",
      "   -8.69176633e-04  -3.06063000e-03  -1.34979863e-03   2.07903632e-03\n",
      "    3.43344075e-03  -1.71902182e-03   1.61118053e-03   3.27618614e-03\n",
      "    2.34833451e-03  -3.37989518e-04  -1.09629487e-03   3.33100510e-03\n",
      "    3.31744420e-03   1.97220295e-03  -1.46261642e-03  -7.37023425e-04\n",
      "   -1.80363255e-03   2.70897396e-03  -3.01768731e-03   3.18470157e-03\n",
      "    2.27037894e-03   5.82442056e-03   5.03911238e-03   2.57579955e-03\n",
      "   -1.55472522e-03   2.21818051e-03   1.60667853e-03   4.49549894e-03\n",
      "    5.27609002e-03   4.83867359e-03  -9.59398631e-04   3.46733441e-03\n",
      "    1.22876355e-03   3.35610529e-03  -3.39950835e-03   1.57027921e-03\n",
      "   -2.61350713e-03   2.98812163e-03   1.98531115e-03   1.99069311e-03\n",
      "    3.11353313e-03  -4.19519331e-03   9.62639440e-03   4.17070010e-03\n",
      "    1.09982419e-02   4.77604784e-03   3.27806228e-03  -5.53309484e-03\n",
      "   -3.41780991e-03  -1.64239470e-02  -1.22566660e-03  -8.60599745e-04\n",
      "   -1.07568554e-03  -1.21490560e-03  -1.07486850e-03  -1.35722659e-03\n",
      "   -9.68624822e-04  -8.62360406e-04  -1.28141538e-03  -7.20750544e-04\n",
      "   -1.13258086e-03  -5.74988518e-04  -1.01115071e-03  -1.20261186e-03\n",
      "   -1.42579458e-03  -6.56145395e-04  -1.46973473e-03  -1.01003633e-03\n",
      "   -1.10201635e-03   2.28045707e-03  -2.29507436e-03  -1.11093148e-03\n",
      "   -9.54871951e-04  -1.33016175e-03  -1.06197291e-03  -1.05693291e-03\n",
      "   -1.42664099e-03  -5.65845002e-04  -9.92409466e-04  -1.24561739e-03\n",
      "   -8.17417706e-04  -1.12617647e-03  -1.00372697e-03  -1.07412507e-03\n",
      "   -9.69549223e-04]]\n",
      "====Iteration 2  ====\n",
      "For  LineSearchLogisticRegression  eta:  0.001 Iterations:  150 Regularization:  L1 and L2  : Accuracy of:  0.227722772277\n",
      "confusion matrix\n",
      " [[ 0  0 12 16  0]\n",
      " [ 0  0  9 24  0]\n",
      " [ 0  0  9 46  0]\n",
      " [ 0  0  8 37  0]\n",
      " [ 0  0  3 38  0]]\n",
      "MultiClass Logistic Regression Object with coefficients:\n",
      "[[ -1.44225276e-04  -3.33486704e-03  -3.04518539e-03  -5.60797778e-03\n",
      "   -1.01260571e-03  -1.73726292e-03  -2.68366497e-04  -4.68382336e-03\n",
      "   -7.64919589e-03  -7.22779143e-04   5.72122328e-03  -9.99795304e-04\n",
      "   -5.86772467e-03  -8.21347472e-05   3.90133074e-03   2.75618142e-03\n",
      "    4.03843744e-03  -5.28924332e-03  -4.62016236e-03  -1.03100019e-03\n",
      "   -5.33383697e-03  -2.17913769e-03  -3.30662689e-03  -2.50584426e-03\n",
      "   -7.75084008e-03  -2.80630723e-03  -1.49122678e-03  -2.88162656e-03\n",
      "   -3.05868609e-03   3.36859967e-03  -1.31049363e-03  -5.41987882e-03\n",
      "   -1.08649788e-04  -6.28931261e-04  -1.68849149e-03  -4.04729374e-04\n",
      "   -3.12344074e-04  -3.49920269e-03  -2.35015033e-03  -4.91599102e-03\n",
      "   -2.70946920e-03  -1.06709982e-03  -3.29350894e-04  -2.59426089e-03\n",
      "   -5.35921585e-03  -1.37944578e-03  -5.05001517e-03  -3.68843199e-03\n",
      "   -1.02420145e-03  -1.32790302e-03  -4.57390991e-04  -5.25761045e-03\n",
      "    4.58320170e-03   2.99589090e-03  -4.12736214e-03  -3.67570515e-03\n",
      "   -9.98284519e-04  -9.69795183e-03  -1.58888160e-02  -1.43350333e-03\n",
      "   -1.33741218e-03  -2.62112604e-03  -2.11777254e-03  -3.77259581e-03\n",
      "   -1.50235334e-03  -4.43277043e-03  -4.77594667e-03  -2.09597337e-03\n",
      "   -7.36409082e-03  -7.77620534e-03  -6.13289654e-03  -4.16998848e-03\n",
      "   -5.64473417e-03  -2.48966903e-03  -3.94235688e-03  -3.41191359e-03\n",
      "   -3.74493727e-03  -2.89512219e-03  -5.74126166e-04  -1.53278144e-03\n",
      "   -2.73003979e-03  -1.83572429e-03  -1.86387275e-03  -5.77582051e-03\n",
      "   -9.68884647e-04  -4.67649722e-04  -2.62300741e-03  -3.22228283e-03\n",
      "   -2.60068256e-03  -4.27233356e-04   2.61286601e-03  -2.27025595e-03\n",
      "   -1.95578851e-03  -3.69361010e-03  -2.50375560e-03  -7.33449487e-03\n",
      "   -4.01065186e-03  -2.01171775e-03   4.22854166e-03  -2.81584491e-03\n",
      "   -3.69161589e-03  -2.13911975e-03  -4.69697206e-03  -2.97702177e-03\n",
      "   -4.44167475e-03  -3.41252187e-03  -7.93759404e-04  -3.79437981e-03\n",
      "   -1.03155366e-03  -5.64772775e-03  -4.00655719e-03  -2.97298200e-03\n",
      "   -2.10880455e-03  -3.06680623e-03  -2.33215656e-03  -4.49045559e-03\n",
      "   -6.80294918e-03  -3.42276087e-03  -9.74320224e-04  -2.68115484e-03\n",
      "   -2.81278054e-03  -5.10234545e-03   5.01097593e-03  -2.67595584e-03\n",
      "   -3.28259840e-03  -2.00724277e-03  -4.16667464e-03  -2.75551282e-03\n",
      "   -4.61272413e-03  -4.38282183e-03  -1.00771412e-02  -4.39653937e-03\n",
      "   -1.04694908e-02  -6.62681891e-03  -4.74977848e-03  -2.05393387e-03\n",
      "   -6.62832344e-03   7.35813489e-03  -9.58351179e-05  -1.92788242e-03\n",
      "   -1.85163719e-03  -1.76685753e-03  -1.31851797e-03  -8.64237431e-04\n",
      "   -2.29646053e-03  -2.08512595e-03  -2.58329545e-03  -1.13349248e-03\n",
      "   -1.36321128e-03  -1.66832580e-03  -1.39787263e-03  -2.60115709e-03\n",
      "   -1.04690487e-03  -1.64926538e-03  -1.84376529e-03  -1.55882580e-03\n",
      "   -1.69058189e-03  -2.56165786e-03  -9.04407877e-04  -1.54993235e-03\n",
      "   -1.85403844e-03  -1.26800744e-03  -1.56083918e-03  -1.71901989e-03\n",
      "   -1.72382279e-03  -1.76344870e-03  -1.99425097e-03  -5.85621433e-04\n",
      "   -2.84461431e-03  -1.81206157e-03  -1.79731464e-03  -1.12409741e-03\n",
      "   -2.26541752e-03]\n",
      " [ -1.28738086e-04  -1.79201105e-03  -2.34308307e-03  -3.98334050e-03\n",
      "   -1.13956722e-04  -7.49172720e-04   1.69611010e-03  -2.25090799e-03\n",
      "   -3.02538425e-03   1.63797128e-03   2.83754673e-03  -1.26054890e-05\n",
      "   -2.39954744e-03  -1.70087517e-03  -1.10903903e-03  -8.88693058e-04\n",
      "   -9.89144479e-04  -1.88366187e-03  -3.31316857e-03   2.81378566e-04\n",
      "   -1.65643756e-03  -1.71286141e-03  -7.65333318e-04  -3.27253039e-03\n",
      "   -3.79999077e-03   1.68530535e-03  -4.77614770e-04  -2.57781778e-03\n",
      "   -2.56095381e-03   3.20518335e-03   1.69799167e-03  -8.18031563e-04\n",
      "   -9.67529855e-07  -1.28050304e-03  -5.03309075e-04  -6.12890248e-04\n",
      "   -1.01254114e-03  -2.07013534e-03  -1.12166056e-03  -3.35151457e-03\n",
      "   -3.21410409e-03  -3.14297769e-03  -9.16997432e-04  -1.31940004e-03\n",
      "   -2.34006978e-03  -2.56360325e-03  -2.73050059e-03  -2.20757610e-03\n",
      "   -2.31611513e-03  -3.78988297e-04  -1.88088209e-03  -3.87776152e-03\n",
      "   -2.09271080e-03  -1.83120470e-03  -3.20083127e-03  -2.69678416e-03\n",
      "   -3.57842938e-03  -4.93938785e-03  -8.74558495e-03  -1.57259831e-03\n",
      "   -1.97214754e-03  -3.24984132e-03  -3.42170242e-03  -3.07579972e-03\n",
      "   -7.53483991e-04  -2.97260134e-03  -3.04371972e-03  -1.08998451e-03\n",
      "   -4.63579715e-03  -3.23779805e-03  -2.92316344e-03  -2.68426858e-03\n",
      "   -3.44795002e-03   2.12883283e-03  -2.06159599e-03  -1.01015121e-03\n",
      "   -1.87666480e-03  -2.32757549e-03  -1.44746576e-03  -1.05912198e-04\n",
      "   -2.11345528e-03  -1.76498376e-03  -1.80513829e-03  -3.59177543e-03\n",
      "   -2.15678686e-03  -3.03932253e-03  -1.64883669e-03  -7.38840733e-04\n",
      "   -3.47425888e-04  -1.54462863e-03  -1.45001856e-03  -1.71413551e-03\n",
      "   -3.18361940e-03  -7.62957292e-04  -3.46387580e-04  -3.48584526e-03\n",
      "   -1.75648345e-03  -2.54908936e-04  -1.07556826e-03  -2.64435772e-03\n",
      "   -3.13510430e-03  -2.93455083e-03  -2.23992559e-03  -1.58314133e-03\n",
      "   -1.43295060e-03  -3.35124136e-03  -1.41266893e-03  -1.39271783e-03\n",
      "   -1.98920652e-03  -3.47771415e-03  -3.89298482e-03  -2.95996278e-03\n",
      "   -7.82059274e-04  -2.31403526e-03  -1.64952144e-03  -7.79542127e-04\n",
      "   -2.49409630e-03  -4.57308551e-04  -1.57933423e-03  -3.81124824e-03\n",
      "   -2.26134052e-03  -2.71179359e-03  -6.26310962e-04  -2.30622822e-03\n",
      "   -1.34270013e-03  -9.92675969e-04  -2.26382683e-03  -1.92669425e-03\n",
      "   -2.56815200e-03   1.21066257e-03  -4.84641550e-03  -3.97295634e-03\n",
      "   -7.23788075e-03  -3.20020325e-03  -2.18488701e-03   3.54558598e-03\n",
      "   -9.69033423e-03   1.31808467e-02  -8.62940537e-04  -1.20062390e-03\n",
      "   -1.09427487e-03  -9.38434333e-04  -1.13478490e-03  -1.15587263e-03\n",
      "   -1.01211638e-03  -1.05150971e-03  -1.12326610e-03  -1.66913216e-03\n",
      "   -4.61127277e-04  -1.16926087e-03  -1.08501178e-03  -1.30916139e-03\n",
      "   -7.85691742e-04  -1.45212203e-03  -1.17304677e-03  -6.69107058e-04\n",
      "   -1.01583991e-03  -1.84210724e-03  -4.37556321e-04  -9.32503491e-04\n",
      "   -1.44843508e-03  -9.56792810e-04  -1.14615520e-03  -1.04682472e-03\n",
      "   -4.73461400e-04  -1.10787692e-03  -1.65925401e-03  -1.43412081e-03\n",
      "   -7.74233584e-04  -6.00879477e-04  -1.58433765e-03  -7.19584234e-04\n",
      "   -1.58428202e-03]\n",
      " [ -7.52417838e-05  -2.00264468e-03  -3.53036099e-04  -5.58063665e-04\n",
      "   -4.20025740e-04  -5.55324118e-04  -2.72008453e-03  -2.31933564e-03\n",
      "   -1.72063195e-03   1.31150212e-03   3.60267247e-03   4.93607622e-04\n",
      "   -1.12825312e-03  -1.78807158e-03  -1.66938378e-03  -1.67214049e-03\n",
      "   -9.18010971e-04  -2.99029783e-03  -5.30882384e-04  -2.19313906e-03\n",
      "   -2.05703735e-03  -1.57876557e-03  -1.45584796e-04  -1.72705132e-03\n",
      "   -1.91619278e-03  -9.98898431e-04  -1.82830131e-04  -1.83188009e-03\n",
      "   -1.34739791e-03  -2.71915331e-03  -1.38794248e-03  -9.04123280e-04\n",
      "   -2.00861564e-03  -1.30561426e-03  -2.47902992e-03  -1.36231220e-03\n",
      "   -5.37673769e-04  -3.17659267e-03  -8.30906739e-04  -7.83502070e-04\n",
      "    9.06952121e-04   1.73302862e-03  -2.81021935e-03  -2.92896558e-03\n",
      "   -3.48886005e-03   1.10408987e-03  -7.56201605e-04   2.23334847e-03\n",
      "   -2.98853633e-03  -1.06695542e-03  -1.15205674e-03  -2.38638933e-03\n",
      "   -2.64015003e-04  -2.50491146e-03  -3.22735568e-04  -2.27505705e-03\n",
      "   -8.07724634e-05  -2.24539357e-03  -3.75415988e-03  -2.05769366e-03\n",
      "   -2.51991322e-03  -1.07067765e-03  -1.15144664e-03  -3.44468186e-03\n",
      "   -1.14330228e-03   2.32709770e-03   1.02679532e-03  -5.17477035e-04\n",
      "   -1.72572225e-03  -1.86480942e-03  -1.17429231e-03  -3.47227831e-03\n",
      "   -9.08869956e-04  -1.32773570e-03  -1.64415500e-03  -3.96154254e-03\n",
      "   -3.42680587e-04  -3.31778520e-03  -2.79751889e-03  -2.02012390e-03\n",
      "    2.90713448e-04  -2.24555515e-03  -8.99164287e-04  -1.44711027e-03\n",
      "   -1.52220325e-03  -1.50706927e-03  -8.99021762e-05  -1.07887833e-03\n",
      "   -1.74385974e-03  -1.17080762e-03  -1.28270084e-03  -1.82665977e-03\n",
      "   -1.98440177e-03  -1.92413765e-03  -2.15304375e-03   2.28900550e-03\n",
      "   -2.37565112e-03  -3.04784249e-03  -1.70950627e-03  -2.53588411e-03\n",
      "   -2.12392825e-03   2.04440693e-03  -5.76309989e-04  -1.26095955e-03\n",
      "   -3.39162878e-04  -1.18468707e-03  -9.47465480e-04  -1.43576808e-03\n",
      "   -2.47263534e-03  -2.43897817e-03  -1.60045342e-03  -1.13219933e-03\n",
      "   -2.59592113e-03  -2.59174339e-03  -2.01098636e-03  -1.52683984e-03\n",
      "   -2.54985592e-03  -3.12182611e-03  -1.64760814e-03  -1.30502573e-03\n",
      "   -1.72258726e-03  -3.27279213e-04  -3.90655153e-04  -1.37593456e-03\n",
      "   -1.26127382e-04  -2.94500701e-03  -4.74481879e-04  -1.79540003e-03\n",
      "   -1.67685325e-03  -5.69865865e-04  -2.88942637e-03  -1.18637681e-03\n",
      "   -2.23358396e-03  -1.58042114e-03  -1.06588716e-03  -3.45017920e-03\n",
      "   -4.10657397e-03   1.01139815e-02  -8.55761130e-04  -1.04136666e-03\n",
      "   -1.14778582e-03  -1.03528414e-03  -8.46880732e-04  -1.68486547e-03\n",
      "   -8.17418788e-04  -5.32947159e-04  -3.31742051e-04  -6.54387163e-04\n",
      "   -2.09202620e-03  -1.51265571e-03  -1.12162064e-03  -1.34154635e-04\n",
      "   -1.36144839e-03  -1.32257092e-03  -4.96019800e-04  -1.29260355e-03\n",
      "   -9.87236496e-04  -1.60160615e-03  -4.60208325e-04  -9.98368186e-04\n",
      "   -1.04603260e-03  -1.24832780e-03  -1.07435960e-03  -1.02205223e-03\n",
      "   -1.04596018e-03  -1.09476391e-03  -6.10742252e-04  -8.79464310e-04\n",
      "   -1.25575428e-03  -1.37473156e-03  -6.69027383e-04  -1.37713318e-03\n",
      "   -7.76626450e-04]\n",
      " [  4.15107347e-05  -5.87325744e-04  -1.54538227e-03   1.40015658e-03\n",
      "   -3.17162275e-04  -8.41100294e-04  -2.12069447e-04   2.82247405e-03\n",
      "    2.53172532e-03  -1.74201867e-03  -3.93175882e-03  -1.68587749e-03\n",
      "   -6.72204840e-04  -2.12257483e-04   1.56593966e-03   1.45639469e-03\n",
      "    2.54763494e-03   3.90134482e-03   2.26548491e-03  -1.57414702e-04\n",
      "    2.22420690e-03  -1.13070472e-03  -1.13513237e-03  -5.93642236e-04\n",
      "    3.03833732e-03  -4.02082234e-04  -6.92540104e-04  -4.21193680e-04\n",
      "    1.98125501e-03  -9.72365508e-04  -1.48081250e-04   2.42822612e-03\n",
      "   -1.68193073e-03  -1.08531097e-03  -6.93336092e-05  -1.62421925e-04\n",
      "   -4.43699334e-05  -2.02172071e-05  -1.47050226e-03   2.69976109e-03\n",
      "    1.51979837e-03  -6.19844662e-04  -1.76019001e-03   3.72130207e-03\n",
      "    2.99483146e-03   1.93761178e-03   2.17449905e-03  -2.58371957e-04\n",
      "    3.35744345e-03  -8.29419403e-04  -4.72838173e-04   2.79344232e-03\n",
      "   -1.95861130e-03  -8.91846745e-04   2.18318649e-03   2.53192657e-03\n",
      "   -1.29256496e-04   2.69332321e-03   6.40610076e-03  -1.18891689e-03\n",
      "    1.91197467e-03  -1.06492261e-03   2.22307448e-03  -8.21442197e-05\n",
      "   -5.70906117e-04  -1.25160001e-03  -1.83309623e-03  -1.60155104e-03\n",
      "    2.12732468e-03   3.29503352e-03  -6.34722238e-04  -1.31504129e-04\n",
      "   -8.78816437e-04  -1.40246816e-03   1.82540742e-03   1.22959382e-03\n",
      "    1.59894626e-03   2.75853279e-03   2.01200491e-03  -1.73108826e-03\n",
      "   -1.03988052e-03  -2.54667795e-04  -5.50339161e-04  -2.50304286e-04\n",
      "    1.36194862e-03  -7.73662163e-04  -8.11570450e-04  -1.25571658e-03\n",
      "   -7.83760184e-04   2.42036107e-03  -1.91691152e-03  -1.21063892e-03\n",
      "   -9.34161661e-04  -4.31431490e-04  -7.27019671e-04   2.61506163e-03\n",
      "    1.73202695e-03  -3.32200362e-04  -1.57353913e-03  -7.62338760e-04\n",
      "    2.51536216e-03  -1.24892162e-03   3.00120466e-03  -1.04760278e-04\n",
      "    2.84836314e-03   1.52959419e-03  -5.54114112e-05  -1.69329808e-03\n",
      "   -8.39102440e-04   1.71012900e-03  -1.65581682e-04  -8.98628945e-06\n",
      "    2.02753931e-03   2.85919326e-03  -8.47085753e-04  -2.93269997e-03\n",
      "    3.15608942e-03  -2.35190111e-03  -1.24643426e-03   1.34835061e-03\n",
      "   -5.12391382e-05  -7.27187436e-04  -2.25432729e-03   1.36670141e-03\n",
      "   -5.48477025e-04  -1.69095119e-03  -5.76973259e-04  -7.24199939e-04\n",
      "    2.43532176e-03   2.82427652e-03   2.87474307e-03  -1.75779877e-04\n",
      "    2.94620065e-03   1.79666606e-03  -1.07868790e-03   1.21002578e-03\n",
      "   -4.80856706e-04  -8.53048915e-03  -2.01044124e-03  -9.51962318e-04\n",
      "   -8.43757667e-04  -8.13969115e-04  -1.23857930e-03  -6.00220582e-04\n",
      "   -8.49057030e-04  -1.49220694e-03  -7.71833362e-04  -1.41781207e-03\n",
      "   -7.96749009e-04  -9.87866990e-04  -9.27872684e-04  -9.75568462e-04\n",
      "   -1.01418996e-03  -7.85204088e-04  -8.03077626e-04  -1.36846768e-03\n",
      "   -9.75578024e-04  -7.97614075e-04  -1.12061293e-03  -9.94559562e-04\n",
      "   -9.07180711e-04  -9.77763125e-04  -1.00614701e-03  -9.30810219e-04\n",
      "   -1.10757142e-03  -1.16630627e-03  -7.14347040e-04  -1.11157445e-03\n",
      "   -8.19011207e-04  -8.86045216e-04  -1.01657418e-03  -1.37224812e-03\n",
      "   -5.12046126e-04]\n",
      " [  2.29963432e-05   2.05565629e-03   2.40145184e-03   4.57804506e-03\n",
      "   -4.33471122e-03  -2.13166917e-03  -2.66385169e-03   2.46692907e-03\n",
      "    5.02633089e-03  -4.17896880e-03  -5.73935857e-03  -3.27542832e-03\n",
      "    4.75931632e-03  -1.83769731e-03  -3.65599746e-03  -3.38037574e-03\n",
      "   -5.44691253e-03   2.03472513e-03   3.17534713e-03  -2.55869577e-03\n",
      "    2.26431042e-03   2.45412339e-03  -1.24391571e-03   3.24487516e-03\n",
      "    5.13238778e-03  -1.96209048e-03  -2.69543763e-03   2.20807890e-03\n",
      "   -7.97700046e-04  -3.71583376e-03  -2.56888880e-03  -6.03159362e-04\n",
      "   -1.65779865e-03  -1.86049150e-03  -9.77669546e-04  -2.79284204e-03\n",
      "   -3.23090451e-03   3.88666353e-03   2.17458968e-03   3.01396295e-03\n",
      "   -1.22828815e-03  -1.48696989e-03  -4.51691667e-04  -1.55857491e-03\n",
      "    4.16654566e-03  -2.81011692e-03   2.70624498e-03  -1.80189844e-04\n",
      "   -1.58798235e-03  -2.37663497e-03  -2.29883318e-03   4.84928644e-03\n",
      "   -1.96582197e-03  -2.02183522e-04   1.89630485e-03   3.46592528e-03\n",
      "   -1.43202981e-03   8.90406733e-03   1.41724824e-02   3.00795646e-03\n",
      "   -1.20172500e-03   2.90056526e-03   2.24072081e-03   5.09686919e-03\n",
      "   -2.45988851e-03   2.50811241e-03   3.72148907e-03  -1.29411851e-03\n",
      "    6.65349087e-03   4.59435130e-03   4.66564301e-03   5.27853936e-03\n",
      "    4.75802514e-03  -2.17343054e-03   2.14302954e-03   4.00022238e-03\n",
      "   -1.20372491e-03   2.46647671e-03  -1.35338523e-03  -8.58034556e-04\n",
      "   -9.38573011e-04  -4.91044114e-04  -1.42327482e-03   5.59897821e-03\n",
      "   -1.99400229e-03   2.25699103e-03  -1.28834845e-03  -1.13092816e-04\n",
      "   -1.43230068e-03  -3.31509410e-03  -1.42867648e-03   2.06532926e-03\n",
      "    4.00650140e-03  -8.43500861e-04  -5.37326136e-04   2.61667555e-03\n",
      "    2.24960126e-03  -1.16617756e-03  -2.17519147e-03   3.94311481e-03\n",
      "    3.00873841e-03  -6.99259608e-04  -1.58212960e-03  -1.02516552e-03\n",
      "   -2.00788565e-03   2.88164443e-03  -2.85675298e-03   3.26577982e-03\n",
      "   -3.18934950e-04   5.64688279e-03   4.64193069e-03   2.25885037e-03\n",
      "   -1.57706523e-03  -3.98143411e-04   2.19790430e-03   4.27320173e-03\n",
      "    4.49957760e-03   4.27899430e-03  -1.03803340e-03   2.03697864e-03\n",
      "    1.80179942e-03   3.18744869e-03  -3.32233166e-03  -4.52787686e-04\n",
      "   -2.08411955e-03   3.03204063e-03   2.26331889e-03   2.22252810e-03\n",
      "    2.66043642e-03  -4.03053252e-03   1.03108977e-02   4.99776171e-03\n",
      "    1.16105744e-02   6.03647774e-03   3.71507891e-03  -6.58456727e-03\n",
      "   -1.81200544e-03  -1.27646792e-02  -1.64087422e-03  -8.19144537e-04\n",
      "   -9.64616396e-04  -1.34006018e-03  -1.22589225e-03  -1.20213101e-03\n",
      "   -1.07261680e-03  -1.00078490e-03  -1.42410993e-03  -8.00752013e-04\n",
      "   -1.02914423e-03  -4.73242651e-04  -1.16482626e-03  -1.14996299e-03\n",
      "   -1.55283444e-03  -7.49359450e-04  -1.70251608e-03  -7.74267048e-04\n",
      "   -1.14032447e-03   1.91855248e-03  -1.95513069e-03  -1.25690148e-03\n",
      "   -8.71203529e-04  -1.27043902e-03  -9.68355510e-04  -1.08544792e-03\n",
      "   -1.45527896e-03  -7.57182722e-04  -1.07534583e-03  -1.56383723e-03\n",
      "   -5.92507786e-04  -1.38570500e-03  -8.10840527e-04  -1.07751185e-03\n",
      "   -1.03027400e-03]]\n"
     ]
    }
   ],
   "source": [
    "# run logistic regression and vary some parameters\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "# first we create a reusable logisitic regression object\n",
    "#   here we can setup the object with different learning parameters and constants\n",
    "\n",
    "optimizations = [\"BFGSBinaryLogisticRegression\",\"StochasticLogisticRegression\",\"LineSearchLogisticRegression\"]\n",
    "#optimizations = [\"BFGSBinaryLogisticRegression\",\"BFGSBinaryLogisticRegression\",\"BFGSBinaryLogisticRegression\"]\n",
    "etas = [0.1, 0.1, 0.001]\n",
    "iters = [10, 5000, 150]\n",
    "regs = [0,1,2]\n",
    "\n",
    "for optimization,eta,iter_,reg in zip(optimizations,etas,iters,regs):\n",
    "    lr_clf = MultiClassLogisticRegression(eta=eta,iterations=iter_, C=0.02, optimization=optimization,reg=reg) # get object\n",
    "\n",
    "\n",
    "    # now we can use the cv_object that we setup before to iterate through the \n",
    "    #    different training and testing sets. Each time we will reuse the logisitic regression \n",
    "    #    object, but it gets trained on different data each time we use it.\n",
    "\n",
    "    iter_num=0\n",
    "    # the indices are the rows used for training and testing in each iteration\n",
    "    for train_indices, test_indices in cv_object.split(X,y): \n",
    "        # I will create new variables here so that it is more obvious what \n",
    "        # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "        # but it makes this code less readable)\n",
    "        X_train = (X[train_indices])\n",
    "        y_train = y[train_indices]\n",
    "\n",
    "    #     print(X_train)\n",
    "    #     print(y_train)\n",
    "\n",
    "        X_test = (X[test_indices])\n",
    "        y_test = y[test_indices]\n",
    "\n",
    "#         st = time.time()\n",
    "        \n",
    "        lr_clf.fit(X_train,y_train)  # train object\n",
    "#         t = (time.time() -st)\n",
    "#         lr_clf_times.append(t)\n",
    "        \n",
    "        lr_clf.fit(X_train,y_train)\n",
    "        \n",
    "        # train the reusable logisitc regression model on the training data\n",
    "        y_hat = lr_clf.predict(X_test) # get test set precitions\n",
    "\n",
    "        # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "        acc = mt.accuracy_score(y_test,y_hat+1)\n",
    "#         lr_clf_accuracies.append(acc)\n",
    "#         cost_accuracies.append([acc])\n",
    "\n",
    "        conf = mt.confusion_matrix(y_test,y_hat+1)\n",
    "        print(\"====Iteration\",iter_num,\" ====\")\n",
    "        if(reg == 0):\n",
    "            label = \"L1\"\n",
    "        elif(reg == 1):\n",
    "            label = \"L2\"\n",
    "        else:\n",
    "            label = \"L1 and L2\"\n",
    "        print('For ',optimization,' eta: ',eta, \"Iterations: \",iter_,\"Regularization: \",label,' : Accuracy of: ',acc)\n",
    "\n",
    "        #print(\"accuracy\", acc )\n",
    "        print(\"confusion matrix\\n\",conf)\n",
    "        iter_num+=1\n",
    "\n",
    "        \n",
    "    # Also note that every time you run the above code\n",
    "    #   it randomly creates a new training and testing set, \n",
    "    #   so accuracy will be different each time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Pipelining PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "For  BFGSBinaryLogisticRegression  eta:  0.1 Iterations:  10 Regularization:  L1  : Accuracy of:  0.371287128713\n",
      "confusion matrix\n",
      " [[ 7  5  9  2  5]\n",
      " [ 8  6 15  5  2]\n",
      " [ 2  6 21 12  6]\n",
      " [ 1  4 11 16 16]\n",
      " [ 0  0 10  8 25]]\n",
      "====Iteration 1  ====\n",
      "For  BFGSBinaryLogisticRegression  eta:  0.1 Iterations:  10 Regularization:  L1  : Accuracy of:  0.361386138614\n",
      "confusion matrix\n",
      " [[ 9  7  7  2  1]\n",
      " [ 8  7 13  5  2]\n",
      " [ 7  6 16  7  5]\n",
      " [ 1  8 18 13 12]\n",
      " [ 1  2  5 12 28]]\n",
      "====Iteration 2  ====\n",
      "For  BFGSBinaryLogisticRegression  eta:  0.1 Iterations:  10 Regularization:  L1  : Accuracy of:  0.336633663366\n",
      "confusion matrix\n",
      " [[ 6  4  8  3  2]\n",
      " [ 5  4 11  8  2]\n",
      " [ 4 15 14 10  3]\n",
      " [ 1  7 11 13 19]\n",
      " [ 0  2 11  8 31]]\n",
      "====Iteration 0  ====\n",
      "For  StochasticLogisticRegression  eta:  0.1 Iterations:  5000 Regularization:  L2  : Accuracy of:  0.29702970297\n",
      "confusion matrix\n",
      " [[15  6  3  0  2]\n",
      " [12  8  5  2  5]\n",
      " [12 11 10 10  4]\n",
      " [10  7 10  9 14]\n",
      " [ 1  5  4 19 18]]\n",
      "====Iteration 1  ====\n",
      "For  StochasticLogisticRegression  eta:  0.1 Iterations:  5000 Regularization:  L2  : Accuracy of:  0.316831683168\n",
      "confusion matrix\n",
      " [[11  7  5  2  2]\n",
      " [ 5  5  8  7  2]\n",
      " [ 8  9 19 11  6]\n",
      " [12 11 10  7  8]\n",
      " [ 5  3  9  8 22]]\n",
      "====Iteration 2  ====\n",
      "For  StochasticLogisticRegression  eta:  0.1 Iterations:  5000 Regularization:  L2  : Accuracy of:  0.361386138614\n",
      "confusion matrix\n",
      " [[ 8 11  6  1  0]\n",
      " [ 9 14  5  2  3]\n",
      " [12  6 17  5  6]\n",
      " [ 5  4 14  7 13]\n",
      " [ 2  4  5 16 27]]\n",
      "====Iteration 0  ====\n",
      "For  LineSearchLogisticRegression  eta:  0.001 Iterations:  150 Regularization:  L1 and L2  : Accuracy of:  0.316831683168\n",
      "confusion matrix\n",
      " [[ 5  9  0  2  5]\n",
      " [16 10  3  4  6]\n",
      " [ 8 12  5 14 14]\n",
      " [ 4  2  8  8 19]\n",
      " [ 4  4  3  1 36]]\n",
      "====Iteration 1  ====\n",
      "For  LineSearchLogisticRegression  eta:  0.001 Iterations:  150 Regularization:  L1 and L2  : Accuracy of:  0.316831683168\n",
      "confusion matrix\n",
      " [[ 8 16  1  2  1]\n",
      " [14 10  5  4  3]\n",
      " [11 14  7  7 13]\n",
      " [ 5  4 10  8 16]\n",
      " [ 1  4  2  5 31]]\n",
      "====Iteration 2  ====\n",
      "For  LineSearchLogisticRegression  eta:  0.001 Iterations:  150 Regularization:  L1 and L2  : Accuracy of:  0.326732673267\n",
      "confusion matrix\n",
      " [[12  6  2  2  1]\n",
      " [14  8  5  5  5]\n",
      " [ 9 11 11  7 14]\n",
      " [ 9  4 11 10 15]\n",
      " [ 3  0  3 10 25]]\n"
     ]
    }
   ],
   "source": [
    "# run logistic regression and vary some parameters\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "# first we create a reusable logisitic regression object\n",
    "#   here we can setup the object with different learning parameters and constants\n",
    "\n",
    "optimizations = [\"BFGSBinaryLogisticRegression\",\"StochasticLogisticRegression\",\"LineSearchLogisticRegression\"]\n",
    "#optimizations = [\"BFGSBinaryLogisticRegression\",\"BFGSBinaryLogisticRegression\",\"BFGSBinaryLogisticRegression\"]\n",
    "etas = [0.1, 0.1, 0.001]\n",
    "iters = [10, 5000, 150]\n",
    "regs = [0,1,2]\n",
    "components = 90\n",
    "pca = PCA(n_components=components)\n",
    "\n",
    "with np.errstate(all='ignore'):\n",
    "    for optimization,eta,iter_,reg in zip(optimizations,etas,iters,regs):\n",
    "        mglr = MultiClassLogisticRegression(eta=eta,iterations=iter_, C=0.02, optimization=optimization,reg=reg) # get object\n",
    "        lr_clf = Pipeline([ ('pca', pca), (\"multiclasslogregression\", mglr)]) # get object\n",
    "\n",
    "\n",
    "        # now we can use the cv_object that we setup before to iterate through the \n",
    "        #    different training and testing sets. Each time we will reuse the logisitic regression \n",
    "        #    object, but it gets trained on different data each time we use it.\n",
    "\n",
    "        iter_num=0\n",
    "        # the indices are the rows used for training and testing in each iteration\n",
    "        for train_indices, test_indices in cv_object.split(X,y): \n",
    "            # I will create new variables here so that it is more obvious what \n",
    "            # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "            # but it makes this code less readable)\n",
    "            X_train = (X[train_indices])\n",
    "            y_train = y[train_indices]\n",
    "\n",
    "        #     print(X_train)\n",
    "        #     print(y_train)\n",
    "\n",
    "            X_test = (X[test_indices])\n",
    "            y_test = y[test_indices]\n",
    "\n",
    "    #         st = time.time()\n",
    "\n",
    "            lr_clf.fit(X_train,y_train)  # train object\n",
    "    #         t = (time.time() -st)\n",
    "    #         lr_clf_times.append(t)\n",
    "\n",
    "            lr_clf.fit(X_train,y_train)\n",
    "\n",
    "            # train the reusable logisitc regression model on the training data\n",
    "            y_hat = lr_clf.predict(X_test) # get test set precitions\n",
    "\n",
    "            # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "            acc = mt.accuracy_score(y_test,y_hat+1)\n",
    "    #         lr_clf_accuracies.append(acc)\n",
    "    #         cost_accuracies.append([acc])\n",
    "\n",
    "            conf = mt.confusion_matrix(y_test,y_hat+1)\n",
    "            print(\"====Iteration\",iter_num,\" ====\")\n",
    "            if(reg == 0):\n",
    "                label = \"L1\"\n",
    "            elif(reg == 1):\n",
    "                label = \"L2\"\n",
    "            else:\n",
    "                label = \"L1 and L2\"\n",
    "            print('For ',optimization,' eta: ',eta, \"Iterations: \",iter_,\"Regularization: \",label,' : Accuracy of: ',acc)\n",
    "\n",
    "            #print(\"accuracy\", acc )\n",
    "            print(\"confusion matrix\\n\",conf)\n",
    "            iter_num+=1\n",
    "\n",
    "\n",
    "        # Also note that every time you run the above code\n",
    "        #   it randomly creates a new training and testing set, \n",
    "        #   so accuracy will be different each time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best: eta: 0.1, reg = 0, iters = 10, acc = 35%\n",
    "eta: eta .001, iters 150, reg 2, acc 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting Values of C to Achieve Best Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53.18359375, 53.24609375, 52.98046875, 52.984375, 52.98828125, 52.98828125, 52.98828125, 52.98828125]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.361386138614\n",
      "confusion matrix\n",
      " [[ 7  8  8  1  2]\n",
      " [ 7  8 20  3  2]\n",
      " [ 0  5 16 12  5]\n",
      " [ 1  2 17 17 16]\n",
      " [ 2  2  6 10 25]]\n",
      "[53.25390625, 53.25390625, 52.98828125, 52.98828125, 53.05078125, 53.05078125, 53.05078125]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.415841584158\n",
      "confusion matrix\n",
      " [[12  7  6  0  0]\n",
      " [ 7 12  8  8  3]\n",
      " [ 4  5 22 18  6]\n",
      " [ 4  5 12 16  9]\n",
      " [ 0  1  5 10 22]]\n",
      "[53.31640625, 53.31640625, 53.05078125, 53.0546875, 53.0546875, 53.0546875, 53.0546875, 53.0546875, 53.0546875]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.311881188119\n",
      "confusion matrix\n",
      " [[ 8  4  6  2  1]\n",
      " [18  7 11 13  1]\n",
      " [ 4  7 15 13  4]\n",
      " [ 4  4 14 10 17]\n",
      " [ 2  2  4  8 23]]\n",
      "[53.3203125, 53.3203125, 53.0546875, 53.0546875, 53.0546875, 53.0546875, 53.0546875, 53.0546875]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.346534653465\n",
      "confusion matrix\n",
      " [[ 8  3 11  4  2]\n",
      " [ 9  4 10  9  2]\n",
      " [ 4 11 23  9  4]\n",
      " [ 2  6 18 14  6]\n",
      " [ 3  2  9  8 21]]\n",
      "[53.3203125, 53.3203125, 53.0546875, 53.0546875, 53.0546875, 53.0546875, 53.0546875, 53.0546875]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.386138613861\n",
      "confusion matrix\n",
      " [[ 8  9  4  2  1]\n",
      " [13  6  9  5  1]\n",
      " [ 8  5 22 11  5]\n",
      " [ 2  5 11 14 15]\n",
      " [ 3  3  4  8 28]]\n",
      "[53.3203125, 53.3203125, 53.0546875, 53.0546875, 53.0546875, 53.0546875, 53.0546875, 53.0546875]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.356435643564\n",
      "confusion matrix\n",
      " [[13  7  5  2  1]\n",
      " [10 11  7  7  2]\n",
      " [ 5  7 15 13  6]\n",
      " [ 3  7 15  9 15]\n",
      " [ 2  4  5  7 24]]\n",
      "[53.3203125, 53.3203125, 53.0546875, 53.0546875, 53.0546875, 53.0546875, 53.0546875, 53.0546875]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.381188118812\n",
      "confusion matrix\n",
      " [[ 9  7  6  4  1]\n",
      " [13  5 10  9  2]\n",
      " [ 9  6 15  9  4]\n",
      " [ 2  4 10 16 13]\n",
      " [ 1  1  3 11 32]]\n",
      "[53.3203125, 53.3203125, 53.0546875, 53.0546875, 53.0546875, 53.0546875, 53.0546875, 53.0546875]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.371287128713\n",
      "confusion matrix\n",
      " [[10 11  3  5  0]\n",
      " [ 8  7 13  6  1]\n",
      " [ 5  7 21 15  3]\n",
      " [ 0  4 15 13  7]\n",
      " [ 1  2  5 16 24]]\n",
      "[53.3203125, 53.31640625, 53.0546875, 53.0546875, 53.0546875, 53.0546875, 53.0546875, 53.0546875, 53.0546875, 53.0546875]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.361386138614\n",
      "confusion matrix\n",
      " [[ 9  8 11  2  1]\n",
      " [ 9  8  8  6  1]\n",
      " [ 5  9 16 17  5]\n",
      " [ 0  6 11 17 10]\n",
      " [ 1  2  4 13 23]]\n",
      "[53.3203125, 53.3203125, 53.0546875, 53.0546875, 53.0546875, 53.0546875, 53.0546875, 53.0546875, 53.0546875, 53.0546875, 53.0546875, 53.0546875, 53.0546875, 53.0546875, 53.0546875]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.381188118812\n",
      "confusion matrix\n",
      " [[ 6  9  4  2  0]\n",
      " [ 8  9 13  2  1]\n",
      " [ 2 11 20 13  3]\n",
      " [ 2  5 12 17  9]\n",
      " [ 2  4  7 16 25]]\n",
      "[53.3203125, 53.3203125, 53.0546875, 53.0546875, 53.0546875, 53.0546875, 53.0546875, 53.0546875, 53.0546875, 53.0546875, 53.0546875]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.356435643564\n",
      "confusion matrix\n",
      " [[12 10  5  0  1]\n",
      " [ 9  7  9  9  2]\n",
      " [ 6  9 17 17  8]\n",
      " [ 1  1 10 18 13]\n",
      " [ 1  2  7 10 18]]\n",
      "[53.3203125, 53.3203125, 53.0546875, 53.0546875, 53.0546875, 53.0546875, 53.0546875, 53.0546875, 53.0546875, 52.70703125, 52.66015625, 52.66015625, 52.640625, 52.359375, 52.390625, 52.390625, 52.390625, 52.390625, 52.39453125, 52.39453125]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.361386138614\n",
      "confusion matrix\n",
      " [[12 13  1  2  1]\n",
      " [ 6  9 10  9  5]\n",
      " [ 8 15 12  8  9]\n",
      " [ 3  4 11 14 13]\n",
      " [ 0  1  2  8 26]]\n",
      "[52.90234375, 52.91015625, 52.64453125, 52.6484375, 52.65234375, 52.65234375, 52.65234375, 52.65234375, 52.6484375, 52.6484375, 52.6484375, 52.6484375, 52.6484375, 52.6484375, 52.6484375]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.420792079208\n",
      "confusion matrix\n",
      " [[ 9  4  7  2  1]\n",
      " [ 8  9  8  7  1]\n",
      " [ 6 12 20 11  6]\n",
      " [ 1  2 11 16 17]\n",
      " [ 1  0  6  6 31]]\n",
      "[52.91796875, 52.91796875, 52.65234375, 52.62109375, 52.62109375, 52.62109375, 52.62109375, 52.62109375, 52.62109375, 52.62109375, 52.62109375]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.331683168317\n",
      "confusion matrix\n",
      " [[10  5 14  3  0]\n",
      " [ 7  7 15  5  3]\n",
      " [ 7 10 15 16  7]\n",
      " [ 1  6 12 14 10]\n",
      " [ 0  1  7  6 21]]\n",
      "[52.890625, 52.890625, 52.625, 52.625, 52.625, 52.625, 52.625, 52.625, 52.625, 52.625, 52.625, 52.625]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.341584158416\n",
      "confusion matrix\n",
      " [[ 6  9  6  0  2]\n",
      " [ 7 30  1  1  1]\n",
      " [ 4 39  5  2  2]\n",
      " [ 0 24  8  4 10]\n",
      " [ 1 12  1  3 24]]\n",
      "[52.89453125, 52.89453125, 52.6328125, 52.6328125, 52.6328125, 52.6328125, 52.6328125, 52.6328125, 52.6328125, 52.59375, 52.59375, 52.59375, 52.59375, 52.6015625]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.366336633663\n",
      "confusion matrix\n",
      " [[11  7 10  0  1]\n",
      " [11  7 14 10  2]\n",
      " [ 2 15 21 13  4]\n",
      " [ 3  5  5 15 11]\n",
      " [ 1  2  0 12 20]]\n",
      "[52.8671875, 52.8671875, 52.6015625, 52.61328125, 52.61328125, 52.61328125, 52.61328125, 52.125, 52.125, 52.125, 52.125, 52.125, 52.125, 52.06640625, 52.06640625, 52.06640625, 52.06640625]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.410891089109\n",
      "confusion matrix\n",
      " [[12  7  8  1  1]\n",
      " [12  7 15  7  2]\n",
      " [ 2  8 20  8 12]\n",
      " [ 0  5 12 15  9]\n",
      " [ 1  0  1  8 29]]\n",
      "[52.33203125, 52.3359375, 52.0859375, 52.10546875, 52.109375, 52.109375, 52.109375, 52.109375, 52.109375, 52.11328125, 52.11328125, 52.11328125, 52.11328125]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.326732673267\n",
      "confusion matrix\n",
      " [[ 8 10  4  3  1]\n",
      " [11  8 12  3  1]\n",
      " [ 5  8 20 16  2]\n",
      " [ 2  2 21 12 12]\n",
      " [ 0  2  6 15 18]]\n",
      "[52.3828125, 52.38671875, 52.15234375, 52.15234375, 52.15234375, 52.15234375, 52.15234375, 52.16015625, 52.16015625, 52.16015625, 52.16015625, 52.16015625, 52.16015625, 52.16015625]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.381188118812\n",
      "confusion matrix\n",
      " [[ 9  5  8  1  0]\n",
      " [ 7  7  8  9  3]\n",
      " [ 4  5 28 14  6]\n",
      " [ 3  3 16 14 17]\n",
      " [ 1  0  7  8 19]]\n",
      "[52.42578125, 52.42578125, 52.19140625, 52.19140625, 52.19140625, 52.19140625, 52.19140625, 52.19140625, 52.19140625, 52.19140625, 52.19140625, 52.19140625]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.366336633663\n",
      "confusion matrix\n",
      " [[ 8  6  7  2  1]\n",
      " [ 6 11 12  7  1]\n",
      " [ 9  8 20 15  8]\n",
      " [ 4  5  8 17 17]\n",
      " [ 1  4  2  5 18]]\n",
      "[52.45703125, 52.45703125, 52.19140625, 52.19140625, 52.19140625, 52.19140625, 52.19140625, 52.19140625, 52.19140625, 52.1953125]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.450495049505\n",
      "confusion matrix\n",
      " [[ 9  3  9  1  0]\n",
      " [ 5 14  7  3  3]\n",
      " [ 6  5 21 11  4]\n",
      " [ 3  7 15 13 13]\n",
      " [ 1  3  3  9 34]]\n",
      "[52.46875, 52.46875, 52.2109375, 52.2109375, 52.2109375, 52.2109375, 52.2109375, 52.2109375, 52.2109375, 52.2109375, 52.2109375, 52.2109375]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.376237623762\n",
      "confusion matrix\n",
      " [[10  5  7  4  2]\n",
      " [ 6  9 10  4  2]\n",
      " [ 5  7 19 10  9]\n",
      " [ 4  8 11 17 10]\n",
      " [ 0  1  5 16 21]]\n",
      "[52.48046875, 52.48046875, 52.21484375, 52.21484375, 52.21484375, 52.21484375, 52.21484375, 52.21484375, 52.21484375, 52.21484375, 52.21484375, 52.21484375]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.405940594059\n",
      "confusion matrix\n",
      " [[ 8  6  5  5  0]\n",
      " [ 6  9  9  8  3]\n",
      " [ 4  7 22 14  9]\n",
      " [ 1  4 13 17  9]\n",
      " [ 1  3  3 10 26]]\n",
      "[52.48046875, 52.48046875, 52.21484375, 52.21875, 52.21875, 52.21875, 52.21875, 52.21875, 52.21875, 52.21875, 52.21875, 52.21875, 52.21875, 52.21875]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.336633663366\n",
      "confusion matrix\n",
      " [[ 9  8 10  4  0]\n",
      " [ 9 11  9  8  2]\n",
      " [ 1 12 14 16  9]\n",
      " [ 2  5  6 14  7]\n",
      " [ 1  0 12 13 20]]\n",
      "[52.484375, 52.484375, 52.21875, 52.21875, 52.21875, 52.21875, 52.21875, 52.21875, 52.21875, 52.21875, 52.21875, 52.21875, 52.21875]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.420792079208\n",
      "confusion matrix\n",
      " [[ 8  7  4  2  0]\n",
      " [ 7 10  6  8  1]\n",
      " [ 7 15 23  9  5]\n",
      " [ 2  5 14 19  5]\n",
      " [ 0  2  8 10 25]]\n",
      "[52.484375, 52.484375, 52.21875, 52.21875, 52.21875, 52.21875, 52.21875, 52.21875, 52.21875, 52.21875, 52.21875, 52.21875]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.356435643564\n",
      "confusion matrix\n",
      " [[ 6 10  9  3  0]\n",
      " [ 6  8  8  4  2]\n",
      " [ 5 10 19  8  8]\n",
      " [ 2  6 19 17 13]\n",
      " [ 0  2  6  9 22]]\n",
      "[52.484375, 52.4921875, 52.2265625, 52.2265625, 52.2265625, 52.2265625, 52.2265625, 52.2265625, 52.2265625, 52.2265625, 52.2265625, 52.2265625, 52.2265625]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.326732673267\n",
      "confusion matrix\n",
      " [[ 8  8  6  3  1]\n",
      " [11  8 11  6  2]\n",
      " [ 6 13  9  9  5]\n",
      " [ 1  5  9 17 18]\n",
      " [ 2  3  5 12 24]]\n",
      "[52.4921875, 52.4921875, 52.2265625, 52.2265625, 52.2265625, 52.2265625, 52.2265625, 52.2265625, 52.2265625, 52.2265625, 52.2265625, 52.2265625, 52.2265625]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.336633663366\n",
      "confusion matrix\n",
      " [[ 9  9  6  1  2]\n",
      " [ 8 10  8  5  0]\n",
      " [ 6  8 15  8 11]\n",
      " [ 1  7 13 14 17]\n",
      " [ 3  2  8 11 20]]\n",
      "[52.4921875, 52.4921875, 52.2265625, 52.2265625, 52.2265625, 52.2265625, 52.2265625, 52.2265625, 52.2265625, 52.2265625]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.405940594059\n",
      "confusion matrix\n",
      " [[ 9  5  8  1  0]\n",
      " [ 5 12 11 10  4]\n",
      " [ 2  8 18 14  4]\n",
      " [ 2  3 11 21  4]\n",
      " [ 2  3  6 17 22]]\n",
      "[52.4921875, 52.5, 52.234375, 52.234375, 52.234375, 52.234375, 52.234375, 52.234375, 52.234375, 52.234375, 52.234375, 52.234375]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.321782178218\n",
      "confusion matrix\n",
      " [[ 6 12  4  2  2]\n",
      " [ 6  7  8  9  3]\n",
      " [ 4 10 15 15  8]\n",
      " [ 1  3 16 10 12]\n",
      " [ 3  3  5 11 27]]\n",
      "[52.5, 52.5, 52.234375, 52.234375, 52.234375, 52.234375, 52.234375, 52.234375, 52.234375, 52.234375, 52.234375, 52.234375, 52.234375]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.381188118812\n",
      "confusion matrix\n",
      " [[10 12  5  1  1]\n",
      " [ 7  5 13  7  1]\n",
      " [ 2  7 21  9 10]\n",
      " [ 3  8  9 13 12]\n",
      " [ 0  2  4 12 28]]\n",
      "[52.5, 52.5, 52.234375, 52.234375, 52.234375, 52.234375, 52.234375, 52.234375, 52.234375, 52.234375, 52.234375, 52.234375, 52.234375, 52.234375, 52.234375, 52.234375]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.351485148515\n",
      "confusion matrix\n",
      " [[ 3 14  8  4  2]\n",
      " [ 7  8 16  5  1]\n",
      " [ 2  9 20 13  4]\n",
      " [ 2  1 14 17  9]\n",
      " [ 2  1  9  8 23]]\n",
      "[52.5, 52.50390625, 52.23828125, 52.23828125, 52.23828125, 52.23828125, 52.23828125, 52.23828125, 52.23828125, 52.23828125, 52.23828125, 52.23828125, 52.23828125, 52.2421875, 52.2421875]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.425742574257\n",
      "confusion matrix\n",
      " [[ 9  8  7  0  2]\n",
      " [ 8 11 12  8  2]\n",
      " [ 0  3 20 16  3]\n",
      " [ 1  4 15 19  9]\n",
      " [ 0  0  2 16 27]]\n",
      "[52.5078125, 52.5078125, 52.2421875, 52.2421875, 52.2421875, 52.2421875, 52.2421875, 52.2421875, 52.2421875, 52.2421875, 52.2421875, 52.2421875, 52.2421875, 52.2421875, 52.2421875, 52.2421875]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.435643564356\n",
      "confusion matrix\n",
      " [[10  5 10  3  0]\n",
      " [ 5 10  7  7  1]\n",
      " [ 2 11 22  9  4]\n",
      " [ 1  3 14 21 13]\n",
      " [ 1  0  4 14 25]]\n",
      "[52.5078125, 52.51171875, 52.24609375, 52.24609375, 52.24609375, 52.24609375, 52.24609375, 52.24609375, 52.24609375, 52.24609375, 52.24609375, 52.24609375]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.341584158416\n",
      "confusion matrix\n",
      " [[ 5  9  5  3  1]\n",
      " [ 5  6 10  5  2]\n",
      " [ 1  9 22 12 11]\n",
      " [ 3  5 14 11 15]\n",
      " [ 2  1 11  9 25]]\n",
      "[52.51171875, 52.51171875, 52.2421875, 52.24609375, 52.24609375, 52.24609375, 52.24609375, 52.24609375, 52.24609375, 52.24609375, 52.24609375, 52.24609375, 52.24609375, 52.24609375]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.386138613861\n",
      "confusion matrix\n",
      " [[ 3  9 10  4  0]\n",
      " [ 6 13  6  7  0]\n",
      " [ 5 10 18 12  8]\n",
      " [ 0  6  9 12 15]\n",
      " [ 1  0  5 11 32]]\n",
      "[52.51171875, 52.51171875, 52.24609375, 52.24609375, 52.24609375, 52.24609375, 52.24609375, 52.24609375, 52.24609375, 52.24609375, 52.24609375, 52.24609375]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.381188118812\n",
      "confusion matrix\n",
      " [[11 10  3  0  1]\n",
      " [ 9 10 11  7  3]\n",
      " [ 4 12 20  6  5]\n",
      " [ 0  5 15 14 14]\n",
      " [ 2  3  5 10 22]]\n",
      "[52.51171875, 52.51171875, 52.25, 52.25, 52.25, 52.25, 52.25, 52.25, 52.25, 52.25, 52.25, 52.25, 52.25, 52.25, 52.25]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.415841584158\n",
      "confusion matrix\n",
      " [[12  2  3  1  0]\n",
      " [13  7 11  6  4]\n",
      " [ 4  8 19 16  4]\n",
      " [ 2  1 17 16 12]\n",
      " [ 1  0  9  4 30]]\n",
      "[52.515625, 52.515625, 52.25, 52.25, 52.25, 52.25, 52.25, 52.25, 52.25, 52.25, 52.25, 52.25, 52.25, 52.25]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.391089108911\n",
      "confusion matrix\n",
      " [[ 7  5  4  5  3]\n",
      " [ 9 12 13  5  3]\n",
      " [ 1  9 19  7  4]\n",
      " [ 0  8 14 13 13]\n",
      " [ 2  1  2 15 28]]\n",
      "[52.515625, 52.515625, 52.25, 52.25, 52.25, 52.25, 52.25, 52.25, 52.25, 52.25, 52.25]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.381188118812\n",
      "confusion matrix\n",
      " [[ 8  5  7  4  1]\n",
      " [ 6  7 16  5  3]\n",
      " [10  3 23 10  0]\n",
      " [ 1  4 21 14  9]\n",
      " [ 2  4  5  9 25]]\n",
      "[52.515625, 52.515625, 52.25, 52.25, 52.25, 52.25, 52.25, 52.25, 52.25, 52.25, 52.25]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.430693069307\n",
      "confusion matrix\n",
      " [[11  7  7  1  0]\n",
      " [ 6 10 15  9  1]\n",
      " [ 3  4 22  5  5]\n",
      " [ 3  6 16 17 11]\n",
      " [ 1  1  5  9 27]]\n",
      "[52.515625, 52.515625, 52.25, 52.25, 52.25, 52.25, 52.25, 52.25, 52.25, 52.25, 52.25, 52.25, 52.25, 52.25, 52.25]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.381188118812\n",
      "confusion matrix\n",
      " [[12  8  3  2  3]\n",
      " [ 7  6  5  4  2]\n",
      " [ 6  7 20 14  5]\n",
      " [ 0  5 15 13 23]\n",
      " [ 1  3  5  7 26]]\n",
      "[52.515625, 52.51953125, 52.25390625, 52.25390625, 52.25390625, 52.25390625, 52.25390625, 52.2578125, 52.2578125, 52.2578125, 52.2578125, 52.2578125, 52.2578125, 52.2578125]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.361386138614\n",
      "confusion matrix\n",
      " [[ 7 10  8  3  2]\n",
      " [ 4 11 10  1  1]\n",
      " [ 5 10 14 14  5]\n",
      " [ 3  3 16 12 16]\n",
      " [ 1  1  6 10 29]]\n",
      "[52.5234375, 52.5234375, 52.2578125, 52.2578125, 52.2578125, 52.2578125, 52.2578125, 52.2578125, 52.2578125, 52.2578125, 52.2578125, 52.2578125, 52.2578125, 52.2578125]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.376237623762\n",
      "confusion matrix\n",
      " [[ 6 13  5  1  1]\n",
      " [ 4  8 14  7  4]\n",
      " [ 4 11 22  7  6]\n",
      " [ 0  7  6 17 17]\n",
      " [ 1  2  7  9 23]]\n",
      "[52.5234375, 52.5234375, 52.2578125, 52.2578125, 52.2578125, 52.2578125, 52.2578125, 52.2578125, 52.2578125, 52.2578125, 52.2578125, 52.2578125]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.371287128713\n",
      "confusion matrix\n",
      " [[ 9 12  2  1  1]\n",
      " [ 5 10 11  6  6]\n",
      " [ 6 11 13 13  4]\n",
      " [ 2  6 12 15 10]\n",
      " [ 1  1  5 12 28]]\n",
      "[52.5234375, 52.5234375, 52.2578125, 52.2578125, 52.2578125, 52.2578125, 52.2578125, 52.2578125, 52.2578125, 52.2578125, 52.2578125, 52.2578125, 52.2578125]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.381188118812\n",
      "confusion matrix\n",
      " [[ 9  2  9  3  0]\n",
      " [ 6 13 10  4  2]\n",
      " [ 6  9 15 11  6]\n",
      " [ 2  5 14 14 16]\n",
      " [ 2  1  6 11 26]]\n",
      "[52.5234375, 52.5234375, 52.2578125, 52.2578125, 52.2578125, 52.2578125, 52.2578125, 52.2578125, 52.2578125, 52.2578125]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.361386138614\n",
      "confusion matrix\n",
      " [[ 6 13  9  1  1]\n",
      " [ 9  8  7  6  4]\n",
      " [ 3  8 18 13  6]\n",
      " [ 2  5  7 13 17]\n",
      " [ 0  2  5 11 28]]\n",
      "[52.5234375, 52.52734375, 52.26171875, 52.26171875, 52.26171875, 52.26171875, 52.26171875, 52.26171875, 52.26171875, 52.26171875, 52.26171875, 52.26171875, 52.26171875, 52.26171875]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.311881188119\n",
      "confusion matrix\n",
      " [[ 5  6  8  1  3]\n",
      " [11  3 16  4  2]\n",
      " [ 2 11 12 14  6]\n",
      " [ 2  5 13 15 17]\n",
      " [ 1  2  4 11 28]]\n",
      "[52.52734375, 52.52734375, 52.26171875, 52.26171875, 52.26171875, 52.26171875, 52.26171875, 52.26171875, 52.26171875, 52.26171875, 52.26171875, 52.26171875]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.346534653465\n",
      "confusion matrix\n",
      " [[ 4  7  8  0  3]\n",
      " [ 9  8 14  5  2]\n",
      " [ 3 10 19  9  5]\n",
      " [ 3  4 11  9 22]\n",
      " [ 0  1  4 12 30]]\n",
      "[52.52734375, 52.52734375, 52.26171875, 52.26171875, 52.26171875, 52.26171875, 52.265625, 52.265625, 52.265625]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.40099009901\n",
      "confusion matrix\n",
      " [[10  3  5  4  1]\n",
      " [ 8  6  8  7  1]\n",
      " [ 2  8 19 13  7]\n",
      " [ 1  5  9 16 15]\n",
      " [ 1  1  6 16 30]]\n",
      "[52.53125, 52.53125, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.351485148515\n",
      "confusion matrix\n",
      " [[ 6  7  6  2  2]\n",
      " [ 9  9 11  4  2]\n",
      " [ 2  7 15 20  4]\n",
      " [ 2  6 12 14 19]\n",
      " [ 0  0  5 11 27]]\n",
      "[52.53125, 52.53125, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.371287128713\n",
      "confusion matrix\n",
      " [[ 8  6  5  2  1]\n",
      " [11 12  9  6  2]\n",
      " [ 6  3 13  9  7]\n",
      " [ 1  3 25 14 16]\n",
      " [ 1  2  4  8 28]]\n",
      "[52.53125, 52.53125, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.405940594059\n",
      "confusion matrix\n",
      " [[12  9  3  3  3]\n",
      " [ 4  8 10  9  1]\n",
      " [ 3  6 17 10  7]\n",
      " [ 2  6 13 14 15]\n",
      " [ 0  1  6  9 31]]\n",
      "[52.53125, 52.53125, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.405940594059\n",
      "confusion matrix\n",
      " [[ 9  9  6  6  2]\n",
      " [ 4 13  8  3  3]\n",
      " [ 7  4 21 12  4]\n",
      " [ 1 12  6 14 14]\n",
      " [ 2  4  6  7 25]]\n",
      "[52.53125, 52.53125, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.440594059406\n",
      "confusion matrix\n",
      " [[12  4  2  2  1]\n",
      " [ 7 13  9  9  1]\n",
      " [ 4  9 19  9  6]\n",
      " [ 1  2 16 12  8]\n",
      " [ 1  2  6 14 33]]\n",
      "[52.53125, 52.53125, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625, 52.265625]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.341584158416\n",
      "confusion matrix\n",
      " [[12  6  3  3  2]\n",
      " [15  7 10  1  3]\n",
      " [ 8 11 16 11  3]\n",
      " [ 3  5 13 12 14]\n",
      " [ 3  3  4 12 22]]\n",
      "[52.53125, 52.53515625, 52.26953125, 52.26953125, 52.26953125, 52.26953125, 52.26953125, 52.26953125, 52.26953125, 52.26953125, 52.26953125, 52.26953125]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.361386138614\n",
      "confusion matrix\n",
      " [[ 9  4  8  4  2]\n",
      " [ 1  9 10  6  4]\n",
      " [ 6  3 16 11 13]\n",
      " [ 0  2 15 15 24]\n",
      " [ 1  1  3 11 24]]\n",
      "[52.53515625, 52.53125, 52.26953125, 52.26953125, 52.26953125, 52.26953125, 52.26953125, 52.26953125, 52.26953125, 52.26953125]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.356435643564\n",
      "confusion matrix\n",
      " [[ 9 11  4  0  1]\n",
      " [ 9  6  9  4  4]\n",
      " [ 5  8 15 11 10]\n",
      " [ 3  3 14 14 12]\n",
      " [ 1  3  4 14 28]]\n",
      "[52.53515625, 52.53515625, 52.26953125, 52.26953125, 52.26953125, 52.26953125, 52.26953125, 52.26953125, 52.26953125, 52.26953125, 52.26953125, 52.26953125]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.376237623762\n",
      "confusion matrix\n",
      " [[ 3  5  6  1  4]\n",
      " [ 8 12 13  4  2]\n",
      " [ 4  7 12  8 12]\n",
      " [ 2  6 11 17 21]\n",
      " [ 0  0  3  9 32]]\n",
      "[52.53515625, 52.53125, 52.26953125, 52.26953125, 52.26953125, 52.26953125, 52.26953125, 52.26953125, 52.26953125, 52.2734375, 52.2734375, 52.2734375, 52.2734375]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.341584158416\n",
      "confusion matrix\n",
      " [[ 8 10  3  0  0]\n",
      " [ 2 17  5  0  2]\n",
      " [ 1 28 12  3  7]\n",
      " [ 2 31 10  6 13]\n",
      " [ 0  9  2  5 26]]\n",
      "[52.5390625, 52.5390625, 52.2734375, 52.2734375, 52.2734375, 52.2734375, 52.2734375, 52.2734375, 52.2734375]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.346534653465\n",
      "confusion matrix\n",
      " [[ 5  7  7  2  2]\n",
      " [ 7 12 12  6  2]\n",
      " [ 3  6 20 10 13]\n",
      " [ 4  3  9 10 24]\n",
      " [ 0  2  5  8 23]]\n",
      "[52.5390625, 52.54296875, 52.27734375, 52.27734375, 52.27734375, 52.27734375, 52.27734375, 52.27734375, 52.27734375, 52.27734375, 52.27734375, 52.27734375, 52.27734375]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.331683168317\n",
      "confusion matrix\n",
      " [[ 6 14 11  3  3]\n",
      " [ 6  9 10  5  6]\n",
      " [ 6  9 12 13 17]\n",
      " [ 0  2  5 16 14]\n",
      " [ 0  2  2  7 24]]\n",
      "[52.54296875, 52.54296875, 52.27734375, 52.27734375, 52.27734375, 52.27734375, 52.27734375, 52.27734375, 52.27734375, 52.27734375, 52.27734375, 52.27734375, 52.27734375, 52.27734375]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.356435643564\n",
      "confusion matrix\n",
      " [[ 6  8  6  2  2]\n",
      " [14  5 10  5  7]\n",
      " [ 7  8 16  8  9]\n",
      " [ 1  5  8 12 13]\n",
      " [ 0  1 10  6 33]]\n",
      "[52.54296875, 52.54296875, 52.27734375, 52.27734375, 52.27734375, 52.27734375, 52.27734375, 52.27734375, 52.27734375, 52.27734375, 52.27734375]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.376237623762\n",
      "confusion matrix\n",
      " [[ 9 11  4  0  1]\n",
      " [11  7  5  5  5]\n",
      " [ 4  6 14 10 10]\n",
      " [ 3  7 13 12 19]\n",
      " [ 1  0  5  6 34]]\n",
      "[52.54296875, 52.54296875, 52.27734375, 52.27734375, 52.27734375, 52.27734375, 52.27734375, 52.27734375, 52.27734375, 52.27734375, 52.27734375, 52.27734375, 52.27734375, 52.27734375, 52.27734375, 52.27734375]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.326732673267\n",
      "confusion matrix\n",
      " [[13 10  7  1  1]\n",
      " [ 9  9  7  3  2]\n",
      " [ 5 12 14 11 14]\n",
      " [ 2  5  8  5 19]\n",
      " [ 2  4  6  8 25]]\n",
      "[52.54296875, 52.54296875, 52.27734375, 52.27734375, 52.27734375, 52.27734375, 52.27734375, 52.27734375, 52.27734375, 52.2890625]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.371287128713\n",
      "confusion matrix\n",
      " [[10  5  2  4  1]\n",
      " [12  9  9  7  2]\n",
      " [ 9  6 26  9  6]\n",
      " [ 5  2 12  6 10]\n",
      " [ 4  2  4 16 24]]\n",
      "[52.5546875, 52.5546875, 52.2890625, 52.2890625, 52.2890625, 52.29296875, 52.29296875, 52.29296875, 52.29296875, 52.29296875, 52.29296875]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.321782178218\n",
      "confusion matrix\n",
      " [[ 8  4  8  4  2]\n",
      " [11  4  9  9  5]\n",
      " [12  4 16 11 10]\n",
      " [ 2  0  8 16 17]\n",
      " [ 0  2  7 12 21]]\n",
      "[52.55859375, 52.5546875, 52.29296875, 52.29296875, 52.29296875, 52.29296875, 52.29296875, 52.29296875, 52.29296875, 52.29296875, 52.29296875, 52.2890625, 52.2890625, 51.87109375]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.356435643564\n",
      "confusion matrix\n",
      " [[ 6  5  3  4  1]\n",
      " [ 7 11 10  5  4]\n",
      " [ 4  7 15 10  8]\n",
      " [ 1  5 17 10 23]\n",
      " [ 3  3  4  6 30]]\n",
      "[52.13671875, 52.13671875, 51.87109375, 51.87109375, 51.87109375, 51.87109375, 51.87109375, 51.87109375, 51.87109375]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.311881188119\n",
      "confusion matrix\n",
      " [[ 7  5  6  2  1]\n",
      " [ 5  6 13  5  5]\n",
      " [ 2  8 16  7 15]\n",
      " [ 5  2 20 11 14]\n",
      " [ 2  6  6 10 23]]\n",
      "[52.13671875, 52.13671875, 51.87109375, 51.87109375, 51.87109375, 51.87109375, 51.87109375, 51.87109375, 51.87109375]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.311881188119\n",
      "confusion matrix\n",
      " [[ 5 14  6  2  3]\n",
      " [ 5  6  6  5  7]\n",
      " [ 5  8 10 10  8]\n",
      " [ 4  5 11 10 17]\n",
      " [ 1  6  8  8 32]]\n",
      "[52.13671875, 52.13671875, 51.87109375, 51.87109375, 51.87109375, 51.87109375, 51.87109375, 51.87109375]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.356435643564\n",
      "confusion matrix\n",
      " [[10 12  7  0  2]\n",
      " [ 6  7  9  6  6]\n",
      " [ 6 10 18 11  5]\n",
      " [ 4  5 13 10 20]\n",
      " [ 2  0  2  4 27]]\n",
      "[52.13671875, 52.13671875, 51.87109375, 51.87109375, 51.87109375, 51.87109375, 51.87109375, 51.87109375]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.262376237624\n",
      "confusion matrix\n",
      " [[ 7  7  1  5  3]\n",
      " [10  5  8  2  4]\n",
      " [12 11 18 14 10]\n",
      " [ 4  8 12  8 15]\n",
      " [ 6  1  8  8 15]]\n",
      "[52.13671875, 52.13671875, 51.87109375, 51.87109375, 51.87109375, 51.87109375, 51.87109375, 51.87109375, 51.87109375]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.292079207921\n",
      "confusion matrix\n",
      " [[11 10  9  2  1]\n",
      " [13  5 10  5  7]\n",
      " [ 3  2 14 11 10]\n",
      " [ 7  5 15 12 14]\n",
      " [ 1  0  3 15 17]]\n",
      "[52.13671875, 52.13671875, 51.87109375, 51.87109375, 51.87109375, 51.87109375, 51.87109375, 51.87109375, 51.87109375]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.391089108911\n",
      "confusion matrix\n",
      " [[11  3  4  2  1]\n",
      " [17  8 13  4  4]\n",
      " [10  6 20 14  7]\n",
      " [ 5  2  7 17 12]\n",
      " [ 4  0  4  4 23]]\n",
      "[52.13671875, 52.13671875, 51.87109375, 51.87109375, 51.87109375, 51.87109375, 51.87109375, 51.87109375, 51.87109375]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.331683168317\n",
      "confusion matrix\n",
      " [[ 9  7  6  2  1]\n",
      " [14  7 14  5  2]\n",
      " [ 7  2 15 14 12]\n",
      " [ 3  4  9 10 17]\n",
      " [ 2  1  1 12 26]]\n",
      "[52.13671875, 52.13671875, 51.87109375, 51.87109375, 51.87109375, 51.87109375, 51.87109375]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.292079207921\n",
      "confusion matrix\n",
      " [[ 3  3 13  0  4]\n",
      " [ 4  7 12  3  3]\n",
      " [10  6 22 16  9]\n",
      " [ 2  5  9  7 26]\n",
      " [ 4  0  7  7 20]]\n",
      "[52.13671875, 52.13671875, 51.87109375, 51.87109375, 51.87109375, 51.87109375, 51.87109375]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.346534653465\n",
      "confusion matrix\n",
      " [[ 9  4  9  4  1]\n",
      " [ 8  9  8  5 10]\n",
      " [ 3 14 15  7  9]\n",
      " [ 2  5 10  9 22]\n",
      " [ 0  3  6  2 28]]\n",
      "[52.13671875, 52.13671875, 51.87109375, 51.87109375, 51.87109375, 51.87109375, 51.87109375, 51.87109375]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.341584158416\n",
      "confusion matrix\n",
      " [[ 7 10 13  1  1]\n",
      " [ 5  7 11  6  8]\n",
      " [ 4 13 14 11  9]\n",
      " [ 5  3  6 10 14]\n",
      " [ 1  3  2  7 31]]\n",
      "[52.13671875, 52.13671875, 51.87109375, 51.87109375, 51.87109375, 51.87109375, 51.87109375, 51.87109375]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.306930693069\n",
      "confusion matrix\n",
      " [[13  6 14  2  3]\n",
      " [ 5  4  7  4 10]\n",
      " [ 3  6 14  9 17]\n",
      " [ 1  7  7  5 28]\n",
      " [ 0  0  8  3 26]]\n",
      "[52.13671875, 52.13671875, 51.875, 51.875, 51.875, 51.875, 51.875, 51.875]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.321782178218\n",
      "confusion matrix\n",
      " [[ 6  7  6  5  2]\n",
      " [ 4  4 10  6  5]\n",
      " [ 3  7 14  6 21]\n",
      " [ 2  6  9  6 26]\n",
      " [ 4  0  1  7 35]]\n",
      "[52.140625, 52.140625, 51.875, 51.875, 51.875, 51.875, 51.875, 51.875]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.30198019802\n",
      "confusion matrix\n",
      " [[ 8  4  7  0  4]\n",
      " [ 8  5 16  7 10]\n",
      " [ 6  7 14  8 17]\n",
      " [ 1  2 10  4 21]\n",
      " [ 1  2  1  9 30]]\n",
      "[52.140625, 52.14453125, 51.87890625, 51.87890625, 51.87890625, 51.87890625, 51.87890625, 51.87890625, 51.87890625]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.336633663366\n",
      "confusion matrix\n",
      " [[13  4  3  2  1]\n",
      " [14  7 10  0  5]\n",
      " [14  8  7  6 17]\n",
      " [ 6  5  8  7 25]\n",
      " [ 2  1  2  1 34]]\n",
      "[52.14453125, 52.14453125, 51.87890625, 51.87890625, 51.87890625, 51.87890625, 51.87890625, 51.87890625, 51.87890625]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.326732673267\n",
      "confusion matrix\n",
      " [[12  4  7  4  1]\n",
      " [10  8 13  7  4]\n",
      " [ 8  4 13 13 10]\n",
      " [ 3  4  7 10 14]\n",
      " [ 2  1  7 13 23]]\n",
      "[52.14453125, 52.14453125, 51.87890625, 51.87890625, 51.87890625, 51.87890625, 51.87890625, 51.87890625, 51.87890625, 51.87890625]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.277227722772\n",
      "confusion matrix\n",
      " [[16  2  5  2  1]\n",
      " [23  2  5  3  8]\n",
      " [17  3  9  8 12]\n",
      " [ 6  1  9  4 26]\n",
      " [ 6  0  2  7 25]]\n",
      "[52.14453125, 52.14453125, 51.87890625, 51.87890625, 51.87890625, 51.87890625, 51.87890625, 51.87890625]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.346534653465\n",
      "confusion matrix\n",
      " [[11  4  5  1  1]\n",
      " [15  8  5  3  6]\n",
      " [11  5 15  8 17]\n",
      " [11  9  4  8 18]\n",
      " [ 4  1  2  2 28]]\n",
      "[52.14453125, 52.14453125, 51.87890625, 51.87890625, 51.87890625, 51.87890625, 51.87890625]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.321782178218\n",
      "confusion matrix\n",
      " [[15  2  0  2  2]\n",
      " [18  4  1  5  6]\n",
      " [14  2  5 14 16]\n",
      " [10  1  5 10 20]\n",
      " [ 2  2  2 13 31]]\n",
      "[52.14453125, 52.14453125, 51.87890625, 51.87890625, 51.87890625, 51.87890625, 51.87890625]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.341584158416\n",
      "confusion matrix\n",
      " [[16  2  6  1  0]\n",
      " [12  5  4  3  4]\n",
      " [ 6  3 11  6 22]\n",
      " [ 6  4  9  8 24]\n",
      " [ 4  1  1 15 29]]\n",
      "[52.14453125, 52.14453125, 51.87890625, 51.87890625, 51.87890625, 51.87890625, 51.87890625]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.366336633663\n",
      "confusion matrix\n",
      " [[ 8  7  3  2  0]\n",
      " [16  9  5  5  8]\n",
      " [11  8 13  7 10]\n",
      " [ 9  4  1  7 18]\n",
      " [ 5  1  3  5 37]]\n",
      "[52.14453125, 52.14453125, 51.87890625, 51.87890625, 51.87890625, 51.8828125, 51.8828125, 51.8828125]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.331683168317\n",
      "confusion matrix\n",
      " [[ 8 10  1  1  2]\n",
      " [16  7  1  8  6]\n",
      " [ 9 10  6  7 17]\n",
      " [ 6  4  3  9 25]\n",
      " [ 1  5  0  3 37]]\n",
      "[52.1484375, 52.1484375, 51.8828125, 51.8828125, 51.8828125, 51.8828125, 51.8828125, 51.8828125, 51.8828125]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.371287128713\n",
      "confusion matrix\n",
      " [[16  9  3  2  2]\n",
      " [12  9  0  3  5]\n",
      " [ 8 10 10  9 11]\n",
      " [ 4  4  4  5 35]\n",
      " [ 2  2  0  2 35]]\n",
      "[52.1484375, 52.1484375, 51.8828125, 51.8828125, 51.8828125, 51.8828125, 51.8828125]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.257425742574\n",
      "confusion matrix\n",
      " [[17  3  1  3  1]\n",
      " [19  5  2  6  9]\n",
      " [19  5  7  7 16]\n",
      " [10  8  3  7 19]\n",
      " [ 6  2  1 10 16]]\n",
      "[52.1484375, 52.1484375, 51.8828125, 51.8828125, 51.8828125, 51.8828125, 51.8828125, 51.8828125]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.306930693069\n",
      "confusion matrix\n",
      " [[10  5  1  1  2]\n",
      " [16  6  3  3 11]\n",
      " [11  8  9  6 17]\n",
      " [ 3  7  9 13 22]\n",
      " [ 4  1  3  7 24]]\n",
      "[52.1484375, 52.1484375, 51.8828125, 51.8828125, 51.8828125, 51.8828125, 51.8828125]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.287128712871\n",
      "confusion matrix\n",
      " [[10  6  3  1  5]\n",
      " [ 8 10  3 10  5]\n",
      " [10 16  8  9 16]\n",
      " [ 1  7  7  7 22]\n",
      " [ 3  2  3  7 23]]\n",
      "[52.1484375, 52.1484375, 51.88671875, 51.88671875, 51.88671875, 51.88671875, 51.88671875, 51.88671875, 51.88671875]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.366336633663\n",
      "confusion matrix\n",
      " [[17  7  5  1  5]\n",
      " [13  4  3  4  2]\n",
      " [11  7 12  6  7]\n",
      " [ 9  3  5  7 26]\n",
      " [ 1  1  5  7 34]]\n",
      "[52.15234375, 52.15234375, 51.88671875, 51.88671875, 51.88671875, 51.88671875, 51.88671875, 51.88671875, 51.88671875]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.29702970297\n",
      "confusion matrix\n",
      " [[12  7  3  3  3]\n",
      " [ 4  8  3  3  6]\n",
      " [ 6 14  5  4 22]\n",
      " [ 6 12  6  7 22]\n",
      " [ 1  5  4  8 28]]\n",
      "[52.15234375, 52.15234375, 51.890625, 51.890625, 51.890625, 51.890625, 51.890625, 51.890625]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.331683168317\n",
      "confusion matrix\n",
      " [[17 11  3  2  1]\n",
      " [16  6  6  6  2]\n",
      " [ 9  5  9  8 13]\n",
      " [ 9  3  6  5 18]\n",
      " [ 4  2  3  8 30]]\n",
      "[52.15625, 52.15625, 51.890625, 51.890625, 51.890625, 51.890625, 51.890625, 51.890625, 51.890625]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.311881188119\n",
      "confusion matrix\n",
      " [[12  7  1  2  3]\n",
      " [17  8  4  5  5]\n",
      " [ 4  6 10 16 15]\n",
      " [10  6  4  9 21]\n",
      " [ 4  3  2  4 24]]\n",
      "[52.15625, 52.15625, 51.890625, 51.890625, 51.890625, 51.890625, 51.890625, 51.890625]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.287128712871\n",
      "confusion matrix\n",
      " [[ 6  7  3  1  1]\n",
      " [ 9  9  5  4  5]\n",
      " [12 15  9  8 13]\n",
      " [ 9  3  8  3 22]\n",
      " [ 6  3  4  6 31]]\n",
      "[52.15625, 52.15625, 51.890625, 51.890625, 51.890625, 51.890625, 51.890625, 51.890625, 51.890625]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.361386138614\n",
      "confusion matrix\n",
      " [[17  6  6  2  2]\n",
      " [14 11  3  3  5]\n",
      " [10  7  9  8 14]\n",
      " [ 8  7  5  6 19]\n",
      " [ 2  0  4  4 30]]\n",
      "[52.15625, 52.15625, 51.890625, 51.890625, 51.890625, 51.890625, 51.890625, 51.890625]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.287128712871\n",
      "confusion matrix\n",
      " [[14  5  2  0  0]\n",
      " [20  6  5  3  4]\n",
      " [15  4 12 10  9]\n",
      " [ 7  2 16 13 11]\n",
      " [ 5  1  6 19 13]]\n",
      "[52.15625, 52.15625, 51.890625, 51.890625, 51.890625, 51.890625, 51.890625, 51.890625, 51.890625, 51.890625]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.272277227723\n",
      "confusion matrix\n",
      " [[ 5 11  5  2  3]\n",
      " [14  8  8  4  5]\n",
      " [13  4  9  8 17]\n",
      " [ 6  5  3  6 29]\n",
      " [ 3  2  1  4 27]]\n",
      "[52.15625, 52.15625, 51.890625, 51.890625, 51.890625, 51.890625, 51.890625, 51.890625, 51.890625]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.272277227723\n",
      "confusion matrix\n",
      " [[ 9  5  3  2  3]\n",
      " [ 8  9  8  6  6]\n",
      " [15  5  8 10 10]\n",
      " [ 9  2  7 15 12]\n",
      " [ 2  4  2 28 14]]\n",
      "[52.15625, 52.15625, 51.890625, 51.890625, 51.890625, 51.890625, 51.890625, 51.890625, 51.890625]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.282178217822\n",
      "confusion matrix\n",
      " [[18  3  3  0  4]\n",
      " [12  6  6  5  4]\n",
      " [ 9  6  8 10 11]\n",
      " [10  8 13 19  2]\n",
      " [ 2  2  8 27  6]]\n",
      "[52.15625, 52.15625, 51.890625, 51.890625, 51.890625, 51.890625, 51.890625, 51.890625]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.277227722772\n",
      "confusion matrix\n",
      " [[13  3  0  4  3]\n",
      " [17  4  3  7  9]\n",
      " [16 10 10 11  5]\n",
      " [ 9  1  6 14 14]\n",
      " [ 4  1  6 17 15]]\n",
      "[52.15625, 52.15625, 51.890625, 51.890625, 51.890625, 51.890625, 51.890625, 51.890625, 51.890625]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.311881188119\n",
      "confusion matrix\n",
      " [[ 9  6  3  1  3]\n",
      " [ 8 13  1  5  5]\n",
      " [10 10  9 12 15]\n",
      " [ 5  7  4 11 20]\n",
      " [ 0  1  2 21 21]]\n",
      "[52.15625, 52.15625, 51.890625, 51.890625, 51.890625, 51.890625, 51.890625]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.247524752475\n",
      "confusion matrix\n",
      " [[ 3 18  3  1  5]\n",
      " [ 4 16  6  3  6]\n",
      " [ 3 15 10  9  6]\n",
      " [ 8  9  4 10 15]\n",
      " [ 4  4  6 23 11]]\n",
      "[52.15625, 52.15625, 51.890625, 51.890625, 51.890625, 51.890625, 51.890625, 51.890625]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.237623762376\n",
      "confusion matrix\n",
      " [[ 5 11  0  0  5]\n",
      " [ 6 11  0  1 12]\n",
      " [15 10  4  0 28]\n",
      " [13  8  4  0 26]\n",
      " [ 7  2  6  0 28]]\n",
      "[52.15625, 52.15625, 51.890625, 51.890625, 51.890625, 51.890625, 51.890625]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.262376237624\n",
      "confusion matrix\n",
      " [[13  1  4  2  2]\n",
      " [11  2  8  5 10]\n",
      " [17  0 11  8 19]\n",
      " [10  1  9  7 17]\n",
      " [ 9  2  5  9 20]]\n",
      "[52.15625, 52.15625, 51.890625, 51.890625, 51.890625, 51.890625]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.272277227723\n",
      "confusion matrix\n",
      " [[16  2  0  1 18]\n",
      " [14  1  0  0 13]\n",
      " [20  0  1  1 27]\n",
      " [15  1  2  0 24]\n",
      " [ 5  1  3  0 37]]\n",
      "[52.15625, 52.15625, 51.890625, 51.890625, 51.890625, 51.890625]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.237623762376\n",
      "confusion matrix\n",
      " [[15  0  1  1  8]\n",
      " [16  0  1  6 13]\n",
      " [20  0  2  6 21]\n",
      " [12  0  8  5 23]\n",
      " [11  0  3  4 26]]\n",
      "[52.15625, 52.15625, 51.890625, 51.890625, 51.890625, 51.890625]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.227722772277\n",
      "confusion matrix\n",
      " [[ 8  0  0 10  3]\n",
      " [22  0  1  9  4]\n",
      " [23  0  1 11 14]\n",
      " [12  0  6 10 16]\n",
      " [ 9  2  2 12 27]]\n",
      "[52.15625, 52.15625, 51.890625, 51.890625, 51.890625, 51.890625]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.232673267327\n",
      "confusion matrix\n",
      " [[14  0  0  3 11]\n",
      " [25  0  0  1 13]\n",
      " [29  1  1  3 16]\n",
      " [18  2  0  2 22]\n",
      " [11  0  0  0 30]]\n",
      "[52.15625, 52.15625, 51.890625, 51.890625, 51.89453125, 51.89453125]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.282178217822\n",
      "confusion matrix\n",
      " [[20  2  0  1 11]\n",
      " [17  7  0  4 13]\n",
      " [15 11  1  2 20]\n",
      " [ 9  9  3  1 16]\n",
      " [ 3  7  0  2 28]]\n",
      "[52.16015625, 52.16015625, 51.89453125, 51.89453125, 51.89453125, 51.89453125]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.267326732673\n",
      "confusion matrix\n",
      " [[ 7  0  6  1  9]\n",
      " [10  1 10  1 13]\n",
      " [19  0 11  2 20]\n",
      " [ 8  3  8  1 25]\n",
      " [ 6  4  2  1 34]]\n",
      "[52.16015625, 52.16015625, 51.89453125, 51.89453125, 51.89453125]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.193069306931\n",
      "confusion matrix\n",
      " [[12  5  0  1 12]\n",
      " [17  1  1  1  8]\n",
      " [16  7  1  3 26]\n",
      " [ 9  7  1  2 26]\n",
      " [11 10  0  2 23]]\n",
      "[52.16015625, 52.16015625, 51.89453125, 51.89453125, 51.89453125, 51.89453125, 51.89453125]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.232673267327\n",
      "confusion matrix\n",
      " [[11  0  2  0 10]\n",
      " [15  0  7  3 15]\n",
      " [14  0  8  1 24]\n",
      " [12  1  5  1 34]\n",
      " [ 5  0  6  1 27]]\n",
      "[52.16015625, 52.16015625, 51.89453125, 51.89453125, 51.89453125, 51.89453125, 51.89453125]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.252475247525\n",
      "confusion matrix\n",
      " [[ 3 11  0  5  9]\n",
      " [ 5 18  0  7  8]\n",
      " [ 8 15  0  3 19]\n",
      " [ 3 15  0  4 28]\n",
      " [ 0 11  1  3 26]]\n",
      "[52.16015625, 52.16015625, 51.89453125, 51.89453125, 51.89453125, 51.89453125]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.237623762376\n",
      "confusion matrix\n",
      " [[15  0  0  1 10]\n",
      " [24  0  1  2 15]\n",
      " [18  0 10  1 27]\n",
      " [13  1  5  0 18]\n",
      " [12  0  6  0 23]]\n",
      "[52.16015625, 52.16015625, 51.89453125, 51.89453125, 51.89453125, 51.89453125]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.247524752475\n",
      "confusion matrix\n",
      " [[11  0  0  1 10]\n",
      " [ 8  7  0  6 19]\n",
      " [16  3  2  1 26]\n",
      " [ 6 10  5  1 27]\n",
      " [ 2  8  3  1 29]]\n",
      "[52.16015625, 52.16015625, 51.89453125, 51.89453125, 51.89453125, 51.89453125]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.247524752475\n",
      "confusion matrix\n",
      " [[10  0  0  2  7]\n",
      " [16  0  1  3 15]\n",
      " [23  0  1  4 17]\n",
      " [19  0  4  1 25]\n",
      " [10  0  5  1 38]]\n",
      "[52.16015625, 52.16015625, 51.89453125, 51.89453125, 51.89453125, 51.89453125, 51.89453125]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.262376237624\n",
      "confusion matrix\n",
      " [[11  3  0  2 12]\n",
      " [11 13  1  1 13]\n",
      " [13 11  0  0 20]\n",
      " [ 7 10  0  2 29]\n",
      " [ 4 10  1  1 27]]\n",
      "[52.16015625, 52.16015625, 51.89453125, 51.89453125, 51.89453125, 51.89453125, 51.89453125]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.306930693069\n",
      "confusion matrix\n",
      " [[ 7 10  0  2 11]\n",
      " [ 8 17  1  2  9]\n",
      " [ 4 19  0  2 20]\n",
      " [ 3 10  3  4 24]\n",
      " [ 2  8  1  1 34]]\n",
      "[52.16015625, 52.16015625, 51.89453125, 51.89453125, 51.89453125, 51.89453125, 51.89453125, 51.89453125]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.212871287129\n",
      "confusion matrix\n",
      " [[12  7  0  0 13]\n",
      " [19  3  0  3 10]\n",
      " [12  9  0  2 21]\n",
      " [ 9 12  4  1 28]\n",
      " [ 2  7  1  0 27]]\n",
      "[52.16015625, 52.16015625, 51.89453125, 51.89453125, 51.89453125, 51.89453125]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.272277227723\n",
      "confusion matrix\n",
      " [[16  0  0  0 13]\n",
      " [13  0  0  1 22]\n",
      " [16  5  0  3 24]\n",
      " [12  4  2  2 22]\n",
      " [ 2  8  0  0 37]]\n",
      "[52.16015625, 52.16015625, 51.89453125, 51.89453125, 51.89453125, 51.89453125]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.212871287129\n",
      "confusion matrix\n",
      " [[ 7  0  3  0 10]\n",
      " [17  0  6  4 16]\n",
      " [17  0  5  2 24]\n",
      " [ 4  1  8  1 31]\n",
      " [ 4  0  8  4 30]]\n",
      "[52.16015625, 52.1640625, 51.8984375, 51.8984375, 51.8984375, 51.8984375, 51.8984375]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.237623762376\n",
      "confusion matrix\n",
      " [[11  0  0  1  8]\n",
      " [12  1  1  3 14]\n",
      " [19  3  3  4 23]\n",
      " [11  4  4  1 27]\n",
      " [13  5  0  2 32]]\n",
      "[52.1640625, 52.1640625, 51.8984375, 51.8984375, 51.8984375, 51.8984375]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.20297029703\n",
      "confusion matrix\n",
      " [[12  0  0  1 11]\n",
      " [23  0  1  1 13]\n",
      " [26  0  1  2 28]\n",
      " [17  0  1  2 29]\n",
      " [ 5  1  2  0 26]]\n",
      "[52.1640625, 52.1640625, 51.8984375, 51.8984375, 51.8984375]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.237623762376\n",
      "confusion matrix\n",
      " [[16  0  0  8  2]\n",
      " [16  3  0  8  5]\n",
      " [24  1  0 12 18]\n",
      " [15  1  1  5 24]\n",
      " [ 7  0  3  9 24]]\n",
      "[52.1640625, 52.16015625, 51.8984375, 51.8984375, 51.8984375, 51.8984375, 51.8984375]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.227722772277\n",
      "confusion matrix\n",
      " [[10  0  2  1  6]\n",
      " [12  3  4  0 20]\n",
      " [17  8  2  1 24]\n",
      " [13  8  3  0 27]\n",
      " [ 5  2  3  0 31]]\n",
      "[52.1640625, 52.1640625, 51.8984375, 51.8984375, 51.8984375, 51.8984375]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.212871287129\n",
      "confusion matrix\n",
      " [[12  0  0  0  9]\n",
      " [19  0  2  0 16]\n",
      " [21  0  0  0 27]\n",
      " [14  0  4  0 30]\n",
      " [14  0  2  1 31]]\n",
      "[52.1640625, 52.1640625, 51.8984375, 51.8984375, 51.8984375, 51.8984375]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.242574257426\n",
      "confusion matrix\n",
      " [[22  1  0  0 15]\n",
      " [16  0  1  0 16]\n",
      " [19  1  2  4 14]\n",
      " [15  6  2  2 29]\n",
      " [ 8  2  3  1 23]]\n",
      "[52.1640625, 52.1640625, 51.8984375, 51.8984375, 51.8984375, 51.8984375]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.207920792079\n",
      "confusion matrix\n",
      " [[11  1  0  2 12]\n",
      " [20  0  0  1 13]\n",
      " [23  1  3  1 26]\n",
      " [20  1  2  1 28]\n",
      " [ 7  0  2  0 27]]\n",
      "[52.1640625, 52.1640625, 51.8984375, 51.8984375, 51.8984375, 51.8984375, 51.8984375]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.29702970297\n",
      "confusion matrix\n",
      " [[19  0  0  3  6]\n",
      " [16  2  1  6  2]\n",
      " [19  0  1 12 18]\n",
      " [17  0  3  9 20]\n",
      " [ 7  1  4  7 29]]\n",
      "[52.1640625, 52.1640625, 51.8984375, 51.8984375, 51.8984375, 51.8984375]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.282178217822\n",
      "confusion matrix\n",
      " [[ 3 14  0  4  4]\n",
      " [ 6 20  1  3 10]\n",
      " [ 0 12  1  7 16]\n",
      " [ 5 17  0  8 23]\n",
      " [ 0 15  1  7 25]]\n",
      "[52.1640625, 52.1640625, 51.8984375, 51.8984375, 51.8984375, 51.8984375]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.207920792079\n",
      "confusion matrix\n",
      " [[14  1  0  2 13]\n",
      " [20  1  1  4 15]\n",
      " [15  0  2  4 21]\n",
      " [11  1  3  3 29]\n",
      " [12  2  2  4 22]]\n",
      "[52.1640625, 52.1640625, 51.8984375, 51.8984375, 51.8984375, 51.8984375]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.227722772277\n",
      "confusion matrix\n",
      " [[ 0 22  0  0  5]\n",
      " [ 0 15  0  5 11]\n",
      " [ 1 24  2  5 21]\n",
      " [ 1 17  4  3 24]\n",
      " [ 0 11  1  4 26]]\n",
      "[52.1640625, 52.1640625, 51.8984375, 51.8984375, 51.8984375, 51.8984375, 51.8984375]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.217821782178\n",
      "confusion matrix\n",
      " [[13  1  0  0  9]\n",
      " [21  0  0  1 18]\n",
      " [18  0  0  2 29]\n",
      " [16  1  3  0 28]\n",
      " [ 7  2  2  0 31]]\n",
      "[52.1640625, 52.1640625, 51.8984375, 51.8984375, 51.8984375, 51.8984375]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.207920792079\n",
      "confusion matrix\n",
      " [[ 7  0  0  2  6]\n",
      " [18  1  1  3 12]\n",
      " [23  0  0  0 24]\n",
      " [27  0  1  1 30]\n",
      " [10  0  3  0 33]]\n",
      "[52.1640625, 52.1640625, 51.8984375, 51.8984375, 51.8984375, 51.8984375, 51.8984375]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.242574257426\n",
      "confusion matrix\n",
      " [[11  1  0  0 12]\n",
      " [14  0  0  4 14]\n",
      " [25  0  0  1 23]\n",
      " [12  5  1  0 28]\n",
      " [11  1  0  1 38]]\n",
      "[52.1640625, 52.1640625, 51.8984375, 51.8984375, 51.8984375, 51.8984375, 51.8984375]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.247524752475\n",
      "confusion matrix\n",
      " [[21  0  0  5  5]\n",
      " [14  0  1 10  4]\n",
      " [16  0  2 14 15]\n",
      " [12  0  5  9 26]\n",
      " [ 9  0  7  9 18]]\n",
      "[52.1640625, 52.1640625, 51.8984375, 51.8984375, 51.8984375, 51.8984375]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.29702970297\n",
      "confusion matrix\n",
      " [[ 2 16  0  7  7]\n",
      " [ 1 19  0  7  6]\n",
      " [ 1 18  2  5 20]\n",
      " [ 0 14  3  6 18]\n",
      " [ 0 13  1  5 31]]\n",
      "[52.1640625, 52.1640625, 51.8984375, 51.8984375, 51.8984375, 51.8984375, 51.8984375]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.267326732673\n",
      "confusion matrix\n",
      " [[ 5  0  4  1  9]\n",
      " [14  2  8  2 17]\n",
      " [ 9  0  9  1 15]\n",
      " [ 9  2 16  0 27]\n",
      " [ 2  1 10  1 38]]\n",
      "[52.1640625, 52.1640625, 51.8984375, 51.8984375, 51.8984375, 51.8984375, 51.8984375]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.207920792079\n",
      "confusion matrix\n",
      " [[12  0  0  1 15]\n",
      " [26  0  0  2 10]\n",
      " [18  1  1  3 28]\n",
      " [14  2  0  3 24]\n",
      " [14  1  1  0 26]]\n",
      "[52.1640625, 52.16796875, 51.90234375, 51.90234375, 51.90234375, 51.90234375, 51.90234375, 51.90234375]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.287128712871\n",
      "confusion matrix\n",
      " [[ 5 11  0  0  9]\n",
      " [ 3 17  0  2  8]\n",
      " [ 2 23  1  2 30]\n",
      " [ 1  9  1  4 32]\n",
      " [ 0  8  1  2 31]]\n",
      "[52.16796875, 52.16796875, 51.90234375, 51.90234375, 51.90234375, 51.90234375, 51.90234375, 51.90234375, 51.90234375]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.292079207921\n",
      "confusion matrix\n",
      " [[ 4  8  0  0 10]\n",
      " [ 4 21  0  3 15]\n",
      " [ 1 11  0  2 30]\n",
      " [ 3 15  3  1 23]\n",
      " [ 0 12  3  0 33]]\n",
      "[52.16796875, 52.16796875, 51.90234375, 51.90234375, 51.90234375, 51.90234375]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.19801980198\n",
      "confusion matrix\n",
      " [[15  0  0  1 10]\n",
      " [18  2  0  1 19]\n",
      " [24  5  0  0 22]\n",
      " [10  5  0  0 32]\n",
      " [ 7  8  0  0 23]]\n",
      "[52.16796875, 52.16796875, 51.90234375, 51.90234375, 51.90234375, 51.90234375, 51.90234375]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.252475247525\n",
      "confusion matrix\n",
      " [[15  0  0  1 11]\n",
      " [21  1  1  1 12]\n",
      " [33  1  0  1 17]\n",
      " [18  3  0  1 20]\n",
      " [ 6  5  0  0 34]]\n",
      "[52.16796875, 52.1640625, 51.90234375, 51.90234375, 51.90234375, 51.90234375, 51.90234375, 51.90234375, 51.90234375]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.247524752475\n",
      "confusion matrix\n",
      " [[15  2  0  2 12]\n",
      " [18  1  2  0 13]\n",
      " [16  0  0  1 23]\n",
      " [17  4  2  2 26]\n",
      " [10  2  1  1 32]]\n",
      "[52.16796875, 52.16796875, 51.90234375, 51.90234375, 51.90234375, 51.90234375, 51.90234375, 51.90234375, 51.90234375]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.247524752475\n",
      "confusion matrix\n",
      " [[16  1  0  0 10]\n",
      " [15  2  2  0 11]\n",
      " [21  3  3  1 24]\n",
      " [17  4  2  0 31]\n",
      " [ 3  4  1  2 29]]\n",
      "[52.16796875, 52.16796875, 51.90234375, 51.90234375, 51.90234375, 51.90234375, 51.90234375, 51.90234375]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.222772277228\n",
      "confusion matrix\n",
      " [[10  0  0  5  6]\n",
      " [11  1  0  9  3]\n",
      " [32  1  0 12  9]\n",
      " [14  1  1 25 12]\n",
      " [12  0  0 29  9]]\n"
     ]
    }
   ],
   "source": [
    "# run logistic regression and vary some parameters\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "# first we create a reusable logisitic regression object\n",
    "#   here we can setup the object with different learning parameters and constants\n",
    "lr_clf_accuracies = []\n",
    "lr_clf_times = []\n",
    "lr_clf_mem = []\n",
    "\n",
    "costs = np.logspace(-3,1)\n",
    "costs.sort()\n",
    "\n",
    "cost_accuracies = []\n",
    "\n",
    "with np.errstate(all='ignore'):\n",
    "    for cost in costs:\n",
    "        mglr = MultiClassLogisticRegression(eta=0.1,iterations=5000, C=cost, optimization=\"BFGSBinaryLogisticRegression\",reg=0) # get object\n",
    "\n",
    "        lr_clf = Pipeline([ ('pca', pca), (\"multiclasslogregression\", mglr)])\n",
    "        # now we can use the cv_object that we setup before to iterate through the \n",
    "        #    different training and testing sets. Each time we will reuse the logisitic regression \n",
    "        #    object, but it gets trained on different data each time we use it.\n",
    "\n",
    "        iter_num=0\n",
    "        # the indices are the rows used for training and testing in each iteration\n",
    "        for train_indices, test_indices in cv_object.split(X,y): \n",
    "            # I will create new variables here so that it is more obvious what \n",
    "            # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "            # but it makes this code less readable)\n",
    "            X_train = (X[train_indices])\n",
    "            y_train = y[train_indices]\n",
    "\n",
    "        #     print(X_train)\n",
    "        #     print(y_train)\n",
    "\n",
    "            X_test = (X[test_indices])\n",
    "            y_test = y[test_indices]\n",
    "\n",
    "            st = time.time()\n",
    "\n",
    "            mem = memory_usage((lr_clf.fit,(X_train,y_train))) # train object\n",
    "            print(mem)\n",
    "            t = (time.time() -st)\n",
    "            lr_clf_times.append(t)\n",
    "            lr_clf_mem.append(mem[0])\n",
    "\n",
    "            # train the reusable logisitc regression model on the training data\n",
    "            y_hat = lr_clf.predict(X_test) # get test set precitions\n",
    "\n",
    "            # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "            acc = mt.accuracy_score(y_test,y_hat+1)\n",
    "            lr_clf_accuracies.append(acc)\n",
    "            cost_accuracies.append([acc])\n",
    "\n",
    "            conf = mt.confusion_matrix(y_test,y_hat+1)\n",
    "            print(\"====Iteration\",iter_num,\" ====\")\n",
    "            print(\"accuracy\", acc )\n",
    "            print(\"confusion matrix\\n\",conf)\n",
    "            iter_num+=1\n",
    "\n",
    "    # Also note that every time you run the above code\n",
    "    #   it randomly creates a new training and testing set, \n",
    "    #   so accuracy will be different each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d25d898>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEjCAYAAAAhczZxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nygAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10fe1f860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d25d898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "li = [np.arange(1,51)]\n",
    "plt.plot(cost_accuracies)\n",
    "plt.title(\"Determining Optimal Value of Regularization Term C\")\n",
    "plt.xlabel('Value of C ')\n",
    "plt.ylabel('Accuracy (%) ')\n",
    "costs_plot = np.around(costs,decimals=2)\n",
    "plt.xticks(li[0],costs_plot, rotation=90)\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=3, random_state=None, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,test_size = 0.2)\n",
    "\n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Varying Eta, Iterations, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "For  LineSearchLogisticRegression  Accuracy of:  0.272277227723\n",
      "confusion matrix\n",
      " [[17  1  2  3  6]\n",
      " [19  0  6  5  9]\n",
      " [13  0  6  4 23]\n",
      " [16  0  4  5 29]\n",
      " [ 4  0  3  0 27]]\n",
      "====Iteration 1  ====\n",
      "For  LineSearchLogisticRegression  Accuracy of:  0.232673267327\n",
      "confusion matrix\n",
      " [[ 0  0  0 25  0]\n",
      " [ 0  0  0 42  0]\n",
      " [ 0  0  1 56  0]\n",
      " [ 0  0  0 38  0]\n",
      " [ 0  0  0 32  8]]\n",
      "====Iteration 2  ====\n",
      "For  LineSearchLogisticRegression  Accuracy of:  0.277227722772\n",
      "confusion matrix\n",
      " [[ 0  0  2 25  0]\n",
      " [ 0  0  1 36  0]\n",
      " [ 0  0  3 47  0]\n",
      " [ 0  0  0 53  0]\n",
      " [ 0  0  1 34  0]]\n"
     ]
    }
   ],
   "source": [
    "# run logistic regression and vary some parameters\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "# first we create a reusable logisitic regression object\n",
    "#   here we can setup the object with different learning parameters and constants\n",
    "\n",
    "#optimizations = [\"BFGSBinaryLogisticRegression\",\"StochasticLogisticRegression\",\"LineSearchLogisticRegression\"]\n",
    "optimizations = [\"BFGSBinaryLogisticRegression\"]\n",
    "etas = [0.1, 0.1, 0.001]\n",
    "iters = [10, 5000, 150]\n",
    "\n",
    "lr_clf = MultiClassLogisticRegression(eta=eta,iterations=iter_, C=0.02, optimization=optimization,reg=0) # get object\n",
    "\n",
    "\n",
    "# now we can use the cv_object that we setup before to iterate through the \n",
    "#    different training and testing sets. Each time we will reuse the logisitic regression \n",
    "#    object, but it gets trained on different data each time we use it.\n",
    "\n",
    "iter_num=0\n",
    "# the indices are the rows used for training and testing in each iteration\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    # I will create new variables here so that it is more obvious what \n",
    "    # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "    # but it makes this code less readable)\n",
    "    X_train = (X[train_indices])\n",
    "    y_train = y[train_indices]\n",
    "\n",
    "#     print(X_train)\n",
    "#     print(y_train)\n",
    "\n",
    "    X_test = (X[test_indices])\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "#         st = time.time()\n",
    "\n",
    "    lr_clf.fit(X_train,y_train)  # train object\n",
    "#         t = (time.time() -st)\n",
    "#         lr_clf_times.append(t)\n",
    "\n",
    "    lr_clf.fit(X_train,y_train)\n",
    "\n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    y_hat = lr_clf.predict(X_test) # get test set precitions\n",
    "\n",
    "    # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "    acc = mt.accuracy_score(y_test,y_hat+1)\n",
    "#         lr_clf_accuracies.append(acc)\n",
    "#         cost_accuracies.append([acc])\n",
    "\n",
    "    conf = mt.confusion_matrix(y_test,y_hat+1)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print('For ',optimization,' Accuracy of: ',acc)\n",
    "\n",
    "    #print(\"accuracy\", acc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing our Best Logistic Regression Optimization Procedure to that of Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations  [ 72  67 186  90 172]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.247524752475\n",
      "confusion matrix\n",
      " [[ 0  1 21  0  0]\n",
      " [ 0  1 34  0  0]\n",
      " [ 0  1 49  0  0]\n",
      " [ 0  1 39  0  0]\n",
      " [ 0  3 52  0  0]]\n",
      "Iterations  [198  95  66  60 179]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.257425742574\n",
      "confusion matrix\n",
      " [[ 0  1 23  0  0]\n",
      " [ 0  1 33  0  0]\n",
      " [ 0  4 51  0  0]\n",
      " [ 0  1 41  0  0]\n",
      " [ 0  0 47  0  0]]\n",
      "Iterations  [151  45  71  89 180]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.217821782178\n",
      "confusion matrix\n",
      " [[ 0  2 26  0  0]\n",
      " [ 0  1 37  0  0]\n",
      " [ 0  2 43  0  0]\n",
      " [ 0  2 41  0  0]\n",
      " [ 0  0 48  0  0]]\n",
      "[0.2574019432067871, 0.2623918056488037, 0.24112296104431152]\n"
     ]
    }
   ],
   "source": [
    "# run logistic regression and vary some parameters\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.linear_model import LogisticRegression as SKLogisticRegression\n",
    "# first we create a reusable logisitic regression object\n",
    "#   here we can setup the object with different learning parameters and constants\n",
    "\n",
    "\n",
    "lr_sk = SKLogisticRegression(solver='lbfgs',class_weight='balanced',max_iter=500,C=0.002) \n",
    "\n",
    "lr_sk_accuracies = []\n",
    "lr_sk_times = []\n",
    "lr_sk_mem = []\n",
    "# now we can use the cv_object that we setup before to iterate through the \n",
    "#    different training and testing sets. Each time we will reuse the logisitic regression \n",
    "#    object, but it gets trained on different data each time we use it.\n",
    "\n",
    "iter_num=0\n",
    "# the indices are the rows used for training and testing in each iteration\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    # I will create new variables here so that it is more obvious what \n",
    "    # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "    # but it makes this code less readable)\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "#     print(X_train)\n",
    "#     print(y_train)\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    st = time.time()\n",
    "    mem = memory_usage((lr_sk.fit,(X_train,y_train)))\n",
    "    #lr_sk.fit(X_train,y_train)\n",
    "    t = (time.time() -st)\n",
    "    lr_sk_times.append(t)\n",
    "    lr_sk_mem.append(mem[0])\n",
    "    #print(np.hstack((lr_sk.intercept_[:,np.newaxis],lr_sk.coef_)))\n",
    "    yhat = lr_sk.predict(X_test)\n",
    " \n",
    "    print(\"Iterations \",lr_sk.n_iter_)\n",
    "    # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    lr_sk_accuracies.append(acc)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"accuracy\", acc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1\n",
    "\n",
    "print(lr_sk_times)\n",
    "# Also note that every time you run the above code\n",
    "#   it randomly creates a new training and testing set, \n",
    "#   so accuracy will be different each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.07451820373535\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11080c048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1108cf3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot([lr_sk_accuracies,lr_clf_accuracies])\n",
    "plt.title(\"Comparing Accuracies\")\n",
    "plt.xlabel('Implementation of Logistic Regression')\n",
    "plt.xticks([1,2],['SKL','OURS'])\n",
    "plt.figure()\n",
    "print((time.time() -st)*100)\n",
    "# ax = fig.add_subplot(111)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2574019432067871, 0.2623918056488037, 0.24112296104431152]\n",
      "[0.5850119590759277, 0.6018118858337402, 0.5404911041259766, 0.6523590087890625, 0.6516342163085938, 0.6441960334777832, 0.5834469795227051, 0.5534920692443848, 0.6882219314575195, 0.6670000553131104, 0.7289450168609619, 0.4853949546813965, 0.6312539577484131, 0.5740299224853516, 0.7087850570678711, 0.5880670547485352, 0.6415519714355469, 0.8173599243164062, 0.6528809070587158, 0.607017993927002, 0.6701700687408447, 0.66845703125, 0.5050959587097168, 0.5645449161529541, 0.7802238464355469, 0.5904569625854492, 0.600836992263794, 0.5712587833404541, 0.5388598442077637, 1.0808320045471191, 0.8679070472717285, 0.8312151432037354, 0.6792759895324707, 0.5945329666137695, 0.4981689453125, 0.38080906867980957, 0.5634069442749023, 0.39070701599121094, 0.5687849521636963, 0.47400593757629395, 0.4096848964691162, 0.4962728023529053, 0.46185803413391113, 0.4719669818878174, 0.22824406623840332, 0.41971302032470703, 0.6084411144256592, 0.43743014335632324, 0.6265170574188232, 0.6277170181274414]\n"
     ]
    }
   ],
   "source": [
    "print(lr_sk_times)\n",
    "print(lr_clf_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5850119590759277, 0.6018118858337402, 0.5404911041259766, 0.6523590087890625, 0.6516342163085938, 0.6441960334777832, 0.5834469795227051, 0.5534920692443848, 0.6882219314575195, 0.6670000553131104, 0.7289450168609619, 0.4853949546813965, 0.6312539577484131, 0.5740299224853516, 0.7087850570678711, 0.5880670547485352, 0.6415519714355469, 0.8173599243164062, 0.6528809070587158, 0.607017993927002, 0.6701700687408447, 0.66845703125, 0.5050959587097168, 0.5645449161529541, 0.7802238464355469, 0.5904569625854492, 0.600836992263794, 0.5712587833404541, 0.5388598442077637, 1.0808320045471191, 0.8679070472717285, 0.8312151432037354, 0.6792759895324707, 0.5945329666137695, 0.4981689453125, 0.38080906867980957, 0.5634069442749023, 0.39070701599121094, 0.5687849521636963, 0.47400593757629395, 0.4096848964691162, 0.4962728023529053, 0.46185803413391113, 0.4719669818878174, 0.22824406623840332, 0.41971302032470703, 0.6084411144256592, 0.43743014335632324, 0.6265170574188232, 0.6277170181274414]\n"
     ]
    }
   ],
   "source": [
    "print(lr_clf_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110b77cf8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110b77f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110b77cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot([lr_sk_times,lr_clf_times])\n",
    "plt.title(\"Comparing Training Times\")\n",
    "plt.xlabel('Implementation of Logistic Regression')\n",
    "plt.ylabel('Training Time (seconds) ')\n",
    "plt.xticks([1,2],['SKL','OURS'])\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.55078125\n"
     ]
    }
   ],
   "source": [
    "print(lr_sk_mem[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-6d14c5d159b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlr_sk_mem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr_clf_mem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Comparing Memory \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Implementation of Logistic Regression'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Memory Usage (mb) '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SKL'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'OURS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Omar/anaconda/lib/python3.5/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mboxplot\u001b[0;34m(x, notch, sym, vert, whis, positions, widths, patch_artist, bootstrap, usermedians, conf_intervals, meanline, showmeans, showcaps, showbox, showfliers, boxprops, labels, flierprops, medianprops, meanprops, capprops, whiskerprops, manage_xticks, autorange, zorder, hold, data)\u001b[0m\n\u001b[1;32m   2784\u001b[0m                          \u001b[0mwhiskerprops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhiskerprops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2785\u001b[0m                          \u001b[0mmanage_xticks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanage_xticks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautorange\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautorange\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2786\u001b[0;31m                          zorder=zorder, data=data)\n\u001b[0m\u001b[1;32m   2787\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2788\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Omar/anaconda/lib/python3.5/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1890\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1891\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1892\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1893\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1894\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Omar/anaconda/lib/python3.5/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mboxplot\u001b[0;34m(self, x, notch, sym, vert, whis, positions, widths, patch_artist, bootstrap, usermedians, conf_intervals, meanline, showmeans, showcaps, showbox, showfliers, boxprops, labels, flierprops, medianprops, meanprops, capprops, whiskerprops, manage_xticks, autorange, zorder)\u001b[0m\n\u001b[1;32m   3266\u001b[0m             \u001b[0mbootstrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'boxplot.bootstrap'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3267\u001b[0m         bxpstats = cbook.boxplot_stats(x, whis=whis, bootstrap=bootstrap,\n\u001b[0;32m-> 3268\u001b[0;31m                                        labels=labels, autorange=autorange)\n\u001b[0m\u001b[1;32m   3269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnotch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3270\u001b[0m             \u001b[0mnotch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'boxplot.notch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Omar/anaconda/lib/python3.5/site-packages/matplotlib/cbook.py\u001b[0m in \u001b[0;36mboxplot_stats\u001b[0;34m(X, whis, bootstrap, labels, autorange)\u001b[0m\n\u001b[1;32m   2021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2022\u001b[0m         \u001b[0;31m# up-convert to an array, just to be safe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2023\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2025\u001b[0m         \u001b[0;31m# arithmetic mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Omar/anaconda/lib/python3.5/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \"\"\"\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11024bb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot([lr_sk_mem[0],lr_clf_mem])\n",
    "plt.title(\"Comparing Memory \")\n",
    "plt.xlabel('Implementation of Logistic Regression')\n",
    "plt.ylabel('Memory Usage (mb) ')\n",
    "plt.xticks([1,2],['SKL','OURS'])\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing which implementation of Logistic Regression would be best for our case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exceptional Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Below is our usage of our implementation of GridSearchCV. We chose a scoring for accuracy and used our BFGS implementation as our estimator. We want to find the best Cost value that GridSearchCV recommends and compare it with our decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.001}\n",
      "{'C': 0.001}\n",
      "{'C': 0.001}\n",
      "{'C': 0.0012067926406393288}\n",
      "{'C': 0.0012067926406393288}\n",
      "{'C': 0.0012067926406393288}\n",
      "{'C': 0.0014563484775012444}\n",
      "{'C': 0.0014563484775012444}\n",
      "{'C': 0.0014563484775012444}\n",
      "{'C': 0.0017575106248547913}\n",
      "{'C': 0.0017575106248547913}\n",
      "{'C': 0.0017575106248547913}\n",
      "{'C': 0.0021209508879201904}\n",
      "{'C': 0.0021209508879201904}\n",
      "{'C': 0.0021209508879201904}\n",
      "{'C': 0.0025595479226995358}\n",
      "{'C': 0.0025595479226995358}\n",
      "{'C': 0.0025595479226995358}\n",
      "{'C': 0.0030888435964774815}\n",
      "{'C': 0.0030888435964774815}\n",
      "{'C': 0.0030888435964774815}\n",
      "{'C': 0.0037275937203149379}\n",
      "{'C': 0.0037275937203149379}\n",
      "{'C': 0.0037275937203149379}\n",
      "{'C': 0.0044984326689694442}\n",
      "{'C': 0.0044984326689694442}\n",
      "{'C': 0.0044984326689694442}\n",
      "{'C': 0.0054286754393238594}\n",
      "{'C': 0.0054286754393238594}\n",
      "{'C': 0.0054286754393238594}\n",
      "{'C': 0.0065512855685955088}\n",
      "{'C': 0.0065512855685955088}\n",
      "{'C': 0.0065512855685955088}\n",
      "{'C': 0.0079060432109077008}\n",
      "{'C': 0.0079060432109077008}\n",
      "{'C': 0.0079060432109077008}\n",
      "{'C': 0.0095409547634999446}\n",
      "{'C': 0.0095409547634999446}\n",
      "{'C': 0.0095409547634999446}\n",
      "{'C': 0.011513953993264469}\n",
      "{'C': 0.011513953993264469}\n",
      "{'C': 0.011513953993264469}\n",
      "{'C': 0.013894954943731374}\n",
      "{'C': 0.013894954943731374}\n",
      "{'C': 0.013894954943731374}\n",
      "{'C': 0.016768329368110076}\n",
      "{'C': 0.016768329368110076}\n",
      "{'C': 0.016768329368110076}\n",
      "{'C': 0.020235896477251564}\n",
      "{'C': 0.020235896477251564}\n",
      "{'C': 0.020235896477251564}\n",
      "{'C': 0.024420530945486511}\n",
      "{'C': 0.024420530945486511}\n",
      "{'C': 0.024420530945486511}\n",
      "{'C': 0.029470517025518096}\n",
      "{'C': 0.029470517025518096}\n",
      "{'C': 0.029470517025518096}\n",
      "{'C': 0.035564803062231282}\n",
      "{'C': 0.035564803062231282}\n",
      "{'C': 0.035564803062231282}\n",
      "{'C': 0.042919342601287762}\n",
      "{'C': 0.042919342601287762}\n",
      "{'C': 0.042919342601287762}\n",
      "{'C': 0.0517947467923121}\n",
      "{'C': 0.0517947467923121}\n",
      "{'C': 0.0517947467923121}\n",
      "{'C': 0.0625055192527397}\n",
      "{'C': 0.0625055192527397}\n",
      "{'C': 0.0625055192527397}\n",
      "{'C': 0.07543120063354615}\n",
      "{'C': 0.07543120063354615}\n",
      "{'C': 0.07543120063354615}\n",
      "{'C': 0.091029817799152174}\n",
      "{'C': 0.091029817799152174}\n",
      "{'C': 0.091029817799152174}\n",
      "{'C': 0.10985411419875583}\n",
      "{'C': 0.10985411419875583}\n",
      "{'C': 0.10985411419875583}\n",
      "{'C': 0.13257113655901082}\n",
      "{'C': 0.13257113655901082}\n",
      "{'C': 0.13257113655901082}\n",
      "{'C': 0.15998587196060574}\n",
      "{'C': 0.15998587196060574}\n",
      "{'C': 0.15998587196060574}\n",
      "{'C': 0.19306977288832497}\n",
      "{'C': 0.19306977288832497}\n",
      "{'C': 0.19306977288832497}\n",
      "{'C': 0.23299518105153719}\n",
      "{'C': 0.23299518105153719}\n",
      "{'C': 0.23299518105153719}\n",
      "{'C': 0.28117686979742279}\n",
      "{'C': 0.28117686979742279}\n",
      "{'C': 0.28117686979742279}\n",
      "{'C': 0.33932217718953261}\n",
      "{'C': 0.33932217718953261}\n",
      "{'C': 0.33932217718953261}\n",
      "{'C': 0.40949150623804231}\n",
      "{'C': 0.40949150623804231}\n",
      "{'C': 0.40949150623804231}\n",
      "{'C': 0.49417133613238334}\n",
      "{'C': 0.49417133613238334}\n",
      "{'C': 0.49417133613238334}\n",
      "{'C': 0.59636233165946428}\n",
      "{'C': 0.59636233165946428}\n",
      "{'C': 0.59636233165946428}\n",
      "{'C': 0.71968567300115138}\n",
      "{'C': 0.71968567300115138}\n",
      "{'C': 0.71968567300115138}\n",
      "{'C': 0.86851137375135201}\n",
      "{'C': 0.86851137375135201}\n",
      "{'C': 0.86851137375135201}\n",
      "{'C': 1.0481131341546852}\n",
      "{'C': 1.0481131341546852}\n",
      "{'C': 1.0481131341546852}\n",
      "{'C': 1.2648552168552958}\n",
      "{'C': 1.2648552168552958}\n",
      "{'C': 1.2648552168552958}\n",
      "{'C': 1.5264179671752318}\n",
      "{'C': 1.5264179671752318}\n",
      "{'C': 1.5264179671752318}\n",
      "{'C': 1.8420699693267144}\n",
      "{'C': 1.8420699693267144}\n",
      "{'C': 1.8420699693267144}\n",
      "{'C': 2.2229964825261934}\n",
      "{'C': 2.2229964825261934}\n",
      "{'C': 2.2229964825261934}\n",
      "{'C': 2.6826957952797246}\n",
      "{'C': 2.6826957952797246}\n",
      "{'C': 2.6826957952797246}\n",
      "{'C': 3.2374575428176433}\n",
      "{'C': 3.2374575428176433}\n",
      "{'C': 3.2374575428176433}\n",
      "{'C': 3.906939937054613}\n",
      "{'C': 3.906939937054613}\n",
      "{'C': 3.906939937054613}\n",
      "{'C': 4.7148663634573893}\n",
      "{'C': 4.7148663634573893}\n",
      "{'C': 4.7148663634573893}\n",
      "{'C': 5.689866029018293}\n",
      "{'C': 5.689866029018293}\n",
      "{'C': 5.689866029018293}\n",
      "{'C': 6.8664884500429979}\n",
      "{'C': 6.8664884500429979}\n",
      "{'C': 6.8664884500429979}\n",
      "{'C': 8.2864277285468422}\n",
      "{'C': 8.2864277285468422}\n",
      "{'C': 8.2864277285468422}\n",
      "{'C': 10.0}\n",
      "{'C': 10.0}\n",
      "{'C': 10.0}\n"
     ]
    }
   ],
   "source": [
    "with np.errstate(all='ignore'):\n",
    "    param_grid_input = {'C': costs }\n",
    "    mglr = MultiClassLogisticRegression(eta=eta,iterations=iter_, C=0.02, optimization=\"BFGSBinaryLogisticRegression\")\n",
    "    gscv = GridSearchCV(cv= cv_object, estimator=mglr, param_grid= param_grid_input, scoring= \"accuracy\",refit=False)\n",
    "    gscv.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.49417133613238334}\n"
     ]
    }
   ],
   "source": [
    "print(gscv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our graph above, \"Determining Optimal Value of Regularization Term C\", we chose C to be ____ . GridSearchCV recommends we use _ for C. These are not too different so we are confident in our choice. While implementing GridSearchCV functionality for our classes was difficult and would require further implementations, we conclude that it would be a better choice (once implemented) than having to graph values.\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
