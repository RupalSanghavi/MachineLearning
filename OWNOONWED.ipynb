{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "%matplotlib inline \n",
    "%load_ext memory_profiler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.special import expit\n",
    "import time\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression as SKLogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "target_classifier = 'Fear of public speaking'\n",
    "df = pd.read_csv('responses.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and Prepare Class Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove rows whose target classfier value is NaN\n",
    "df_cleaned_classifier = df[np.isfinite(df[target_classifier])]\n",
    "# change NaN number values to the mean\n",
    "df_imputed = df_cleaned_classifier.fillna(df.mean())\n",
    "# get categorical features\n",
    "object_features = list(df_cleaned_classifier.select_dtypes(include=['object']).columns)\n",
    "# one hot encode categorical features\n",
    "one_hot_df = pd.concat([pd.get_dummies(df_imputed[col],prefix=col) for col in object_features], axis=1)\n",
    "# drop object features from imputed dataframe\n",
    "df_imputed_dropped = df_imputed.drop(object_features, 1)\n",
    "frames = [df_imputed_dropped, one_hot_df]\n",
    "# concatenate both frames by columns\n",
    "df_fixed = pd.concat(frames, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Music</th>\n",
       "      <th>Slow songs or fast songs</th>\n",
       "      <th>Dance</th>\n",
       "      <th>Folk</th>\n",
       "      <th>Country</th>\n",
       "      <th>Classical music</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Pop</th>\n",
       "      <th>Rock</th>\n",
       "      <th>Metal or Hardrock</th>\n",
       "      <th>...</th>\n",
       "      <th>Education_doctorate degree</th>\n",
       "      <th>Education_masters degree</th>\n",
       "      <th>Education_primary school</th>\n",
       "      <th>Education_secondary school</th>\n",
       "      <th>Only child_no</th>\n",
       "      <th>Only child_yes</th>\n",
       "      <th>Village - town_city</th>\n",
       "      <th>Village - town_village</th>\n",
       "      <th>House - block of flats_block of flats</th>\n",
       "      <th>House - block of flats_house/bungalow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.761952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1009 rows × 172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Music  Slow songs or fast songs  Dance  Folk  Country  Classical music  \\\n",
       "0       5.0                       3.0    2.0   1.0      2.0              2.0   \n",
       "1       4.0                       4.0    2.0   1.0      1.0              1.0   \n",
       "2       5.0                       5.0    2.0   2.0      3.0              4.0   \n",
       "3       5.0                       3.0    2.0   1.0      1.0              1.0   \n",
       "4       5.0                       3.0    4.0   3.0      2.0              4.0   \n",
       "5       5.0                       3.0    2.0   3.0      2.0              3.0   \n",
       "6       5.0                       5.0    5.0   3.0      1.0              2.0   \n",
       "7       5.0                       3.0    3.0   2.0      1.0              2.0   \n",
       "8       5.0                       3.0    3.0   1.0      1.0              2.0   \n",
       "9       5.0                       3.0    2.0   5.0      2.0              2.0   \n",
       "10      5.0                       3.0    3.0   2.0      1.0              2.0   \n",
       "11      5.0                       3.0    1.0   1.0      1.0              4.0   \n",
       "12      5.0                       3.0    1.0   2.0      1.0              4.0   \n",
       "13      5.0                       3.0    5.0   3.0      2.0              1.0   \n",
       "14      5.0                       3.0    2.0   1.0      1.0              2.0   \n",
       "15      1.0                       3.0    2.0   2.0      3.0              4.0   \n",
       "16      5.0                       3.0    3.0   1.0      1.0              1.0   \n",
       "17      5.0                       3.0    3.0   3.0      3.0              2.0   \n",
       "18      5.0                       3.0    5.0   4.0      3.0              4.0   \n",
       "19      5.0                       4.0    3.0   3.0      2.0              4.0   \n",
       "20      5.0                       3.0    3.0   2.0      3.0              4.0   \n",
       "21      5.0                       5.0    1.0   1.0      3.0              2.0   \n",
       "22      5.0                       3.0    3.0   2.0      3.0              3.0   \n",
       "23      5.0                       3.0    4.0   2.0      2.0              2.0   \n",
       "24      5.0                       2.0    3.0   1.0      1.0              4.0   \n",
       "25      5.0                       3.0    4.0   2.0      1.0              2.0   \n",
       "26      5.0                       5.0    5.0   5.0      4.0              5.0   \n",
       "27      4.0                       5.0    3.0   4.0      1.0              3.0   \n",
       "28      5.0                       3.0    5.0   1.0      1.0              1.0   \n",
       "29      5.0                       4.0    3.0   4.0      2.0              3.0   \n",
       "...     ...                       ...    ...   ...      ...              ...   \n",
       "980     5.0                       3.0    2.0   2.0      2.0              5.0   \n",
       "981     5.0                       4.0    1.0   2.0      4.0              5.0   \n",
       "982     5.0                       4.0    2.0   1.0      1.0              3.0   \n",
       "983     5.0                       4.0    3.0   1.0      1.0              3.0   \n",
       "984     5.0                       2.0    1.0   3.0      2.0              3.0   \n",
       "985     5.0                       2.0    1.0   3.0      2.0              4.0   \n",
       "986     4.0                       3.0    2.0   5.0      3.0              5.0   \n",
       "987     4.0                       3.0    2.0   2.0      3.0              2.0   \n",
       "988     5.0                       2.0    3.0   2.0      2.0              5.0   \n",
       "989     5.0                       5.0    3.0   2.0      2.0              4.0   \n",
       "990     5.0                       4.0    2.0   1.0      1.0              2.0   \n",
       "991     5.0                       5.0    2.0   1.0      1.0              1.0   \n",
       "992     4.0                       4.0    4.0   1.0      4.0              4.0   \n",
       "993     5.0                       3.0    3.0   1.0      2.0              3.0   \n",
       "994     5.0                       4.0    3.0   2.0      2.0              3.0   \n",
       "995     5.0                       4.0    2.0   1.0      1.0              1.0   \n",
       "996     5.0                       3.0    1.0   1.0      1.0              3.0   \n",
       "997     5.0                       4.0    3.0   3.0      3.0              1.0   \n",
       "998     5.0                       4.0    4.0   3.0      1.0              3.0   \n",
       "999     5.0                       5.0    5.0   3.0      4.0              5.0   \n",
       "1000    5.0                       3.0    3.0   3.0      2.0              3.0   \n",
       "1001    5.0                       5.0    5.0   1.0      2.0              1.0   \n",
       "1002    5.0                       5.0    3.0   1.0      3.0              1.0   \n",
       "1003    4.0                       3.0    4.0   3.0      2.0              2.0   \n",
       "1004    5.0                       3.0    4.0   1.0      2.0              3.0   \n",
       "1005    5.0                       2.0    5.0   2.0      2.0              5.0   \n",
       "1006    4.0                       4.0    5.0   1.0      3.0              4.0   \n",
       "1007    4.0                       3.0    1.0   1.0      2.0              2.0   \n",
       "1008    5.0                       3.0    3.0   3.0      1.0              3.0   \n",
       "1009    5.0                       5.0    4.0   3.0      2.0              3.0   \n",
       "\n",
       "      Musical  Pop      Rock  Metal or Hardrock  \\\n",
       "0         1.0  5.0  5.000000                1.0   \n",
       "1         2.0  3.0  5.000000                4.0   \n",
       "2         5.0  3.0  5.000000                3.0   \n",
       "3         1.0  2.0  2.000000                1.0   \n",
       "4         3.0  5.0  3.000000                1.0   \n",
       "5         3.0  2.0  5.000000                5.0   \n",
       "6         2.0  5.0  3.000000                1.0   \n",
       "7         2.0  4.0  5.000000                1.0   \n",
       "8         4.0  3.0  5.000000                5.0   \n",
       "9         5.0  3.0  5.000000                2.0   \n",
       "10        3.0  4.0  3.000000                2.0   \n",
       "11        1.0  2.0  5.000000                1.0   \n",
       "12        3.0  3.0  5.000000                4.0   \n",
       "13        5.0  5.0  2.000000                1.0   \n",
       "14        3.0  4.0  5.000000                2.0   \n",
       "15        3.0  3.0  5.000000                5.0   \n",
       "16        2.0  4.0  4.000000                1.0   \n",
       "17        2.0  4.0  4.000000                2.0   \n",
       "18        5.0  5.0  4.000000                4.0   \n",
       "19        2.0  2.0  4.000000                5.0   \n",
       "20        3.0  2.0  5.000000                5.0   \n",
       "21        2.0  2.0  5.000000                5.0   \n",
       "22        3.0  4.0  3.761952                1.0   \n",
       "23        4.0  4.0  5.000000                2.0   \n",
       "24        3.0  3.0  5.000000                5.0   \n",
       "25        3.0  5.0  1.000000                1.0   \n",
       "26        3.0  4.0  4.000000                3.0   \n",
       "27        2.0  2.0  4.000000                2.0   \n",
       "28        1.0  3.0  4.000000                1.0   \n",
       "29        3.0  3.0  4.000000                1.0   \n",
       "...       ...  ...       ...                ...   \n",
       "980       1.0  4.0  4.000000                4.0   \n",
       "981       5.0  3.0  4.000000                1.0   \n",
       "982       2.0  2.0  4.000000                3.0   \n",
       "983       3.0  5.0  3.000000                1.0   \n",
       "984       3.0  3.0  4.000000                4.0   \n",
       "985       2.0  4.0  5.000000                3.0   \n",
       "986       2.0  2.0  4.000000                2.0   \n",
       "987       1.0  1.0  5.000000                3.0   \n",
       "988       2.0  2.0  5.000000                2.0   \n",
       "989       5.0  5.0  5.000000                5.0   \n",
       "990       2.0  3.0  4.000000                4.0   \n",
       "991       1.0  1.0  5.000000                5.0   \n",
       "992       1.0  3.0  4.000000                4.0   \n",
       "993       1.0  4.0  4.000000                1.0   \n",
       "994       4.0  3.0  5.000000                3.0   \n",
       "995       2.0  1.0  4.000000                4.0   \n",
       "996       2.0  1.0  4.000000                3.0   \n",
       "997       3.0  3.0  4.000000                2.0   \n",
       "998       2.0  3.0  5.000000                5.0   \n",
       "999       4.0  4.0  4.000000                3.0   \n",
       "1000      3.0  4.0  3.000000                1.0   \n",
       "1001      4.0  4.0  3.000000                2.0   \n",
       "1002      1.0  2.0  5.000000                5.0   \n",
       "1003      3.0  4.0  5.000000                2.0   \n",
       "1004      2.0  3.0  3.000000                4.0   \n",
       "1005      4.0  4.0  4.000000                3.0   \n",
       "1006      1.0  4.0  1.000000                1.0   \n",
       "1007      2.0  3.0  4.000000                1.0   \n",
       "1008      1.0  3.0  4.000000                1.0   \n",
       "1009      3.0  4.0  1.000000                1.0   \n",
       "\n",
       "                      ...                    Education_doctorate degree  \\\n",
       "0                     ...                                             0   \n",
       "1                     ...                                             0   \n",
       "2                     ...                                             0   \n",
       "3                     ...                                             0   \n",
       "4                     ...                                             0   \n",
       "5                     ...                                             0   \n",
       "6                     ...                                             0   \n",
       "7                     ...                                             0   \n",
       "8                     ...                                             0   \n",
       "9                     ...                                             0   \n",
       "10                    ...                                             0   \n",
       "11                    ...                                             0   \n",
       "12                    ...                                             0   \n",
       "13                    ...                                             0   \n",
       "14                    ...                                             0   \n",
       "15                    ...                                             0   \n",
       "16                    ...                                             0   \n",
       "17                    ...                                             0   \n",
       "18                    ...                                             0   \n",
       "19                    ...                                             0   \n",
       "20                    ...                                             0   \n",
       "21                    ...                                             0   \n",
       "22                    ...                                             0   \n",
       "23                    ...                                             0   \n",
       "24                    ...                                             0   \n",
       "25                    ...                                             0   \n",
       "26                    ...                                             0   \n",
       "27                    ...                                             0   \n",
       "28                    ...                                             0   \n",
       "29                    ...                                             0   \n",
       "...                   ...                                           ...   \n",
       "980                   ...                                             0   \n",
       "981                   ...                                             0   \n",
       "982                   ...                                             0   \n",
       "983                   ...                                             0   \n",
       "984                   ...                                             0   \n",
       "985                   ...                                             0   \n",
       "986                   ...                                             0   \n",
       "987                   ...                                             0   \n",
       "988                   ...                                             0   \n",
       "989                   ...                                             0   \n",
       "990                   ...                                             0   \n",
       "991                   ...                                             0   \n",
       "992                   ...                                             0   \n",
       "993                   ...                                             0   \n",
       "994                   ...                                             0   \n",
       "995                   ...                                             0   \n",
       "996                   ...                                             0   \n",
       "997                   ...                                             0   \n",
       "998                   ...                                             0   \n",
       "999                   ...                                             0   \n",
       "1000                  ...                                             0   \n",
       "1001                  ...                                             0   \n",
       "1002                  ...                                             0   \n",
       "1003                  ...                                             0   \n",
       "1004                  ...                                             0   \n",
       "1005                  ...                                             0   \n",
       "1006                  ...                                             0   \n",
       "1007                  ...                                             0   \n",
       "1008                  ...                                             0   \n",
       "1009                  ...                                             0   \n",
       "\n",
       "      Education_masters degree  Education_primary school  \\\n",
       "0                            0                         0   \n",
       "1                            0                         0   \n",
       "2                            0                         0   \n",
       "3                            0                         0   \n",
       "4                            0                         0   \n",
       "5                            0                         0   \n",
       "6                            0                         0   \n",
       "7                            0                         0   \n",
       "8                            0                         0   \n",
       "9                            0                         0   \n",
       "10                           0                         0   \n",
       "11                           0                         1   \n",
       "12                           0                         0   \n",
       "13                           0                         0   \n",
       "14                           0                         0   \n",
       "15                           0                         0   \n",
       "16                           0                         0   \n",
       "17                           0                         0   \n",
       "18                           0                         0   \n",
       "19                           0                         0   \n",
       "20                           0                         0   \n",
       "21                           0                         0   \n",
       "22                           0                         0   \n",
       "23                           0                         0   \n",
       "24                           0                         0   \n",
       "25                           0                         0   \n",
       "26                           0                         0   \n",
       "27                           0                         0   \n",
       "28                           0                         0   \n",
       "29                           0                         0   \n",
       "...                        ...                       ...   \n",
       "980                          0                         0   \n",
       "981                          0                         0   \n",
       "982                          0                         0   \n",
       "983                          0                         0   \n",
       "984                          0                         0   \n",
       "985                          0                         0   \n",
       "986                          0                         0   \n",
       "987                          0                         0   \n",
       "988                          0                         0   \n",
       "989                          1                         0   \n",
       "990                          0                         0   \n",
       "991                          0                         0   \n",
       "992                          1                         0   \n",
       "993                          0                         0   \n",
       "994                          0                         0   \n",
       "995                          0                         0   \n",
       "996                          0                         0   \n",
       "997                          0                         0   \n",
       "998                          1                         0   \n",
       "999                          0                         0   \n",
       "1000                         0                         1   \n",
       "1001                         0                         1   \n",
       "1002                         0                         0   \n",
       "1003                         0                         0   \n",
       "1004                         0                         0   \n",
       "1005                         0                         0   \n",
       "1006                         1                         0   \n",
       "1007                         0                         0   \n",
       "1008                         0                         0   \n",
       "1009                         0                         0   \n",
       "\n",
       "      Education_secondary school  Only child_no  Only child_yes  \\\n",
       "0                              0              1               0   \n",
       "1                              0              1               0   \n",
       "2                              1              1               0   \n",
       "3                              0              0               1   \n",
       "4                              1              1               0   \n",
       "5                              1              1               0   \n",
       "6                              1              1               0   \n",
       "7                              0              1               0   \n",
       "8                              1              1               0   \n",
       "9                              1              1               0   \n",
       "10                             1              1               0   \n",
       "11                             0              1               0   \n",
       "12                             0              1               0   \n",
       "13                             1              1               0   \n",
       "14                             0              1               0   \n",
       "15                             1              0               1   \n",
       "16                             0              1               0   \n",
       "17                             1              1               0   \n",
       "18                             1              1               0   \n",
       "19                             1              1               0   \n",
       "20                             1              1               0   \n",
       "21                             1              1               0   \n",
       "22                             0              1               0   \n",
       "23                             1              1               0   \n",
       "24                             1              1               0   \n",
       "25                             1              0               1   \n",
       "26                             0              1               0   \n",
       "27                             1              1               0   \n",
       "28                             1              0               1   \n",
       "29                             1              1               0   \n",
       "...                          ...            ...             ...   \n",
       "980                            1              1               0   \n",
       "981                            1              1               0   \n",
       "982                            1              1               0   \n",
       "983                            1              1               0   \n",
       "984                            1              0               1   \n",
       "985                            1              1               0   \n",
       "986                            1              1               0   \n",
       "987                            1              1               0   \n",
       "988                            1              0               1   \n",
       "989                            0              1               0   \n",
       "990                            1              1               0   \n",
       "991                            1              0               1   \n",
       "992                            0              1               0   \n",
       "993                            1              0               1   \n",
       "994                            1              0               1   \n",
       "995                            1              0               1   \n",
       "996                            1              0               1   \n",
       "997                            1              1               0   \n",
       "998                            0              1               0   \n",
       "999                            1              1               0   \n",
       "1000                           0              1               0   \n",
       "1001                           0              1               0   \n",
       "1002                           1              1               0   \n",
       "1003                           1              1               0   \n",
       "1004                           1              1               0   \n",
       "1005                           1              1               0   \n",
       "1006                           0              1               0   \n",
       "1007                           1              0               1   \n",
       "1008                           0              1               0   \n",
       "1009                           1              1               0   \n",
       "\n",
       "      Village - town_city  Village - town_village  \\\n",
       "0                       0                       1   \n",
       "1                       1                       0   \n",
       "2                       1                       0   \n",
       "3                       1                       0   \n",
       "4                       0                       1   \n",
       "5                       1                       0   \n",
       "6                       0                       1   \n",
       "7                       1                       0   \n",
       "8                       1                       0   \n",
       "9                       1                       0   \n",
       "10                      1                       0   \n",
       "11                      1                       0   \n",
       "12                      1                       0   \n",
       "13                      1                       0   \n",
       "14                      1                       0   \n",
       "15                      1                       0   \n",
       "16                      1                       0   \n",
       "17                      0                       1   \n",
       "18                      1                       0   \n",
       "19                      1                       0   \n",
       "20                      1                       0   \n",
       "21                      1                       0   \n",
       "22                      1                       0   \n",
       "23                      1                       0   \n",
       "24                      1                       0   \n",
       "25                      1                       0   \n",
       "26                      1                       0   \n",
       "27                      1                       0   \n",
       "28                      0                       1   \n",
       "29                      0                       1   \n",
       "...                   ...                     ...   \n",
       "980                     1                       0   \n",
       "981                     0                       1   \n",
       "982                     1                       0   \n",
       "983                     0                       1   \n",
       "984                     1                       0   \n",
       "985                     1                       0   \n",
       "986                     1                       0   \n",
       "987                     1                       0   \n",
       "988                     1                       0   \n",
       "989                     0                       1   \n",
       "990                     1                       0   \n",
       "991                     1                       0   \n",
       "992                     1                       0   \n",
       "993                     1                       0   \n",
       "994                     1                       0   \n",
       "995                     1                       0   \n",
       "996                     0                       0   \n",
       "997                     0                       0   \n",
       "998                     1                       0   \n",
       "999                     1                       0   \n",
       "1000                    1                       0   \n",
       "1001                    1                       0   \n",
       "1002                    1                       0   \n",
       "1003                    1                       0   \n",
       "1004                    1                       0   \n",
       "1005                    1                       0   \n",
       "1006                    0                       1   \n",
       "1007                    1                       0   \n",
       "1008                    1                       0   \n",
       "1009                    0                       1   \n",
       "\n",
       "      House - block of flats_block of flats  \\\n",
       "0                                         1   \n",
       "1                                         1   \n",
       "2                                         1   \n",
       "3                                         0   \n",
       "4                                         0   \n",
       "5                                         1   \n",
       "6                                         0   \n",
       "7                                         0   \n",
       "8                                         0   \n",
       "9                                         1   \n",
       "10                                        1   \n",
       "11                                        1   \n",
       "12                                        1   \n",
       "13                                        1   \n",
       "14                                        1   \n",
       "15                                        1   \n",
       "16                                        1   \n",
       "17                                        0   \n",
       "18                                        0   \n",
       "19                                        0   \n",
       "20                                        1   \n",
       "21                                        1   \n",
       "22                                        0   \n",
       "23                                        1   \n",
       "24                                        1   \n",
       "25                                        1   \n",
       "26                                        0   \n",
       "27                                        0   \n",
       "28                                        0   \n",
       "29                                        1   \n",
       "...                                     ...   \n",
       "980                                       0   \n",
       "981                                       0   \n",
       "982                                       0   \n",
       "983                                       0   \n",
       "984                                       1   \n",
       "985                                       1   \n",
       "986                                       0   \n",
       "987                                       1   \n",
       "988                                       1   \n",
       "989                                       0   \n",
       "990                                       1   \n",
       "991                                       0   \n",
       "992                                       1   \n",
       "993                                       1   \n",
       "994                                       1   \n",
       "995                                       1   \n",
       "996                                       1   \n",
       "997                                       1   \n",
       "998                                       1   \n",
       "999                                       1   \n",
       "1000                                      1   \n",
       "1001                                      1   \n",
       "1002                                      1   \n",
       "1003                                      0   \n",
       "1004                                      1   \n",
       "1005                                      0   \n",
       "1006                                      0   \n",
       "1007                                      1   \n",
       "1008                                      1   \n",
       "1009                                      0   \n",
       "\n",
       "      House - block of flats_house/bungalow  \n",
       "0                                         0  \n",
       "1                                         0  \n",
       "2                                         0  \n",
       "3                                         1  \n",
       "4                                         1  \n",
       "5                                         0  \n",
       "6                                         1  \n",
       "7                                         1  \n",
       "8                                         1  \n",
       "9                                         0  \n",
       "10                                        0  \n",
       "11                                        0  \n",
       "12                                        0  \n",
       "13                                        0  \n",
       "14                                        0  \n",
       "15                                        0  \n",
       "16                                        0  \n",
       "17                                        1  \n",
       "18                                        1  \n",
       "19                                        1  \n",
       "20                                        0  \n",
       "21                                        0  \n",
       "22                                        1  \n",
       "23                                        0  \n",
       "24                                        0  \n",
       "25                                        0  \n",
       "26                                        1  \n",
       "27                                        1  \n",
       "28                                        1  \n",
       "29                                        0  \n",
       "...                                     ...  \n",
       "980                                       1  \n",
       "981                                       1  \n",
       "982                                       1  \n",
       "983                                       1  \n",
       "984                                       0  \n",
       "985                                       0  \n",
       "986                                       1  \n",
       "987                                       0  \n",
       "988                                       0  \n",
       "989                                       1  \n",
       "990                                       0  \n",
       "991                                       1  \n",
       "992                                       0  \n",
       "993                                       0  \n",
       "994                                       0  \n",
       "995                                       0  \n",
       "996                                       0  \n",
       "997                                       0  \n",
       "998                                       0  \n",
       "999                                       0  \n",
       "1000                                      0  \n",
       "1001                                      0  \n",
       "1002                                      0  \n",
       "1003                                      1  \n",
       "1004                                      0  \n",
       "1005                                      1  \n",
       "1006                                      1  \n",
       "1007                                      0  \n",
       "1008                                      0  \n",
       "1009                                      1  \n",
       "\n",
       "[1009 rows x 172 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide Data into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=1, random_state=None, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# we want to predict the X and y data as follows:\n",
    "if target_classifier in df_fixed:\n",
    "    y = df_fixed[target_classifier].values # get the labels we want\n",
    "    del df_fixed[target_classifier] # get rid of the class label\n",
    "    X = df_fixed.values # use everything else to predict!\n",
    "\n",
    "num_cv_iterations = 1\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,test_size = 0.2)\n",
    "\n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 82 µs, sys: 1 µs, total: 83 µs\n",
      "Wall time: 93 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# from last time, our logistic regression algorithm is given by (including everything we previously had):\n",
    "class BinaryLogisticRegression:\n",
    "    def __init__(self, eta, iterations=20, C=0.001):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        self.C = C\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "        \n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'Binary Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained Binary Logistic Regression Object'\n",
    "        \n",
    "    # convenience, private:\n",
    "    @staticmethod\n",
    "    def _add_bias(X):\n",
    "        return np.hstack((np.ones((X.shape[0],1)),X)) # add bias term\n",
    "    \n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        # increase stability, redefine sigmoid operation\n",
    "        return expit(theta) #1/(1+np.exp(-theta))\n",
    "    \n",
    "    # vectorized gradient calculation with regularization using L1 Norm\n",
    "    def _get_gradient(self,X,y):\n",
    "        ydiff = y-self.predict_proba(X,add_bias=False).ravel() # get y difference\n",
    "        gradient = np.mean(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\n",
    "        \n",
    "        gradient = gradient.reshape(self.w_.shape)\n",
    "        \n",
    "        # L2 norm from Dr. Larson's implementation\n",
    "        #         gradient[1:] += 2 * self.w_[1:] * self.C\n",
    "        \n",
    "        # L1 norm implementation\n",
    "        gradient[1:] += np.sign(self.w_[1:]) * self.C\n",
    "        \n",
    "        return gradient\n",
    "    \n",
    "    # public:\n",
    "    def predict_proba(self,X,add_bias=True):\n",
    "        # add bias term if requested\n",
    "        Xb = self._add_bias(X) if add_bias else X\n",
    "        return self._sigmoid(Xb @ self.w_) # return the probability y=1\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return (self.predict_proba(X)>0.5) #return the actual prediction\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        Xb = self._add_bias(X) # add bias term\n",
    "        num_samples, num_features = Xb.shape\n",
    "        \n",
    "        self.w_ = np.zeros((num_features,1)) # init weight vector to zeros\n",
    "        \n",
    "        # for as many as the max iterations\n",
    "        for _ in range(self.iters):\n",
    "            gradient = self._get_gradient(Xb,y)\n",
    "            self.w_ += gradient*self.eta # multiply by learning rate \n",
    "\n",
    "# blr = BinaryLogisticRegression(eta=0.1,iterations=500,C=0.001)\n",
    "\n",
    "# blr.fit(X,y)\n",
    "# print(blr)\n",
    "\n",
    "# yhat = blr.predict(X)\n",
    "# print('Accuracy of: ',accuracy_score(y,yhat+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 88 µs, sys: 1 µs, total: 89 µs\n",
      "Wall time: 96.1 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# and we can update this to use a line search along the gradient like this:\n",
    "from scipy.optimize import minimize_scalar\n",
    "from scipy.optimize import OptimizeResult\n",
    "\n",
    "import copy\n",
    "class LineSearchLogisticRegression(BinaryLogisticRegression):\n",
    "    \n",
    "    # define custom line search for problem\n",
    "    @staticmethod\n",
    "    def line_search_function(eta,X,y,w,grad,C):\n",
    "        wnew = w + grad*eta\n",
    "        yhat = expit(X @ wnew)>0.5\n",
    "        return np.sum((y-yhat)**2) + C*np.sum(wnew**2)\n",
    "     \n",
    "    def fit(self, X, y):\n",
    "        Xb = self._add_bias(X) # add bias term\n",
    "        num_samples, num_features = Xb.shape\n",
    "        \n",
    "        self.w_ = np.zeros((num_features,1)) # init weight vector to zeros\n",
    "        \n",
    "        # for as many as the max iterations\n",
    "        for _ in range(self.iters):\n",
    "            gradient = self._get_gradient(Xb,y)\n",
    "            \n",
    "            # do line search in gradient direction, using scipy function\n",
    "            opts = {'maxiter':self.iters/20} # unclear exactly what this should be\n",
    "            res = minimize_scalar(self.line_search_function, # objective function to optimize\n",
    "                                  bounds=(self.eta/1000,self.eta*10), #bounds to optimize\n",
    "                                  args=(Xb,y,self.w_,gradient,self.C), # additional argument for objective function\n",
    "                                  method='bounded', # bounded optimization for speed\n",
    "                                  options=opts) # set max iterations\n",
    "            eta = res.x # get optimal learning rate\n",
    "            self.w_ += gradient*eta # set new function values\n",
    "                \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56 µs, sys: 1 µs, total: 57 µs\n",
      "Wall time: 62.9 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "class StochasticLogisticRegression(BinaryLogisticRegression):\n",
    "    # stochastic gradient calculation \n",
    "    def _get_gradient(self,X,y):\n",
    "        idx = int(np.random.rand()*len(y)) # grab random instance\n",
    "        ydiff = y[idx]-self.predict_proba(X[idx],add_bias=False) # get y difference (now scalar)\n",
    "        gradient = X[idx] * ydiff[:,np.newaxis] # make ydiff a column vector and multiply through\n",
    "        \n",
    "        gradient = gradient.reshape(self.w_.shape)\n",
    "        gradient[1:] += 2 * self.w_[1:] * self.C\n",
    "        \n",
    "        return gradient\n",
    "    \n",
    "    \n",
    "# slr = StochasticLogisticRegression(0.1,1000, C=0.001) # take a lot more steps!!\n",
    "\n",
    "# slr.fit(X,y)\n",
    "\n",
    "# yhat = slr.predict(X)\n",
    "# print(slr)\n",
    "# print('Accuracy of: ',accuracy_score(y,yhat))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 80 µs, sys: 1 µs, total: 81 µs\n",
      "Wall time: 89.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# for this, we won't perform our own BFGS implementation \n",
    "# (it takes a good deal of code and understanding of the algorithm)\n",
    "# luckily for us, scipy has its own BFGS implementation:\n",
    "from scipy.optimize import fmin_bfgs\n",
    "class BFGSBinaryLogisticRegression(BinaryLogisticRegression):\n",
    "    \n",
    "    @staticmethod\n",
    "    def objective_function(w,X,y,C):\n",
    "        g = expit(X @ w)\n",
    "        return -np.sum(np.log(g[y==1]))-np.sum(np.log(1-g[y==0])) + C*sum(w**2) #-np.sum(y*np.log(g)+(1-y)*np.log(1-g))\n",
    "\n",
    "    @staticmethod\n",
    "    def objective_gradient(w,X,y,C):\n",
    "        g = expit(X @ w)\n",
    "        ydiff = y-g # get y difference\n",
    "        gradient = np.mean(X * ydiff[:,np.newaxis], axis=0)\n",
    "        gradient = gradient.reshape(w.shape)\n",
    "        gradient[1:] += 2 * w[1:] * C\n",
    "        return -gradient\n",
    "    \n",
    "    # just overwrite fit function\n",
    "    def fit(self, X, y):\n",
    "        Xb = self._add_bias(X) # add bias term\n",
    "        num_samples, num_features = Xb.shape\n",
    "        \n",
    "        self.w_ = fmin_bfgs(self.objective_function, # what to optimize\n",
    "                            np.zeros((num_features,1)), # starting point\n",
    "                            fprime=self.objective_gradient, # gradient function\n",
    "                            args=(Xb,y,self.C), # extra args for gradient and objective function\n",
    "                            gtol=1e-03, # stopping criteria for gradient, |v_k|\n",
    "                            maxiter=self.iters, # stopping criteria iterations\n",
    "                            disp=False)\n",
    "        result = fmin_bfgs(self.objective_function, # what to optimize\n",
    "                            np.zeros((num_features,1)), # starting point\n",
    "                            fprime=self.objective_gradient, # gradient function\n",
    "                            args=(Xb,y,self.C), # extra args for gradient and objective function\n",
    "                            gtol=1e-03, # stopping criteria for gradient, |v_k|\n",
    "                            maxiter=self.iters, # stopping criteria iterations\n",
    "                            disp=False,\n",
    "                            retall=True)\n",
    "        self.w_ = self.w_.reshape((num_features,1))\n",
    "            \n",
    "# bfgslr = BFGSBinaryLogisticRegression(_,2) # note that we need only a few iterations here\n",
    "\n",
    "# bfgslr.fit(X,y)\n",
    "# yhat = bfgslr.predict(X)\n",
    "# print(bfgslr)\n",
    "# print('Accuracy of: ',accuracy_score(y,yhat+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MultiClassLogisticRegression:\n",
    "    def __init__(self, eta, iterations=20, C=0.0001, optimization=None):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        self.C = C\n",
    "        self.classifiers_ = []\n",
    "        self.optimization = optimization\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "    \n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'MultiClass Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained MultiClass Logistic Regression Object'\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        num_samples, num_features = X.shape\n",
    "        self.unique_ = np.sort(np.unique(y)) # get each unique class value\n",
    "        num_unique_classes = len(self.unique_)\n",
    "        self.classifiers_ = []\n",
    "        for i,yval in enumerate(self.unique_): # for each unique value\n",
    "            y_binary = y==yval # create a binary problem\n",
    "            # train the binary classifier for this class\n",
    "            #hblr = HessianBinaryLogisticRegression(self.eta,self.iters,self.C)\n",
    "            if(self.optimization == \"BFGSBinaryLogisticRegression\"):\n",
    "                #self.iters = 10\n",
    "                print(\"BFGS\")\n",
    "                hblr = BFGSBinaryLogisticRegression(self.eta,self.iters,self.C)\n",
    "            elif(self.optimization == \"StochasticLogisticRegression\"):\n",
    "                #self.iters = 2000 #1000\n",
    "                print(\"Stohastic\")\n",
    "                hblr = StochasticLogisticRegression(self.eta,self.iters,self.C)\n",
    "            else:\n",
    "                #self.iters = 100\n",
    "                #self.C = 0.001\n",
    "                print(\"Line Search\")\n",
    "                hblr = LineSearchLogisticRegression(self.eta,self.iters,self.C)\n",
    "\n",
    "            hblr.fit(X,y_binary)\n",
    "            #print(accuracy(y_binary,hblr.predict(X)))\n",
    "            # add the trained classifier to the list\n",
    "            self.classifiers_.append(hblr)\n",
    "            \n",
    "        # save all the weights into one matrix, separate column for each class\n",
    "        self.w_ = np.hstack([x.w_ for x in self.classifiers_]).T\n",
    "        \n",
    "    def predict_proba(self,X):\n",
    "        probs = []\n",
    "        for hblr in self.classifiers_:\n",
    "            probs.append(hblr.predict_proba(X).reshape((len(X),1))) # get probability for each classifier\n",
    "        \n",
    "        return np.hstack(probs) # make into single matrix\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return np.argmax(self.predict_proba(X),axis=1) # take argmax along row\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying Different Optimization Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "====Iteration 0  ====\n",
      "For  BFGSBinaryLogisticRegression  Accuracy of:  0.282178217822\n",
      "confusion matrix\n",
      " [[18 11  4  4  1]\n",
      " [13 10 10  5  0]\n",
      " [ 7 13 16 13  3]\n",
      " [ 1 14 18 13  6]\n",
      " [ 0  4 10  8  0]]\n",
      "Stohastic\n",
      "Stohastic\n",
      "Stohastic\n",
      "Stohastic\n",
      "Stohastic\n",
      "====Iteration 0  ====\n",
      "For  StochasticLogisticRegression  Accuracy of:  0.247524752475\n",
      "confusion matrix\n",
      " [[26  8  3  1  1]\n",
      " [25  7 11  3  0]\n",
      " [16 11 13 13  0]\n",
      " [16  5 15  4  0]\n",
      " [ 8  1 11  4  0]]\n",
      "Line Search\n",
      "Line Search\n",
      "Line Search\n",
      "Line Search\n",
      "Line Search\n",
      "====Iteration 0  ====\n",
      "For  LineSearchLogisticRegression  Accuracy of:  0.336633663366\n",
      "confusion matrix\n",
      " [[ 0  9 15  0  0]\n",
      " [ 1  7 34  0  0]\n",
      " [ 0  2 60  2  0]\n",
      " [ 0  1 46  1  0]\n",
      " [ 0  1 20  3  0]]\n"
     ]
    }
   ],
   "source": [
    "# run logistic regression and vary some parameters\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "# first we create a reusable logisitic regression object\n",
    "#   here we can setup the object with different learning parameters and constants\n",
    "\n",
    "optimizations = [\"BFGSBinaryLogisticRegression\",\"StochasticLogisticRegression\",\"LineSearchLogisticRegression\"]\n",
    "etas = [0.1, 0.1, 0.001]\n",
    "iters = [10, 5000, 150]\n",
    "\n",
    "for optimization,eta,iter_ in zip(optimizations,etas,iters):\n",
    "    lr_clf = MultiClassLogisticRegression(eta=eta,iterations=iter_, C=0.02, optimization=optimization) # get object\n",
    "\n",
    "\n",
    "    # now we can use the cv_object that we setup before to iterate through the \n",
    "    #    different training and testing sets. Each time we will reuse the logisitic regression \n",
    "    #    object, but it gets trained on different data each time we use it.\n",
    "\n",
    "    iter_num=0\n",
    "    # the indices are the rows used for training and testing in each iteration\n",
    "    for train_indices, test_indices in cv_object.split(X,y): \n",
    "        # I will create new variables here so that it is more obvious what \n",
    "        # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "        # but it makes this code less readable)\n",
    "        X_train = (X[train_indices])\n",
    "        y_train = y[train_indices]\n",
    "\n",
    "    #     print(X_train)\n",
    "    #     print(y_train)\n",
    "\n",
    "        X_test = (X[test_indices])\n",
    "        y_test = y[test_indices]\n",
    "\n",
    "#         st = time.time()\n",
    "        lr_clf.fit(X_train,y_train)  # train object\n",
    "#         t = (time.time() -st)\n",
    "#         lr_clf_times.append(t)\n",
    "\n",
    "        # train the reusable logisitc regression model on the training data\n",
    "        y_hat = lr_clf.predict(X_test) # get test set precitions\n",
    "\n",
    "        # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "        acc = mt.accuracy_score(y_test,y_hat+1)\n",
    "#         lr_clf_accuracies.append(acc)\n",
    "#         cost_accuracies.append([acc])\n",
    "\n",
    "        conf = mt.confusion_matrix(y_test,y_hat+1)\n",
    "        print(\"====Iteration\",iter_num,\" ====\")\n",
    "        print('For ',optimization,' Accuracy of: ',acc)\n",
    "\n",
    "        #print(\"accuracy\", acc )\n",
    "        print(\"confusion matrix\\n\",conf)\n",
    "        iter_num+=1\n",
    "\n",
    "        \n",
    "    # Also note that every time you run the above code\n",
    "    #   it randomly creates a new training and testing set, \n",
    "    #   so accuracy will be different each time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Pipelining PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line Search\n",
      "Line Search\n",
      "Line Search\n",
      "Line Search\n",
      "Line Search\n",
      "[48.11328125, 48.11328125, 48.203125, 48.203125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125, 48.20703125]\n",
      "====Iteration 0  ====\n",
      "For  BFGSBinaryLogisticRegression  Accuracy of:  0.311881188119\n",
      "confusion matrix\n",
      " [[27  1  1  4  3]\n",
      " [30  8  4  4  2]\n",
      " [19  9 11 17  9]\n",
      " [ 8  2  7  7 11]\n",
      " [ 0  0  5  3 10]]\n",
      "Line Search\n",
      "Line Search\n",
      "Line Search\n",
      "Line Search\n",
      "Line Search\n",
      "[48.47265625, 48.47265625, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.07421875, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125, 48.078125]\n",
      "====Iteration 0  ====\n",
      "For  StochasticLogisticRegression  Accuracy of:  0.29702970297\n",
      "confusion matrix\n",
      " [[17 10  2  3  1]\n",
      " [14 10  9 11  3]\n",
      " [16 16 16  8  8]\n",
      " [ 5  5 11  8  6]\n",
      " [ 3  1  1  9  9]]\n",
      "Line Search\n",
      "Line Search\n",
      "Line Search\n",
      "Line Search\n",
      "Line Search\n",
      "[48.34765625, 48.34375, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625, 48.34765625]\n",
      "====Iteration 0  ====\n",
      "For  LineSearchLogisticRegression  Accuracy of:  0.267326732673\n",
      "confusion matrix\n",
      " [[13  9  4  1  1]\n",
      " [13 16 13  7  2]\n",
      " [13 12 14 13 13]\n",
      " [11  3 11  7  7]\n",
      " [ 3  0 10  2  4]]\n"
     ]
    }
   ],
   "source": [
    "# run logistic regression and vary some parameters\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "# first we create a reusable logisitic regression object\n",
    "#   here we can setup the object with different learning parameters and constants\n",
    "\n",
    "optimizations = [\"BFGSBinaryLogisticRegression\",\"StochasticLogisticRegression\",\"LineSearchLogisticRegression\"]\n",
    "etas = [0.1, 0.1, 0.001]\n",
    "iters = [10, 5000, 150]\n",
    "components = 90\n",
    "pca = PCA(n_components=components)\n",
    "mglr = MultiClassLogisticRegression(eta=eta,iterations=iter_, C=0.02, optimization=optimization)\n",
    "\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "\n",
    "for optimization,eta,iter_ in zip(optimizations,etas,iters):\n",
    "    lr_clf = Pipeline([ ('pca', pca), (\"multiclasslogregression\", mglr)]) # get object\n",
    "\n",
    "\n",
    "    # now we can use the cv_object that we setup before to iterate through the \n",
    "    #    different training and testing sets. Each time we will reuse the logisitic regression \n",
    "    #    object, but it gets trained on different data each time we use it.\n",
    "\n",
    "    iter_num=0\n",
    "    # the indices are the rows used for training and testing in each iteration\n",
    "    for train_indices, test_indices in cv_object.split(X,y): \n",
    "        # I will create new variables here so that it is more obvious what \n",
    "        # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "        # but it makes this code less readable)\n",
    "        X_train = (X[train_indices])\n",
    "        y_train = y[train_indices]\n",
    "\n",
    "    #     print(X_train)\n",
    "    #     print(y_train)\n",
    "\n",
    "        X_test = (X[test_indices])\n",
    "        y_test = y[test_indices]\n",
    "\n",
    "#         st = time.time()\n",
    "#         lr_clf.fit(X_train,y_train)  # train object\n",
    "#         t = (time.time() -st)\n",
    "#         lr_clf_times.append(t)\n",
    "        print(memory_usage((lr_clf.fit, (X_train, y_train))))\n",
    "\n",
    "        # train the reusable logisitc regression model on the training data\n",
    "        y_hat = lr_clf.predict(X_test) # get test set precitions\n",
    "\n",
    "        # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "        acc = mt.accuracy_score(y_test,y_hat+1)\n",
    "#         lr_clf_accuracies.append(acc)\n",
    "#         cost_accuracies.append([acc])\n",
    "\n",
    "        conf = mt.confusion_matrix(y_test,y_hat+1)\n",
    "        print(\"====Iteration\",iter_num,\" ====\")\n",
    "        print('For ',optimization,' Accuracy of: ',acc)\n",
    "\n",
    "        #print(\"accuracy\", acc )\n",
    "        print(\"confusion matrix\\n\",conf)\n",
    "        iter_num+=1\n",
    "\n",
    "        \n",
    "    # Also note that every time you run the above code\n",
    "    #   it randomly creates a new training and testing set, \n",
    "    #   so accuracy will be different each time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting Values of C to Achieve Best Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 136.57 MiB, increment: 0.02 MiB\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.336633663366\n",
      "confusion matrix\n",
      " [[16 12  6  1  0]\n",
      " [10 17 19  4  1]\n",
      " [ 7 10 28  9  7]\n",
      " [ 8  3 20  3  5]\n",
      " [ 0  2  7  3  4]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.341584158416\n",
      "confusion matrix\n",
      " [[17 11 11  3  1]\n",
      " [11 18 12  6  2]\n",
      " [ 5 12 24 12  4]\n",
      " [ 3  4 14  8  3]\n",
      " [ 0  0 12  7  2]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFGS\n",
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.321782178218\n",
      "confusion matrix\n",
      " [[18 11  2  3  2]\n",
      " [11 13 23  4  0]\n",
      " [ 6  8 23 15  7]\n",
      " [ 2  9 18  7  5]\n",
      " [ 0  1  7  3  4]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.331683168317\n",
      "confusion matrix\n",
      " [[12 10  5  3  0]\n",
      " [ 8 13 12  6  2]\n",
      " [ 5 16 28 10  4]\n",
      " [ 2  6 16  7  4]\n",
      " [ 1  2 17  6  7]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.381188118812\n",
      "confusion matrix\n",
      " [[21  6  9  6  3]\n",
      " [ 8 15 11  2  1]\n",
      " [ 7 16 27 10  4]\n",
      " [ 2  6 10 10  2]\n",
      " [ 2  2 10  8  4]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.277227722772\n",
      "confusion matrix\n",
      " [[12 15  7  2  1]\n",
      " [10 11 14  3  1]\n",
      " [ 8 19 24 12  5]\n",
      " [ 4  7 13  7  5]\n",
      " [ 0  4 10  6  2]]\n",
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.341584158416\n",
      "confusion matrix\n",
      " [[14 11  5  3  0]\n",
      " [12 20 16  4  0]\n",
      " [ 8 10 19 12  3]\n",
      " [ 4  8 15 10  4]\n",
      " [ 3  2  9  4  6]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.326732673267\n",
      "confusion matrix\n",
      " [[15 10  5  5  1]\n",
      " [ 6 14 13  9  1]\n",
      " [ 8  9 22 13  7]\n",
      " [ 6  7 14 11  6]\n",
      " [ 1  1  6  8  4]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.346534653465\n",
      "confusion matrix\n",
      " [[14 14  6  4  1]\n",
      " [10 16 15  6  0]\n",
      " [ 8 10 24 15  7]\n",
      " [ 6  8  8 13  5]\n",
      " [ 1  0  3  5  3]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.30198019802\n",
      "confusion matrix\n",
      " [[19  4  4  2  0]\n",
      " [11 14  9  9  3]\n",
      " [ 6 23 14 12  7]\n",
      " [ 2 10 19 11  4]\n",
      " [ 1  2  7  6  3]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.292079207921\n",
      "confusion matrix\n",
      " [[14 12  8  3  0]\n",
      " [17 12 18  2  1]\n",
      " [11 14 20 12  2]\n",
      " [ 5  4 13 10  7]\n",
      " [ 1  1  6  6  3]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.326732673267\n",
      "confusion matrix\n",
      " [[17  8  6  3  1]\n",
      " [16 13 19  3  0]\n",
      " [ 6 15 21 15  2]\n",
      " [ 0  6 12 11  7]\n",
      " [ 2  3  5  7  4]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.29702970297\n",
      "confusion matrix\n",
      " [[13  9  8  7  0]\n",
      " [13 13 14  6  1]\n",
      " [ 8 15 24 13  6]\n",
      " [ 3  6 14  8  4]\n",
      " [ 1  0  5  9  2]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.356435643564\n",
      "confusion matrix\n",
      " [[17 11 12  1  0]\n",
      " [10 15 13  4  2]\n",
      " [ 5 17 30 11  1]\n",
      " [ 4  8 12  9  6]\n",
      " [ 1  2  5  5  1]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.356435643564\n",
      "confusion matrix\n",
      " [[21  7  4  4  0]\n",
      " [13 16 12  2  1]\n",
      " [ 4 13 23 14  4]\n",
      " [ 7  5 16 11 10]\n",
      " [ 0  0  6  8  1]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.336633663366\n",
      "confusion matrix\n",
      " [[16  9  6  4  1]\n",
      " [ 8 14 19  2  0]\n",
      " [11 11 25 10  8]\n",
      " [ 1  5 15  9  5]\n",
      " [ 1  2 12  4  4]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy 0.282178217822\n",
      "confusion matrix\n",
      " [[13 10  8  5  0]\n",
      " [12 13 20  6  0]\n",
      " [12 10 26 12  4]\n",
      " [ 6  5 13  3  4]\n",
      " [ 1  3  7  7  2]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.311881188119\n",
      "confusion matrix\n",
      " [[13  8  5  5  2]\n",
      " [12 12 20 12  2]\n",
      " [ 7  5 23 10  6]\n",
      " [ 5  4 10 11 10]\n",
      " [ 1  1  7  7  4]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.326732673267\n",
      "confusion matrix\n",
      " [[19  8  8  1  0]\n",
      " [12 11 15  1  1]\n",
      " [ 4 18 25 17  2]\n",
      " [ 2 10 18  8  2]\n",
      " [ 0  4  6  7  3]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.306930693069\n",
      "confusion matrix\n",
      " [[14 10 10  0  3]\n",
      " [10 14 14  4  0]\n",
      " [ 7 10 28 12  8]\n",
      " [ 3  4 21  5  5]\n",
      " [ 0  3 12  4  1]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy 0.331683168317\n",
      "confusion matrix\n",
      " [[15  8 11  5  1]\n",
      " [ 6 13 17  4  0]\n",
      " [ 3 16 22 12  2]\n",
      " [ 0  9  9 16  5]\n",
      " [ 0  1 12 14  1]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.361386138614\n",
      "confusion matrix\n",
      " [[14  5  9  2  1]\n",
      " [ 9 18 12  1  0]\n",
      " [ 3 14 26 15  1]\n",
      " [ 3 16 15 13  4]\n",
      " [ 3  1  9  6  2]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.341584158416\n",
      "confusion matrix\n",
      " [[13 13  6  6  0]\n",
      " [ 5 16 11  3  0]\n",
      " [ 3 18 25 17  1]\n",
      " [ 1  9 18 13  2]\n",
      " [ 1  1 10  8  2]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy 0.316831683168\n",
      "confusion matrix\n",
      " [[17 11  7  0  0]\n",
      " [13 17 13  7  2]\n",
      " [ 5 14 19 15  5]\n",
      " [ 6 12  8 10  3]\n",
      " [ 0  2  8  7  1]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy 0.29702970297\n",
      "confusion matrix\n",
      " [[13 20 13  3  0]\n",
      " [12 20 13  2  0]\n",
      " [ 5 17 17  8  3]\n",
      " [ 3  8 12 10  4]\n",
      " [ 2  3  8  6  0]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.371287128713\n",
      "confusion matrix\n",
      " [[20 19  5  2  0]\n",
      " [ 5 15 13  7  0]\n",
      " [ 4 22 22 10  3]\n",
      " [ 4  8 12 16  3]\n",
      " [ 0  2  5  3  2]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy 0.287128712871\n",
      "confusion matrix\n",
      " [[11  9  5  4  0]\n",
      " [19 12 11  3  0]\n",
      " [ 6 23 22 14  2]\n",
      " [ 4 14 10 12  3]\n",
      " [ 1  1 10  5  1]]\n",
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFGS\n",
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy 0.326732673267\n",
      "confusion matrix\n",
      " [[15 13  9  1  0]\n",
      " [12 20 13  2  0]\n",
      " [ 8 15 22  5  1]\n",
      " [ 3 11 21  9  1]\n",
      " [ 0  4 14  3  0]]\n",
      "BFGS\n",
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.356435643564\n",
      "confusion matrix\n",
      " [[14 13 10  2  0]\n",
      " [ 9 18 14  2  0]\n",
      " [ 7 10 36  4  2]\n",
      " [ 1  9 26  4  0]\n",
      " [ 0  2 16  3  0]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.366336633663\n",
      "confusion matrix\n",
      " [[20 17  6  0  1]\n",
      " [ 5 17 12  2  2]\n",
      " [ 1 14 31  8  4]\n",
      " [ 4  9 23  3  2]\n",
      " [ 1  1 12  4  3]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.376237623762\n",
      "confusion matrix\n",
      " [[18 14 10  1  0]\n",
      " [10 16 21  1  0]\n",
      " [ 6 10 38  2  2]\n",
      " [ 1  3 23  4  0]\n",
      " [ 1  1 15  5  0]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.361386138614\n",
      "confusion matrix\n",
      " [[11  8 12  1  0]\n",
      " [10 14 17  1  3]\n",
      " [ 7  8 42  0  7]\n",
      " [ 5  2 31  4  6]\n",
      " [ 1  1  7  2  2]]\n",
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFGS\n",
      "BFGS\n",
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy 0.336633663366\n",
      "confusion matrix\n",
      " [[20 15  6  0  2]\n",
      " [ 8 19 15  3  2]\n",
      " [ 6 11 22  4  5]\n",
      " [ 5  5 29  6  4]\n",
      " [ 0  2 12  0  1]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.227722772277\n",
      "confusion matrix\n",
      " [[27  0  5  0  2]\n",
      " [29  0  7  2  3]\n",
      " [45  0 11 10  7]\n",
      " [12  0 12  3  6]\n",
      " [ 7  0  3  6  5]]\n",
      "BFGS\n",
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.316831683168\n",
      "confusion matrix\n",
      " [[13 24  2  1  0]\n",
      " [14 14  6  0  0]\n",
      " [23 11 30  4  1]\n",
      " [12  7 13  7  3]\n",
      " [ 2  1  9  5  0]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFGS\n",
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy 0.30198019802\n",
      "confusion matrix\n",
      " [[32  0  1  2  0]\n",
      " [22  0  8 11  1]\n",
      " [40  0 18  9  1]\n",
      " [16  0 13  9  2]\n",
      " [ 4  0  7  4  2]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy 0.237623762376\n",
      "confusion matrix\n",
      " [[31  1  3  0  0]\n",
      " [35  1  2  5  0]\n",
      " [43  3  6  8  1]\n",
      " [23  1 10 10  0]\n",
      " [ 8  0  4  7  0]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFGS\n",
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy 0.292079207921\n",
      "confusion matrix\n",
      " [[28  0  8  0  0]\n",
      " [37  0 10  1  0]\n",
      " [26  0 21  4  1]\n",
      " [19  0 18  8  3]\n",
      " [ 4  0  7  5  2]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.19801980198\n",
      "confusion matrix\n",
      " [[28  1  0  0  4]\n",
      " [38  1  0  4  5]\n",
      " [28  1  0 14 16]\n",
      " [24  0  0  4 13]\n",
      " [ 6  0  0  8  7]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy 0.222772277228\n",
      "confusion matrix\n",
      " [[21  0  0 16  0]\n",
      " [16  0  0 24  0]\n",
      " [30  0  0 45  0]\n",
      " [ 9  0  0 22  1]\n",
      " [ 3  0  0 13  2]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.242574257426\n",
      "confusion matrix\n",
      " [[40  0  0 11  0]\n",
      " [32  0  0 14  0]\n",
      " [35  0  0 20  5]\n",
      " [18  0  0  9  0]\n",
      " [ 5  0  0 13  0]]\n",
      "BFGS\n",
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFGS\n",
      "BFGS\n",
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy 0.193069306931\n",
      "confusion matrix\n",
      " [[21  0  0 14  0]\n",
      " [16  0  0 26  0]\n",
      " [19  0  0 53  6]\n",
      " [12  0  0 17  4]\n",
      " [ 4  0  0  9  1]]\n",
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFGS\n",
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.212871287129\n",
      "confusion matrix\n",
      " [[19  0  0 17  0]\n",
      " [20  0  0 32  0]\n",
      " [21  0  0 36  0]\n",
      " [ 7  0  0 24  0]\n",
      " [ 6  0  0 20  0]]\n",
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.217821782178\n",
      "confusion matrix\n",
      " [[13  0  0 16  0]\n",
      " [15  0  0 35  0]\n",
      " [25  0  0 34  0]\n",
      " [17  0  0 31  0]\n",
      " [ 5  0  0 11  0]]\n",
      "BFGS\n",
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFGS\n",
      "BFGS\n",
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy 0.217821782178\n",
      "confusion matrix\n",
      " [[ 0  0  0 32  2]\n",
      " [ 0  0  0 48  2]\n",
      " [ 0  0  0 53  1]\n",
      " [ 0  0  0 41  1]\n",
      " [ 0  0  0 19  3]]\n",
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.227722772277\n",
      "confusion matrix\n",
      " [[22  0  0 17  0]\n",
      " [18  0  0 26  0]\n",
      " [25  0  0 36  0]\n",
      " [ 7  0  0 24  0]\n",
      " [ 5  0  0 22  0]]\n",
      "BFGS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/Omar/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.20297029703\n",
      "confusion matrix\n",
      " [[21  0  0 24  0]\n",
      " [14  0  0 29  0]\n",
      " [17  0  0 42  0]\n",
      " [13  0  0 20  0]\n",
      " [ 1  0  0 21  0]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.212871287129\n",
      "confusion matrix\n",
      " [[ 0  0  0 40  0]\n",
      " [ 0  0  0 45  0]\n",
      " [ 0  0  0 58  0]\n",
      " [ 0  0  0 43  0]\n",
      " [ 0  0  0 16  0]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.212871287129\n",
      "confusion matrix\n",
      " [[ 0  0  0 32  0]\n",
      " [ 0  0  0 47  0]\n",
      " [ 0  0  0 61  0]\n",
      " [ 0  0  0 43  0]\n",
      " [ 0  0  0 19  0]]\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "BFGS\n",
      "====Iteration 0  ====\n",
      "accuracy 0.20297029703\n",
      "confusion matrix\n",
      " [[ 0  0  0 29  0]\n",
      " [ 0  0  0 53  0]\n",
      " [ 0  0  0 65  0]\n",
      " [ 0  0  0 41  0]\n",
      " [ 0  0  0 14  0]]\n"
     ]
    }
   ],
   "source": [
    "# run logistic regression and vary some parameters\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "# first we create a reusable logisitic regression object\n",
    "#   here we can setup the object with different learning parameters and constants\n",
    "lr_clf_accuracies = []\n",
    "lr_clf_times = []\n",
    "\n",
    "costs = np.logspace(-3,1)\n",
    "costs.sort()\n",
    "\n",
    "cost_accuracies = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for cost in costs:\n",
    "    lr_clf = MultiClassLogisticRegression(eta=0.1,iterations=10, C=cost, optimization=\"BFGSBinaryLogisticRegression\") # get object\n",
    "\n",
    "\n",
    "    # now we can use the cv_object that we setup before to iterate through the \n",
    "    #    different training and testing sets. Each time we will reuse the logisitic regression \n",
    "    #    object, but it gets trained on different data each time we use it.\n",
    "\n",
    "    iter_num=0\n",
    "    # the indices are the rows used for training and testing in each iteration\n",
    "    for train_indices, test_indices in cv_object.split(X,y): \n",
    "        # I will create new variables here so that it is more obvious what \n",
    "        # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "        # but it makes this code less readable)\n",
    "        X_train = (X[train_indices])\n",
    "        y_train = y[train_indices]\n",
    "\n",
    "    #     print(X_train)\n",
    "    #     print(y_train)\n",
    "\n",
    "        X_test = (X[test_indices])\n",
    "        y_test = y[test_indices]\n",
    "\n",
    "        st = time.time()\n",
    "        lr_clf.fit(X_train,y_train)  # train object\n",
    "        t = (time.time() -st)\n",
    "        lr_clf_times.append(t)\n",
    "\n",
    "        # train the reusable logisitc regression model on the training data\n",
    "        y_hat = lr_clf.predict(X_test) # get test set precitions\n",
    "\n",
    "        # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "        acc = mt.accuracy_score(y_test,y_hat+1)\n",
    "        lr_clf_accuracies.append(acc)\n",
    "        cost_accuracies.append([acc])\n",
    "\n",
    "        conf = mt.confusion_matrix(y_test,y_hat+1)\n",
    "        print(\"====Iteration\",iter_num,\" ====\")\n",
    "        print(\"accuracy\", acc )\n",
    "        print(\"confusion matrix\\n\",conf)\n",
    "        iter_num+=1\n",
    "    \n",
    "# Also note that every time you run the above code\n",
    "#   it randomly creates a new training and testing set, \n",
    "#   so accuracy will be different each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111549438>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEjCAYAAAAhczZxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xd4XNWZ+PHvqzJqo15tuchYBuMCxhg7gAmhG0JCQnZD\nW9i0Jd70ZFPYbJLlt8mmbepuSAibSugJISEJ2JSwEGPAhWLLuMldzSpW79Kc3x/33vFoNDO6M5qR\nZOn9PI8ea249Mx7NO+e8p4gxBqWUUmosSZNdAKWUUqcGDRhKKaVc0YChlFLKFQ0YSimlXNGAoZRS\nyhUNGEoppVzRgHEKEJFbROSpeB87FYjIPBHpEpHkBFz7ThG5L97XTfS1x7jvhSKy337N3jXR949E\nRIyIVMZ4bkLeByJykYjsjec1Z7IZFzBE5LCI9IpIp4i0ichmEVkvIq5eCxF5m4jUJLqcgYwx9xtj\nroz3sbEQkfeJyE4R6RGRBhH5iYjkRXH+YRG53HlsjDlqjPEaY4YTU+KQZSgXkSERWRhi32Mi8p2J\nKksM/gP4kf2a/SF4Z8D7u8v+//mViHgnoZxRidf7IDhoGWP+Zow5Y/wlHHGPi+zXt0tEuu17dgX8\nzIvn/aIo19tFZJNdhkYR+auIXB3Pe8y4gGF7hzEmG5gPfBP4AvDzibixiKRMxH0SQUT+BfgW8Dkg\nF3gL1mv4tIh4JrNs0TDG1ALPArcGbheRAuAa4NeTUS6X5gO7xjjmHcYYL7ACOAf414SXahxOtb8J\nOwh57dd4qb05z9lmjDkazfXi8fxF5BbgAeB/gdnALOA/gXeO99ojGGNm1A9wGLg8aNtqwAcssx+n\nAd8BjgLHgbuBDCAL6LWP7bJ/ZmMF3juAA0AL8AhQYF+rAjDAB+3rvRCw7f3AMaAVWA+cB+wA2rC+\nRTrlex+wKeCxsY/fbx97FyAxHJsMfBdoBg4BH7OPTwnxuuXYz/e9Qdu9QBPwAfvxncDvgIeBTuBV\n4Gx732/s167XvtbnA16LFPuY/wO+Bmy2j/kTUAjcD3QAW4GKgPv/0H4NO4DtwEUB++4E7gvzPrgZ\nOBC07SPAa9FeG3gbUBPufRbp/RGmbP8EVAMngMeB2fb2A0GvX9pY72/g28BfAh6HfG8H7P88UA/U\nAR+y/28qA/5vPjTG+9I59u3Aa/Zrdwy4M+A45/881N9ECnA+J/++uoA+4HDA3+pLWO/leuBHgMfe\n94J9jW77vBuC/2+AM+3n0YYVeN8ZsO9XWH8ff8F6774CLBzj88Rf7qDtBcC9QIP9/P8dSLL3rQf+\nat+rFfhSwLYfAe1Yf6+rgNuBWvv/6sYwZUix7/PxRH9+ztQaxgjGmC1ADXCRvembwOlY39AqgXLg\nK8aYbuBqoM6c/DZRB3wceBdwMVYAacV6MwS6GOvNelXAtjXAIqw39g+AfwMux/rW8l4RuThCsa/F\nCjBnAe8Nuq7bY//Jfj4rgJX2cwjnAiAd+H3gRmNMF/AEcEXA5uuA32L90TwA/EFEUo0xt2J9QLzD\nfu2+HeZeN2J9+y8HFmJ9QPzSvt5urD8+x1a7/M69fisi6RGeh+MxoEhE1gZsu5WRtYtYrx3MzfsD\nABG5FPgG1v/TLOAI8BCAMWYhI1+//kg3FZE5WP+/1QGbQ7637ePXAZ/Beg9WYn3YxqobuA3Iwwoe\n/xwi5xLqbwJjzEvm5Df4fKwP7gft3cPAp4EirMByGVagxxjzVvuYs+3zHw68roikYn0BeQoowfp/\nuV9EApusbgT+n33faqxv6bG4H+uD/zSsIPcuRtZo3wq8bj+P79rbLsL6olQA/AF4FOv1WYD1t/qT\nMO+/ZUAp1he1xEp0RJpqP4SoYdjbX8b6wBasN/vCgH3nA4fs39/G6G+Tu4HLAh7PAgaxIn8F1jeQ\n00J8KykP2NYC3BDw+FHgU/bv72P0N7m1AY8fAe6I4di/Ah8O2Hc54WsY/wA0hHlNvwk8bf9+J/By\nwL4krG+CF4V6/Qldw/i3gP3fBZ4MePwO4PUI/7+tnKzR3EmYGoa9/2fAPfbvi4ABoCTaa4d5T/if\nZ6T3R4h7/Bz4dsBjr31sRaT3b9B9u7C+IRusprc8e99Y7+1fAN8I2FdJjDWMEOX6AfD9oP/zUH8T\nwd/UfwL8GfvbeYjrfgp4LFwZAv9vsD6QGwKvhRWI7rR//xXws4B91wB7wr3W4cqN1WzYDaQGbHs/\n9vsYqzaxL+g664GdAY/Ps6+bG7CtG1gcogyXYdU8Q75G8fw5pdoOE6wcqwmgGMgEtouIs0+wmm/C\nmQ88JiK+gG3DWFHfcSzEeccDfu8N8ThSsrIh4PeeGI+dHVSuUGV0NGN9I08xxgwF7Ztl7x91HWOM\nz+4kMDvCtYO5fl1E5LNYTRuzsf7AcrC+tbnxa+BxEfkE1re/jcaYxjhdO1Ck90dt0LGzsZrxAKsG\nJyItWO/Pwy7v9y5jzDN2DfUBu8xtjP3eng1sC7hOpPdDRCKyBuuLxDLAg9UU9tugwyJeX0Q+jPWB\nv8YY47O3nQ58D6u5JhPrS9l2l8WaDRxzrmU7gvXaOqL5uwpnPlZtvCngdU5iZE3PzedBvzGmPWhb\nqPK0YP0/lmJ9OUsYbZICROQ8rDfNJqwPvl5gqTEmz/7JNVb1GKwPjmDHgKsDjs8zxqQbK7lKhPMm\nWz0wJ+Dx3AjHvgT0A9cHbrR74FyN9U121HXs3mdzsNrEIY6vg4hchNXm/l4g3xiTh9UMIBFPPGkT\n1peE67BqUP7mqCiv3Y314eWcm4z14exw8/5w1GF94DjXysLK4YQ6NiJjzPNY35qdXl9jvbfHej+M\neJ5AWYTbP4CVf5lrjMnFypUEv3Zh3wv26/9V4DpjTEfArp8Ae4BFxpgc4IshrhtOHTA3qEfkPGJ4\nbcdwDKuWlx/wOucYY1YGHBPPz4MqrGDznjheM6QZHTBEJEdErsVqI77PGLPT/vbxv8D3RaTEPq5c\nRJx21uNAoYjkBlzqbuA/RWS+fXyxiFw3cc8kZo8An7SfXx5Wb7GQ7G86/w/4HxFZJyKpIlJhX6MG\nK6HtOFdErrd7f3wKK9C8bO87jtWuGw/ZwBBW0j1FRL6CVQtwxVj1+Xuxen7lYbVvx3LtfUC63a0x\nFSuJmRawP5r3x4PA+0VkhYikAV8HXjHGHHb7vIL8ALhCRM528d5+xL73mSKSCXw56FqvA9eLSKbd\ndfWDEe6bDZwwxvSJyGqsTgauiMhcuyy3GWP2hbhuB9AlIouBfw7aH+n99QpWreHz9vv3bVhNnA+5\nLZsbxphDWO/3b4tItogkiciioHxZPO83BHwW+JqI3Bpwz4tF5MfxvNdMDRh/EpFOrG8C/4ZVxX1/\nwP4vYFUfXxaRDuAZ4AwAY8werD/qg2KN45iN1ZvmceAp+7ovYyW0p7r/xUoA7sDq0fIE1odkyL7w\nxkpSfxHrG2sH1h/gMaz2+cAE7B+xEvmtWE091xtjBu193wC+ZL92nx1n+TcCG7A+sI9g9aaJthnl\nXqxvmQ8HPQfX17aD6UewciK1WN/EA8fquH5/GGOewfqgfhTrG/9CrERsTIwxTVjP8Sv2pkjv7SeB\n/waec46xz3Fel+9j5XmOY9XG7o9w648A/2E/369gBQC3LsNO4gaMbXC6En8WK/h0Yr1/Hw46907g\n1/b7672BO4wxA1gB4mqs2taPsYLSnijK5tZNWF9C9mDVYh9mZBN1XBlj7sOqJa/Het80YHUO+WM8\n7+N0r1QKe5DP3caY+WMeHP4ad2IlHf8hbgVTk0JEzsRq7kgLkbdSM9BMrWEoQEQyROQaEUkRkXKs\nbySPTXa51OQRkXeLSJqI5GM11f1Jg4VyaMCY2QQrL9GK1SS1m5NNF2pm+jDQiDVIcJjROQI1g2mT\nlFJKKVe0hqGUUsoVDRhKKaVcmVYjvYuKikxFRcVkF0MppU4Z27dvbzbGFI995DQLGBUVFWzbtm3s\nA5VSSgEgIkfcHqtNUkoppVxJaMCwp5DYKyLVInJHhOPOE2sFtL+L9lyllFITI2EBw56A7S6sYfhL\ngJtEZEmY476FNUVFVOcqpZSaOImsYawGqo0xB+05XB7CmhU02Mex5s1pjOFcpZRSEySRAaOckZO1\n1TBy3nns6SjejTVlcVTnKqWUmliTnfT+AfCFoAVNoiIit4vINhHZ1tTUFMeiKaWUCpTIbrW1jFyA\nZQ6jFypZBTxkr0pVBFwjIkMuzwXAGHMPcA/AqlWrdJ4TpZRKkETWMLYCi0RkgYh4sOb0fzzwAGPM\nAmNMhTGmAmsB848YY/7g5lylprIvPraTR7bFvMKpUlNSwgKGPSXyx7AWotkNPGKM2SUi60VkfSzn\nJqqsSsXT4LCPR7Ye46ldDWMfrNQpJKEjvY0xT2Ct4ha47e4wx75vrHOVOhUcaelhyGeoa+ub7KIo\nFVeTnfRWatqpbuwCoL69d5JLolR8acBQKs4ONFkBo7VnkN6BkMujK3VK0oChVJw5NQyAOq1lqGlE\nA4ZScVbd2EWWJxmAes1jqGlEA4ZSceTzGQ40dXH+wiIA6tq0hqGmDw0YSsVRfUcfPQPDXFhZiIg2\nSanpRQOGUnHk5C/OnJVDkTdNm6TUtKIBQ6k4cgJGZYmX2XkZWsNQ04oGDKXiqLqxi7zMVAqzPMzO\nTdcchppWNGAoFUcHGruoLPYiIszKzaC+vQ9jdE5MNT1owFAqjqqbuqgs8QIwOy+dnoFhOnqHJrlU\nSsWHBgyl4uRE9wAnugcCAkYGALXaLKWmCQ0YSsWJk/BeaAeMWbnpgM4ppaYPDRhKxYm/h1SxFTDK\n7RpGXbt2rVXTgwYMpeKkurGLjNRkf6Ao8qaRmizaU0pNGxowlIqT6qYuTivOIilJAEhKEkpz0qnX\ngKGmCQ0YSsXJgcaTPaQc1uA9bZJS04MGDKXioLt/iNq2Xn/+wqGD99R0ogFDqTg42NQNMKqGMSsv\ng+Mdffh8OnhPnfo0YCgVB9VNncDogDE7N53BYUNzV/9kFEupuNKAoVQcVDd2kZwkzC/MGrE9UYP3\njDHc/fwBDjV3x/W6SkWiAUOpONh/vIv5hZl4Ukb+Sc3KtQJGfZwT301d/XzzyT3c9Vx1XK+rVCQa\nMJSKg+qmrlEJb7Dmk4L4r7x37EQPAM/sPs7gsC+u11YqHA0YSo3TwJCPIy09o/IXALkZqWR6kuNe\nwzhqB4y2nkG2HDoR12srFY4GDDXjPLz1KL/efDhu1zvS0s2wz7CodHTAsKY5j3/X2qMtvYhARmoy\nG6oa4nptpcLRgKFmFGMM3396P/+1cS/9Q8NxuebJOaSyQ+5PxOC9Iye6KctJ55LFxWzc1aDddtWE\n0IChZpQDTd00dPTR1T/E5uqWuFzz5Cy1WSH3z87NiPv0IMdO9DC3IJOrlpbR2NnPa8fa4np9pULR\ngKFmlE37mwDwpCTFrSmnuqmL8rwMMj0pIffPykunqaufgaH4JaePnuhhXkEmly4uwZOcxIaq+rhd\nW6lwNGBE8N2n9vKDZ/ZNdjFUHG2qbmFeQSZXLyvjqTcbGIpDD6Pqxi7/GhihzM7NwBg43hG+WerF\n6mbe/8strsrTNzjM8Y5+5hVkkp2eygWVhWzY1RDXpWCNMfzx9Vr+/u7NHG3pidt11alNA0YYLV39\n3P38AR7acmyyi6LiZGjYx8sHW7iwsoh1S8to7Rlky+Hx9TDy+QwHwnSpdcxy0bX2wS1HeW5vk7/3\nUyQ1rdYx8wszAVi3tIxjJ3p5s74jmqKHdaSlm9t+sYVPPvQ6Ww+3snWcr5GaPhIaMERknYjsFZFq\nEbkjxP7rRGSHiLwuIttEZG3AvsMistPZl8hyhvK77TUMDhsaOvpo7NTZRqeDN2ra6Oof4qJFRVx8\nRjFpKUlsHGezVG1bL32DvpBdah2z/QsphQ4YPp9h8wErn+LkQyI5Yn/jn1tgBYzLl5SSJIz7uQwM\n+bjruWqu/P4LvHa0jc+vOwOwlp5VChIYMEQkGbgLuBpYAtwkIkuCDnsWONsYswL4APCzoP2XGGNW\nGGNWJaqcofh8hge3HCU/MxWAqtr2iby9SpBN+1sQgfNPKyTTk8LFpxezcdfxcfUwqm6ye0iN0SQF\nUNcW+ovH7oYO/4fyfhcBw6mFzLMDRpE3jfMqCtiwK/aAsfXwCd7+33/jvzbu5bIzS3jmMxfzzxcv\nxJOcRHO3zoOlLImsYawGqo0xB40xA8BDwHWBBxhjuszJhtcsYEr0DXz5YAuHW3r4lyvPQAR21sSn\nqq8m16bqJpbNziU/ywPAumVlNHT08UZN7D2MDjSOHTAyPMnkZaaGXdt70/5mALxpKf7rRXL0RA+Z\nnmQK7ecB1nPZd7yLA01jnx/s2d3H+fu7X6JnYJif/+MqfnzLuZTlpiMiFHo9nOjSGoayJDJglAOB\nCYAae9sIIvJuEdkD/AWrluEwwDMisl1Ebk9gOUe5f8tRcjNS+btz57Cw2MtOrWGc8rr6h3jtaBtr\nFxX5t122uJSUJBnXN/Pqxi4KsjwUBHx4h2J1rQ1dw9hU3cyiEi8r5ub5ayyRHLN7SImIf9tVS8sA\n2BjDc3lk2zFKc9J4+jNv5bIzS0fsK8jy0KJNUso26UlvY8xjxpjFwLuArwbsWms3VV0NfFRE3hrq\nfBG53c5/bGtqahp3eZq7+nlqVwPvWTmH9NRklpfnsrNW+7if6rYcamHIZ1hbeTJg5Gamcv7CQjZW\nxd7DqLoxcsLbMTsvPeSMtX2Dw2w9fIILK4uoLPFyoLFrzLI4XWpHXj+Ds+fkRp3H6BkY4vl9Taxb\nWhayW3ChN00DhvJLZMCoBeYGPJ5jbwvJGPMCcJqIFNmPa+1/G4HHsJq4Qp13jzFmlTFmVXFx8bgL\n7SS7b15jFX15eS7HO/o18X2K+9v+ZtJSkjh3fv6I7euWlXG4pYe9xzujvqYxhuqmyF1qHbNyM0LO\nJ/XqkVb6Bn1ctKiIhSVeugeGI847ZYwJGTAArlpWxhs17VFNpf7Cvib6Bn1ctaws5P6iLA8tupaH\nsiUyYGwFFonIAhHxADcCjwceICKVYterRWQlkAa0iEiWiGTb27OAK4GqBJYVOJnsXl1RQGWJNc3D\n8jm5gCa+T3UvVjezekEB6anJI7ZfsaQUEWIaxFfT2ktbzyCLXASM2XkZtPcO0t0/NGL7pupmkpOE\nNacV+msqkXpKNXX20zfoY17h6ICxzm6WeiqKZqkNVQ3kZ6ayuqIg5P6CLA8tmsNQtoQFDGPMEPAx\nYCOwG3jEGLNLRNaLyHr7sPcAVSLyOlaPqhvsJHgpsElE3gC2AH8xxmxIVFkdLx1s4UhLDzetOVkx\nWjIrBxHYUaMB41TV2NHHvuNdXBjQHOUoyU5n1fz8mALGb7fXIGIFnbE405wHJ743VTdzztw8vGkp\n/sR5pIDh9JCaG6KGcVqxl9NLva6fy8CQj2d3N3LFklJSkkN/FBR60+gdHKZnYCjkfjWzJDSHYYx5\nwhhzujFmoTHmP+1tdxtj7rZ//5YxZqnddfZ8Y8wme/tBY8zZ9s9S59xEe+CVo+RlpnL1sln+bVlp\nKSws9moN4xS2qdrqhbQ2RMAAK2G8p6GTw1GsXjc07OPhrUd566LikB/ewWaF6Frb1jPAztp2fyK+\nyOshNyM1YuI7uEttsHVLy9h6+ISrJWE3H2ims3+IdWGaowB/TyytZSiYAknvqaKps5+NAcnuQGeV\n57rqKWWMiepDZyaoa+uldyA+s8KG09DeFzFRvKm6mYIsD0tm5YTcH0sPo+f2NnG8o5+bVs9zdfys\n3NE1jJcOtGDMyUAmIlSWeMesYYjAnPyMkPuvWlaGz8Azbx4fs0wbdzXgTUvhgoWhAylAodcKGDp4\nT4EGDL/fba9hyGe4afXcUfuWOYnvCHMBAfx5Rz1v+87/sadBx22ANb3KZd99nsu/9zx/3TP2B1gs\n9jR0cOG3/srX/rI75H5jDJv2N3PBwkKSkiTkMXMLMllWnhNV99oHXjlCSXYal51Z4up4a1wD1AbU\nMP5W3Yw3LYWz5+b5t1UWeyOOxTh6oodZOemkpSSH3L9kVg7zCzN5eNuxiEF02Gd4atdxLllcMuoL\nUqBCbxoALTp4T6EBAwhIdi84mewO5CS+x6pl/HlHHQAvH4jPtNmnukdfraF3cJjUZOEDv9rGR+7f\nHnECvlg8saOeYZ/h55sO8dhrNaP2Vzd20djZH7Y5yrFuaRmvHW2jwcW6FbVtvfzfviZuOG8uqWHa\n/oOlJidRkp02YprzF6ubectpBSOuUVnipaV7gNYw3+iPtvREbAITEdZfvJDXjrbxdIRaxrbDJ2jp\nHvAnysNxmqSatUlKoQEDgM0HWjh6ooebwzQvOInvSAHD6c8OsO1Ia0LKeSoxxvDglmOcV5HPU5++\nmM9ddQbP7m7ksu8+z683H2Y4Tgv+bNjVwHkV+axZUMAdj+4clWty8hehEt6B1tl5q6feHLuW8fCW\nowDccN7o2mgkgV1rj53o4UhLz6hy+RPfYfIY4brUBvr7c+dwWnEW/7Vxb9jXecOuBjwpSbztjMhd\n0bVJSgXSgAE8sOUIeZmpYZN/WWkpVI6R+Hb6s8/OTedVDRi8dKCFQ83d3LxmHp6UJD56SSUbP/VW\nzpmXx78/vovrf/wiexuiH/sQ6EBTF/uOd/H25bO465aVFGZ5+PBvto8YN7BpfzMVhZljJqYrS7xU\nlozdw2ho2MfD245x8enFzMkfO9kdqDwvwz9jrRPILloUJmCEaJbqHRimsbN/zICRkpzE5648g/2N\nXTz66uhalzGGjVUNvHVRMVlpodfwcGR6UkhPTdKxGArQgEFX/xDP7WkKmewOtLw8N2LXWqc/+wfW\nLqCuvS/uazifah6wp1cJ7HFWUZTFvR9YzQ9vXEFtWy83/+/L43qdnCT1VcvKKPKm8dNbV9Hc1c9H\nH3iVwWEfgwHTmbtx7Vmz2HygJWLC+K97GqNKdgealZtOXXuvlVepbqY0J42FQaPEy/MySE9NChkw\nnGnNQ43BCLZuWRlnz8nlB0/vo29wZKeDnbXt1LX3RewdFagwS0d7K8uMDxjetBSe//zb+PDFp0U8\nbll5Lo2doRPf/UPD/v7saxYUArB9BtcymrvC9zgTEa5bUc5Dt59P/5CP9fdtH/WB5tbGqgZWzM3z\nd1ldPieXb1y/nJcPnuDrT+zmjWNtdA8Mj/oWH876ixeyvDyXTz/8ethJ/B7YcpTSnDQuW+wu2R1o\nVl4GfYM+TnQPsLm6mbWVxSPmgwJIShJOKwrdU2qsLrWBRIQvrFtMXXsf9718ZMS+J6saSEkSLneZ\nsC/y6uA9ZZnxAQOswVsl2ekRj4mU+N58oMXfn/3MWdlkpCbP6IARPL1KKJUlXr5/wwp21LTzb49V\nRT2XU21bL2/UtI/6lnz9yjm8/8IKfvniYb765zft6czdBYz01GTuvvVcPClJ3H7vNjr7Bkfsr2nt\n4fl9Tdywam7YgW6RlNuD957d3UhrzyBrFxWGPC5c19poAgbABZVFXLSoiB89V02H/VyMMWyoauD8\nhYXkZUaeMNFhTUCoTVJKA4ZrS2blkBRmxPfGqpP92VOSk1gxN49tR2bmKmU+n+GhoOlVwrliSSmf\nvGwRj75aw683H47qPs70F1eF6OXzxWvO5C2nFfBGTTtnleeSa69r4kZ5XgY/unklh1t6+PTDb4xY\nK+Phrdbky++NMtntcGpCj2yzrnNhmPEPlSVeatt6R42uPtLSQ5YnecyZcQN9Yd1i2noGuef5g4C1\n3sah5u6Qr1s4hd40neJcARowXAs34nvYZ3jqzZH92VdV5LO7vnPUvEEzwUv2WiI3r3HXxv/JyxZx\n+ZmlfPUvu3n5oPvuyBuqGlhcls2CoqxR+1KTk7jr5pUsKvHyzhWjZtQf0/kLC/nS28/kmd3H+e+/\n7geckd3HeFsMyW6Hs1TrtiOtnFGaTUlO6Fqtk/g+2DRyEOixE1aX2uBmrEiWledy7Vmz+PmmQzR2\n9rGhqgERuNLFdCaOwiwPzd0DcV0zXJ2aNGBEYXmIEd9bD5/gRFB/9pXz8xn2Gd44NvOmRX9gy9GI\nPc6CJSUJ37/hbCoKM/no/a+6mmm1uaufrYdPRPyWXOhN4+nPXMwH1y5wXfZA77uggutXlvODZ/bz\n9JvHeXZPI42d/dy8Zn5M1wMoykojNdn6sI+UiA/XU+roiR7/Ot7R+OyVZzA47ON/nq1mQ1UD587L\nDxusQin0ehgY8tGd4BH7aurTgBGF5XOsxHfg4LMNVQ2kBfVnXznPmkJ7puUxgtcScSs7PZV7blvF\nwJCP9b8ZOwn+9JvH8RlcB6VYiAhff/dyfxL8R3+tpiwnnUvGGLcQSVKS+JulIiXiKwqzSE6SEQEj\n0rTmY6koyuLG1XN5YMtR3qzviPp1K8iyR3tr19oZTwNGFJaX24lvO49hjGHjrgbeevrI/uy5Gamc\nXuqdcQP4frvNSnaHml5lLAuLrST4ztp2vvjYzojNHxuqGphfmMnissg5kvFKT03mp7eeS1pKEjtr\n23nvebEluwPNyk0nJUlYvSD0dOIAnpQk5hdkjggYTZ399A/5YgoYAJ+4dBEeu+zR5C/g5OA97Vqr\nNGBEYclsK/HtNEvtqGmnvr0v5PQK584v4NWjrSOSptOZz2d4aGv46VXcuHxJKZ++/HR+/2otvwqT\nBG/vHWTzgWbWLS2Lqi0/VrPzMrj71nO5YGEht7jMy0RyzfJZ3Hr+/DEHzC0s8Y4Y7X0kwrTmbpTk\npPP5dWdw/TnlUV+jyF/D0IAx00V+16oRMj0jE98bdln92UNNQHfu/Hwe3HKU/Y1dnJHgb8JTweYD\n1loin7ni9HFd5+OXVrKrrp2v/WU3Z5Rlj5pJ9bk9jQwOm7ArxCXCeRUFPPBPb4nLtf7xggpXx1WW\neO3n6iM1OYmjLVbAmF84Osnv1vsvjC2fU+DUMLRJasbTGkaUls/JZUdt+5j92VfZS4HOlO61D245\nSn5matTNHcGSkoTvvvdsFhRl8bEHXvOPbnZsqGqgNCeNFXPywlxheqgs9jLkMxxpsXpKOdOal+eF\nntY8kfzyli9+AAAgAElEQVRrYmiT1IynASNKy8tzaersZ1N1c8T+7PMLMynyemZE4ru2rTfsyO5Y\nZKencs+t5zI4PHIkeO/AMP+3r5GrlpaFnap8ugjuKXXsRA+zczPwpEz8n2x6ajJZnmRtklIaMKLl\nJL6/s3FvxP7sIsLKefnTPmD0DQ7zkfu2k5aSxG3nV8TtuqcVe/nhjSvYVdfBv/7eSoI/b0/wONaU\n3NPBwqCAcfRED3MLJr524Sj0pnFCR3vPeBowouQkvt+oaR+zP/uqinyOtPTQ1Dk9/9CMMXz5D1W8\nUdPO925Y4WpSvGhcuriUz1x+Oo+9VsvPNx1i464G8jJTI/Ywmi68aSnMzk0fETBi7SEVD4VejzZJ\nKQ0Y0cr0pPibC8bqz37u/Ok9HuM3Lx/ht9tr+MSllePOXYTz0UsquWppKd94cg9PVtVzxZml4+7a\neqpweko505qPJ+E9XoVZHl1ESWnAiMUyu1lqrA/JZeW5eJKT2D4Bie8dNW3c8rOX/UnS8bjruWre\n98st7D8efr2KVw628B9/epPLFpfwqcvH1zMqEisJvoLTirKs5qgJ7B012SpLvBxo7ObICev/NNYu\ntfFQmKVNUkoDRkw+uHYBX7l2yZh/wGkpySyfk5vwGkZTZz+337udF6tb+PaGveO61uNv1PFfG/ey\naX8z1/z33/jOxr2jRl7XtfXykftfZV5BJt+/cUXCE9DetBR+8b7z+Py6M3jr6bGPtD7VVJZ46R0c\n5pWD1heOyWySKvB6OKHzSc14GjBisHR2Lh9wOUfRqvn5VNV2xLzmw1gGhnx89P5Xaesd4B1nz+Yv\nO+vZURPbHFZv1nXw+d+9wXkV+bx4x6W84+zZ/Oi5aq76wQu8YC8/2zc4zPr7ttM/5OOe284lJ939\nTLDjMbcgk4+8rdL1GtrTQaW9uNJf9zQCkxswCrM8DA4bOvpm3oSa6qSZ89c3Sc6dn8/AsC/ieuDj\n8bW/vMmWwyf41nvO4uvvXkZBlodvbdgT9XVauwe4/TfbyMvwcNctKynNSed7713BAx9aQ7IIt/1i\nC5948DU+/7sd7Khp53vvPTvmEd3KHSdX9tLBFrxpKeRHMU17vBV5dT4ppQEj4VYmMPH9yLZj3PvS\nEf7pogVct6Kc7PRUPnpJJS9Wt/C3/U2urzM07OPjD75GY0c/P/mHlSMWk7qgsognPnkRn7xsERuq\nGnj8jTo+cdkirpwBXVsnW6E3jfzMVAbsOaQmYiqUcAp08J5CA0bCFXnTWFCUxbbD8Q0Yrx9r40uP\nVXFhZSFfWLfYv/0f3jKP8rwMvr1hr+t5rL69cS+bqpv52ruWcY49026g9NRkPn3F6Tz5qYv45vXL\n+dRli+L2PFRkTi1jMpujIGACQu0pNaNpwJgAK+fl8+rR1rglDBs7+1j/m+2U5KTxo5tWjuhmmpaS\nzGeuOJ2dte08UVU/5rX++Hot97xwkNvOnz/mSnILi73cuHretB9lPZX4A0acx7hEq9CZgFB7Ss1o\nGjAmwKqKfE50D3CoefxdXgOT3Pfcuor8EMt1vuuccs4ozeY7G/cyOOwLe61dde184dEdrK4o4MvX\nLhl32VT8LbQT35PZpRZONknpUq0z25gBQ0SSROQcEXm7iFwqIqOnZlURnVdhNfN85Y+7OHaiZ4yj\nI/vV5kNsPdzKt//ubJbMzgl5THKS8LmrzuBwS49/HepAxhh+u+0Y//CzV8jPtJLcM6n30alkcZn1\nf7wwxFK0E8mTkkROeormMGa4sJ8SIrJQRO4BqoFvAjcBHwGeEZGXReT9IqKfMi5UlmTz1euW8trR\nVq74/vP85P8ORPzmH8mfd9SzYm4e7zx7dsTjLjuzhFXz8/nhs/vpDVhas7qxixvveZnP/W4HpxV7\nue9DayjOToupLCrxLqws5DcfXM35CwsnuygUetM0YMxwkT7wvwbcByw0xlxljPkHY8zfGWPOAt4J\n5AK3Rrq4iKwTkb0iUi0id4TYf52I7BCR10Vkm4isdXvuqebW8yt45l8u5uLTi/nWhj284382Rd1z\nqratlx017a5GO4sId1y9mKbOfn7x4iH6Bof53tP7uOaHf2N3fQffuH45v/3w+f4mDzU1iQgXLSqe\n1B5SjsIsj3arneHCLqBkjLkpwr5G4AeRLiwiycBdwBVADbBVRB43xrwZcNizwOPGGCMiZwGPAItd\nnnvKmZWbwU9vXcVTuxr498d38Z6fbObmNfO44+rFrgbAbaxqANwvsbmqooDLzyzh7ucP8LvtNRxq\n7ua6FbP50tuXaK1CRa0gy8ORlshNqu09gyDWMsVq+nHdpCQilSJyn4g8KiLnuzhlNVBtjDlojBkA\nHgKuCzzAGNNlTnYdygKM23NPZVcuLePpz1zMB9cu4KEtR/nKH6pcnbdhVwOLy7JZEEV79ueuWkzP\nwDA+Y7j3A6v54Y3naLBQMXHTJLX+vu185uHXJ6hEaqKFrWGISLoxpi9g01eBz9u//wlYMca1y4HA\njGsNsCbEfd4NfAMoAd4ezbmnMm9aCl++dgnDPsP9rxzhy9cuodAb/oO8qbOfrYdP8IlLoxsDcUZZ\nNs/9y9soyUmLy+JGauYq8npo7RnA5zMhu1YPDft49WgrOVq7mLYi1TD+JCK3BTweBCqA+UDcJkYy\nxjxmjFkMvAsrKEVFRG638x/bmprcj26eKm5ZM4/BYcOjr9ZEPO6Z3ccxZuwp1UOZV5ipwUKNW0GW\nh2Gfob13MOT+/Y1d9A/5aOrsD3uMOrVFChjrgBwR2SAibwU+C1wFvBu4xcW1a4HAkWBz7G0hGWNe\nAE4TkaJozjXG3GOMWWWMWVVcfOrNZLqoNJvzKvJ5cMuxiAP7NlQ1ML8wk8VlOn+TmhxODTjc4L2d\nNSfnS3MWflLTS9iAYYwZNsb8CLgBq1fUD4FfGmP+xRjjZna7rcAiEVkgIh7gRuDxwAPsvIjYv68E\n0oAWN+dOJzetnseh5m5eOtgScn977yCbDzSzbmnZlOgto2amQnvwXriFlHbWtuO0VB3QgDEtRRqH\nsUZEfgf8BPgV8CXgP0XkuyKSN9aFjTFDwMeAjcBu4BFjzC4RWS8i6+3D3gNUicjrWL2ibjCWkOfG\n/CynuGuWzyI3I5UHXjkacv9f9xxncNhw1QxaPEhNPc58UifCJL531rZz7vx8PClJVDdpwJiOwia9\ngZ8C1wBerJrFhcCNInIx8DBW81RExpgngCeCtt0d8Pu3gG+5PXe6Sk9N5vqV5dz38hGau/r9U0k7\nNlQ1UJqTxoo5Y8ZppRLGP59UiLEYg8M+3qzv4La3zKezb0ibpKapSDmMIU4muf1fKYwxzxtjxgwW\nKjr+5Pf2kcnvnoEhnt/XxFVLy3TSPzWpnPU4QnWt3X+8i4EhH8vn5FprkWvAmJYiBYybsZqMLgVu\ni3CcioPKkmxWVxTw4JajI6Ylf2Ffk7WWta4/oSZZSnIS+ZmpIac4r7IXCFtenktlsZdjrT0JW2VS\nTZ5IAWO/neD+V2PM6BnsANEMbFzdtGYuh1t6RiS/N1Q1kJeZyuoFBZNYMqUsBVmekDmMHbVteNNS\nqCjMorLEizFwQPMY006kgPGciHxcROYFbhQRjz1r7a+Bf0xs8WaWq5fZye8tVvJ7YMjHs7sbueLM\n0hFrXig1WQq9aTSHyGHsrO1gWXkOSUniX8NDm6Wmn7HGYQwDD4pInYi8KSIHgf1YM9f+wBjzqwko\n44yRnprMe1bO4aldDTR39bP5QDOd/UMxDdZTKhGKvJ5ROYzBYR+76ztYXp4LwIKiLJJEu9ZOR5Em\nH+wDfgz8WERSgSKg1xjTNlGFm4luXjOXX7x4iN9tr+FISzdZnmQurCya7GIpBYRuktp3vJOBIR/L\n7ICRnprMvIJM7Vo7DUXqVutnjBkExl7vU41bZUk2qxdYye+uviEuPbNUp/VQU0ZhVhqtPQMM+wzJ\ndq+9wIS3o1J7Sk1L2jA+Bd28eh5HWnpo6R7Q3lFqSin0ejAGWntO1jJ21raTbSe8HQtLvBxq7mYo\nxoXC1NSkAWMKWresjLzMVDwpSbztjFNvfiw1fZ0cvBcYMDpYaie8HZXFXgaHDUfHuSSxmlrcrOn9\ncRHJn4jCKEt6ajJfvPpMPnPF6WSluWo1VGpCONODOKO9gxPeDu0pNT25+TQqxVrx7lXgF8BGE2la\nVRUX7z1v7tgHKTXBnAkInZ5STsJ7edC0NQudgNHUxZUTW0SVQGPWMIwxXwIWAT8H3gfsF5Gvi8jC\nBJdNKTXF+Kc4t2sYoRLeADnpqZTmpGkNY5pxlcOwaxQN9s8QkA/8TkS+ncCyKaWmmLyMVJLk5Iy1\nO2qshPf8gsxRx1aWeHUsxjTjJofxSRHZDnwbeBFYboz5Z+BcrLmmlFIzRFKSUJDlodkOGFW17aMS\n3o7KYi8HmrojLgymTi1uahgFwPXGmKuMMb+1x2RgjPEB1ya0dEqpKacwK42Wrn4GhnzsbujkrDDT\n7leWeOnqH6Kho2+CS6gSxU3AeBI44TwQkRwRWQNgjNmdqIIppaYmZ7R38AjvYAu1p9S04yZg/AQI\n/B/vsrcppWagQq+Hlq6BsAlvh3atnX7cBAwJ7EZrN0Xp4AClZqjCLGsCwp217WSnh054AxR708hJ\nT9GAMY24CRgHReQTIpJq/3wSOJjogimlpqZCbxrtvYO8erSNZbNzw64EKSI6p9Q04yZgrAcuAGqB\nGmANcHsiC6WUmrqc0d676ztYPid0c5SjssSrCylNI2M2LRljGoEbJ6AsSqlTgDPaGwib8HZUlnh5\nZFsNbT0D5GV6Ih6rpr4xA4aIpAMfBJYC6c52Y8wHElgupdQU5Yz2BjjLRcAAK/G9qkKXGT7VuWmS\n+g1QBlwFPA/MAToTWSil1NRVYNcwstNTmF8YOuHtqCzOBrSn1HThJmBUGmO+DHQbY34NvB0rj6GU\nmoGK7CnOl83ORSR0wttRnp9BWkqSBoxpwk3AGLT/bRORZUAuUJK4IimlprKcjBRy0lM4r2LsVQ+S\nk4TTir26XOs04WY8xT32ehhfAh4HvMCXE1oqpdSUJSI88cmLKArIZURSWeLltaOtCS6VmggRA4aI\nJAEdxphW4AXgtAkplVJqSpuTHzl3Eaiy2Mufd9TROzBMhkfXpz+VRWySskd1f36CyqKUmoYqS7wY\ng47HmAbc5DCeEZHPishcESlwfhJeMqXUtOB0rdWAcepzk8O4wf73owHbDNo8pZRyoaIokyTRrrXT\ngZuR3gtivbiIrAN+CCQDPzPGfDNo/y3AFwDBGtvxz8aYN+x9h+1tw8CQMWZVrOVQSk2etJRk5hdm\nacCYBtyM9L4t1HZjzL1jnJcM3AVcgTUH1VYRedwY82bAYYeAi40xrSJyNXAPI8d4XGKMaR6rjEqp\nqW1hcfwmIdy0v5n5hZnMDTNLrluDwz7+vKOO684uDzuBohrJTQ7jvICfi4A7gXe6OG81UG2MOWiM\nGQAeAq4LPMAYs9nugQXwMtYocqXUNLOwOIsjLT3jXq51cNjHh+7dyvee3jfuMj23p5FPP/wG27XL\nr2tumqQ+HvhYRPKwPvzHUg4cC3jszHQbzgexVvfz3xor4T4M/NQYc4+LeyqlpqCSnHQGhn209QyS\nnxX7JIT7j3fRN+hjR03buMtU09oLQF1b77ivNVPEshBSNxBzXiMUEbkEK2CsDdi81hhTKyIlwNMi\nsscY80KIc2/Hnm593rx58SyWUipOSnOsQX6Nnf3jChg7a61AcbC5m67+Ibxpsa/l5gSKhnZdc9yt\nMZukRORPIvK4/fNnYC/wmItr1wJzAx7PsbcFX/8s4GfAdcaYFme7MabW/rfRvt/qUDcxxtxjjFll\njFlVXFzsolhKqYlWmmNNdH28Y3wfzjvtZWGNgV3277GqtwNFQxRlemJn/Ywete4mPH8n4Pch4Igx\npsbFeVuBRSKyACtQ3AjcHHiAiMwDfg/caozZF7A9C0gyxnTav18J/IeLeyqlpqCSbKuGMf6A0eFf\nxW9nbTtrTiuM+Vp17dHXML7yx12sXpDPj285N+b7nsrcBIyjQL0xpg9ARDJEpMIYczjSScaYIRH5\nGLARq1vtL4wxu0Rkvb3/buArQCHwY3vWS6f7bCnwmL0tBXjAGLMhlieolJp8JdlWDaOxsz/mawwO\n+9hd38Ftb5lPV9+Qv7YRK3+TlMsg1j80THNXP63dg2MfPE25CRi/xVqi1TFsbztvrBONMU8ATwRt\nuzvg9w8BHwpx3kHgbBdlU0qdAjI8yeSkp9A4jhrGvuOdDAz5WD4nlyMnesYVMAaHff7gddxlDcOp\nibT2DMR831Odm261KXa3WADs33WtRaVUVEpy0sdVw6iyA8Ty8lyWl+dyyE58x+J4Rx/GQJHXw/HO\nfoZ9Y3f3rbVrJBowImsSEf+4CxG5DtDBdEqpqJTmpI0rh7Gzth1vWgoVhVksL88dV+K7rs0qx4q5\n+Qz7DC1dYweyevuc1u7BcY8nOVW5CRjrgS+KyFEROYo1lceHE1sspdR0U5KdzvGO2GsYO2vaWVae\nQ1KSsMxeSzzWZql6O+G9cn4e4C6P4ZwzMOyjZ2A4pvue6sYMGMaYA8aYtwBLgCXGmAuMMdWJL5pS\najopyUmjqbM/pm/ng8M+djd0stwOFMXZaczKTY85YDg1jHPmWqsG1rvIY9S2nTzmRPfMbJZyMw7j\n6yKSZ4zpMsZ0iUi+iHxtIgqnlJo+SrNPjvaOlpPwdmoWAMvKc8dVw8hJT2FhSRbgrruvU8MAYnoO\n04GbJqmrjTH+cfj23E/XJK5ISqnpqMQe7X28M/o8RmDC2+Ekvjv7ov/wrmvrZXZeBkVZaaQkiasa\nRn1bHwX2KPUTMzTx7SZgJIuIf/FeEckA3C3mq5RSNme0d2MMeYwdNe1k2wlvx/I5duK7riPq69W1\n9TE7L4OkJKE0J91V19q69l6Wzs4BoE0DRlj3A8+KyAdF5IPA00DEqc2VUipYaXbs04NU1baz1E54\nO5zaRlUMzVL17b3MyrXKU5qTNmbSu7NvkM6+IZbOtu45U3MYbmar/ZaIvAFcbm/6qjFmY2KLpZSa\nbkoCJiCMxsCQlfD+x/Pnj9he5I0t8d07MExrzyCz8zIAKMtNZ099Z8RznCarM2dlIwKtMzRguKlh\nYIzZYIz5rDHms0C3iNyV4HIppaaZ9NTYRnufHOGdN2rf8vJcdtZEFzCcOaRm51k1jLKcDBo6+iL2\n3nKmEZmTn0FuRiqtmvQOT0TOEZFv28umfhXYk9BSKaWmpZKc6MdihEp4O5aX53IwysS3MwBvVq5T\nw0ijZ2CYzgijxusCzinI9MzYpHfYJikROR24yf5pBh4GxBhzyQSVTSk1zZTmpEXdS2pnrZXwnh9i\nSdZlc6wgsquug7e4nLnWqS3MtgOGk4xvaO8jJz015Dn17b0kiTXrbl5mqia9Q9gDXApca4xZa4z5\nH6yJB5VSKial2elR95IKlfB2xJL4rmvvRQRKc62cilPTiDTNeV1bH2U56aQkJ1GQ5eHEDJ2xNlLA\nuB6oB54Tkf8VkcsAXSldKRWz4ihHew8M+dhd38lZIfIXYCW+Z+emsyOKPEZ9Wx9F3jTSUpIBKHNq\nGBFyK3Vtvcyyk+R5mR6tYQQzxvzBGHMjsBh4DvgUUCIiPxGRKyeqgEqp6SPa0d77jncyMDxyhHew\nZeW5UdcwZttdauFk761INYzAbrhWDUMDRkjGmG5jzAPGmHdgLbP6GtYEhEopFRX/Uq0u8xiREt6O\naBPfdW29/mYosHpvFWR5wtYwjDHUtff5u+HmZabSP+SjdwZOQOiql5TDGNNqr6F9WaIKpJSavvzT\ng7jMY+ysbSc7PXTC27F8jpPHGHvEtzGG+oAPf0ek0d4t3QMMDPn8tZKCzJk7PUhUAUMppcbDGe3t\ndizGztp2ls3ODZnwdkST+O7oHaJnYNg/BsNRlpMWdj4pfzdcO8jk2/NJzcTBexowlFITJprR3gND\nPvbUd/prEOEU2olvNyO+nVXzApukAMpyM8JOWeIf6Gefk2/XMGbiynsaMJRSE8YZ7e1mPikn4R0p\nf+Fwm/iuDxrl7SjLSaele4D+odF5ifq2kecUZFljNWbiaG8NGEqpCVWa424sxk4XCW/HWXOsxHfH\nGInvOrvZKTiHUWaPyQhVrrr2PtJSkvxTm+dlapOUUkpNiBKXo739Ce/C8Alvh9PtdtcYie+6tl5S\nkoQi78gVGsqcwXshaj5Wr6p0RKw8Sl6GU8PQgKGUUgnldrR3lZ3wdj6oI3Gb+K5v66U0J53koCS6\nM3gvVOI7uFdVSnISOekpWsNQSqlEK8lJp7Ez8uywTsL7rDES3g4n8b1jjIBR195HeVBzFFhTnAMh\nu9YGj9sAa/Ce5jCUUirBSrLTGBw2ET9w3YzwDnb23DxePdI65jTls4IS3gA56SlkpCaPapIaGvZx\nvKNvVJI8L9OjTVJKKZVo/tHeEXpKRZPwdlxQWURtWy+HW3pC7vf5DMc7+kbVFgBEhLLc9FHTgzR2\n9uMzo7vhWjUMDRhKKZVQpS7GYkST8HasrSwCYFN1c8j9zV39DA4bykPUMMDKYwTXMOraQnfDzctM\npXUGzlirAUMpNaFKXKztXVXbzvJydwlvR0VhJuV5Gby4P3TAcLrUhqphACFrGOG64RZkupuAsKa1\nh3teOIDP52523qlOA4ZSakI5o72bwtQw/CO8o2iOAqtZaW1lEZsPNDMc4gPaqS2EymGAPZ9UR9+I\nD/d6/8jwkefkZ3noHRymbzDyBIS/f7WWrz+xhz/vrI/quUxVGjCUUhNqrNHesSS8HWsXFdHRNxRy\nmpDglfaCzcpNZ8hnaAmoOdS19ZKdnkJ20Ep8bqcHqWm18inffWovA0M+909kitKAoZSacM63+VCc\nD3u3XWoDXbDQWqZ10/6mUfvq2/vISE0mLzP0MqyhkvF17X0hA4x/epAx8hg1rb1keZI50tLDw1uP\nunsSU1hCA4aIrBORvSJSLSJ3hNh/i4jsEJGdIrJZRM52e65S6tRVmpMeNum9o6adnPQU5kWY0jyc\nQm8aS2blhEx8O11qw+VFnLEYgYP36ttDd8PNc1nDqG3r5ZLFJaxeUMAPn62mu3/I9XOZihIWMEQk\nGbgLuBpYAtwkIkuCDjsEXGyMWQ58FbgninOVUqeokuy0sKO9q2rbWRZlwjvQRYuKePVIGz0DIz+c\nw9UWHE6eIrCnVH3b6LUzAP+8UpEChs9nqGvrZU5+Jl9Yt5jmrn5++eKhqJ7LVJPIGsZqoNoYc9AY\nMwA8BFwXeIAxZrMxptV++DLWin6uzlVKnbrCjfYeGPKxtyH6hHegCyuLGBj2seXQiRHb69t6R3WP\nDVTkTSM5SfyjvfsGh2npHhixnKvDadaKND1IY6fVjXdOfgbnzs/niiWl/PT5g6f0lCKJDBjlwLGA\nxzX2tnA+CDwZ7bkicruIbBORbU1No9stlVJTT2lO6NHe/inNY8hfOM6rKMCTnMSLAc1SA0M+mrr6\nw3apBUhOEoq9JxdSqo/QDfdk0jt8DsNJeJfnW+d/7qoz6B4Y4q7nqqN8RlPHlEh6i8glWAEj6rXC\n7SVjVxljVhUXF8e/cEqpuAs3FmNHTfQjvINleJJZVZHPpuoW/7bjHX0YM3oAXrCy3JPJ+PoI3XBT\nk5PITkuJOBbDWaxprh0wTi/N5vqVc7j35SP+fcG2H2nltl9s4W8hkvZTQSIDRi0wN+DxHHvbCCJy\nFvAz4DpjTEs05yqlTk2l/rW9RwaMnbWxJ7wDXVhZxO76Dv9Yj7owK+0FK8tJ9y+y5Hyoh5qsEKyx\nGG0Rchg1rc75J5/Lp684HYAfPL1vxLHtvYN86Q87+bu7N/PCviZ+vmlq5joSGTC2AotEZIGIeIAb\ngccDDxCRecDvgVuNMfuiOVcpdepyurAG95Sqqm1n+ZzYE94OZ5qQzQesZqn6MCO2g1k1jP4R55SF\nyGEA5GemcmKMJqnCLA8ZnmT/tvK8DG57y3wefbWG/cc7McbwpzfquPx7z/PAK0f5wIULuHnNPF6s\nbh5zMajJkLCAYYwZAj4GbAR2A48YY3aJyHoRWW8f9hWgEPixiLwuItsinZuosiqlJlZxtrPC3cka\nRv/QMHsaOmIasBdsWXkuuRmpbLKnCakNMydUsLLcdLr6h+jsG6S+vZcir4e0lOSQx7qpYczJHx2g\nPnJJJVmeFO780y7e98utfPzB1yjLSefxj63ly9cu4T0ryxkcNjy3p9Ht050wKYm8uDHmCeCJoG13\nB/z+IeBDbs9VSk0P6anJ5Gak+r/NA+xr6GJw2Iwrf+FIThIuWFjIi9XNGGOob+8lNyOVTE/kj7yy\ngMF7tWG61DryMz1UN3aF3V/b2sviWdmjthdkebj9rafx3af3keVJ5s53LOHW8yv8izqdMzef4uw0\nNlQ1cN2KSP2EJl5CA4ZSSoVTkp1GY8BSrbFMaR7JhZVFPFnVwKHm7rDjKYI5zU8N7f3Ut/VyWnFW\n2GPzMz20hWmSMsZQ29bL5UtKQ+7/p7eehjc9hXXLykblVZKShKuWlvLo9lp6B4ZHNGlNtinRS0op\nNfNY04OcrGHEK+HtuGjRyenOa9t6Q46nCHZyqdbekCvtBcrPTKWrfyjkHFFNXf30D/nCJszTU5N5\n/4ULwl7/6mWz6B0c5oUp1ltKA4ZSalKU5KSNmLF2Z21bXBLejnkFmczJz2DT/mbq2/vCzlIbyKlh\nVDd20T0wHPYDH6wcBhAyj1Fr95AKlcNwY/WCAvIyU9lY1RDT+YmiAUMpNSlKsq3R3j6foX9omL0N\nnXFJeDuc6c43VTfT3js4ZpdasL7552Wm8trRNiD8VOhwcnqQEyEChr9LbYwBIzU5icvPLOWZ3cen\n1Cy3GjCUUpPi5GjvgbgmvAOtXVREz4C1ZkWk2kKgspx0dtTaASNCkHGmBwk1eO/kGIzYAgbAuqVl\ndAHbqPAAABj5SURBVPQN8fLBlrEPniAaMJRSkyJwLIZ/SvPyvLje44KFRf7fgxdBilSuvkHrW32k\nbrgF/iap0Ynv2rYe8jJTR62jEY21i4rI9CTz5BRqltKAoZSaFCXZJ0d776xtIzcjlbkFsX8jD6Ug\ny8PS2TnA2IP2HE5gSU4S/xQmoTjzSYWrYYyndgFW89gli0t4+s2GkCsITgYNGEqpSeGvYXRYNYxl\n5TlxS3gHunRxCZmeZP/93JarLCfdPzYiFKdJKlzSO9aEd6B1S8to7hpg+5HWsQ+eABowlFKTwhnt\nXdPaY09pHt/mKMdHL6nkiU9chCfF3ced01NqrCastJRksjzJnAhadc8YY9cwxt89+JLFJXiSk9gw\nRZqlNGAopSaFM9r7hf3NCUl4B96noij8ALxgTsBw04QVanqQ1p5BegeH41LD8KalcNGiIjbuahi1\ndshk0IChlJo0pTlpvH7M6pGUqIARLWfwnptxG/mZnlHdaoPXwRivq5aVUdvWS1VtR1yuNx4aMJRS\nk8ZJKici4R2rOfkZeNNSWDIrZ8xj87M8oxZRqhnnoL1gl59ZSnKSsGFXfVyuNx4aMJRSk6bEXhdj\n+TjW8I637PRUXv7iZbzz7NljHpufmTpqydWTo7zjM8VJQZaHNQsKpkQeQwOGUmrSOD2S4jnCOx68\naSmuAlh+pofWEE1S2Wkp5GbEPgYj2LplZRxo6qa6sTNu14yFBgyl1KRxxmJMlfxFtPIzPXT2DTE4\nfHL6jtq23rjlLxxXLikDmPRahgYMpdSkOXtuHkXeNM6ryJ/sosSkIMsZi3EyjxFu4aTxKMtN59z5\n+Tz2Wu2k9pbSgKGUmjQr5+Wz7UuXU+JyUN1U48xY6zRLGWPsQXvxyV8EuuG8uRxo6mbr4ckbxKcB\nQymlYuRMD+Ikvjt6h+jsHxr3tCChXHvWLLLTUnjglSNxv7ZbGjCUUipG/oBh1zCO2WMw4t0kBZDp\nSeHdK8t5oqphVM+siaIBQymlYpRv5zCcsRi1beNbB2MsN62ex8CQj0dfrUnI9ceiAUMppWIUPGNt\nTZzHYAQ7c1YO58zL44EtRycl+a0BQymlYpSemkxGarJ/Pqna1l4yPcnkZ8ZvDEawm1fP42BTN1sO\nnUjYPcLRgKGUUuNQkOXxz1hb09pDeV5GQketX3vWbLLTU3hgy9GE3SMcDRhKKTUOeZmp/qR3bVv8\nx2AEy/Akc/055Ty5c+KT3xowlFJqHAqyTk4PUtMa/1Heody0Zh4DwxOf/NaAoZRS45CX6aG1e4DO\nvkHaewcTlvAOtLgsh5WTkPzWgKGUUuNQkJlKa8/gyS61CRi0F8pNdvL7lQlMfmvAUEqpccjL9NDe\nO8iRlsQN2gvFn/x+ZeKS3xowlFJqHArs+aR21Vkr4k1EDgNOJr83VDX4x4EkmgYMpZQaB2cCwqra\ndtJSkij2pk3Yvf3J7+0Tk/xOaMAQkXUisldEqkXkjhD7F4vISyLSLyKfDdp3WER2isjrIrItkeVU\nSqlYOYP0dta2U56f2DEYwZzk94MTlPxOSdSFRSQZuAu4AqgBtorI48aYNwMOOwF8AnhXmMtcYoxp\nTlQZlVJqvJzpQZo6+1lclj3h919/8UIONnczOGzwpCQ2WCUsYACrgWpjzEEAEXkIuA7wBwxjTCPQ\nKCJvT2A5lFIqYZwmKUjcHFKRXLm0bMLulcgmqXLgWMDjGnubWwZ4RkS2i8jtcS2ZUkrFSUFmYMCY\nmIT3ZElkDWO81hpjakWkBHhaRPYYY14IPsgOJrcDzJs3b6LLqJSa4TI8yaSlJNE/5Jv2ASORNYxa\nYG7A4zn2NleMMbX2v43AY1hNXKGOu8cYs8oYs6q4uHgcxVVKqdg4XWsnatDeZElkwNgKLBKRBSLi\nAW4EHndzoohkiUi28ztwJVCVsJIqpdQ45NnNUpORw5hICWuSMsYMicjHgI1AMvALY8wuEVlv779b\nRMqAbUAO4BORTwFLgCLgMbt7WgrwgDFmQ6LKqpRS41GQlUpqslCSPXFjMCZDQnMYxpgngCeCtt0d\n8HsDVlNVsA7g7ESWTSml4qU8L4OFxV6SkiZuDMZkmMpJb6WUOiX82zVL6B0cnuxiJJwGDKWUGqfc\nzFRySdyyrFOFziWllFLKFQ0YSimlXNGAoZRSyhUNGEoppVzRgKGUUsoVDRhKKaVc0YChlFLKFZmI\nVZomiog0AUfifNkiINQiTtFuj+e1puK9J+IeM/XeE3EPvff0vEekezvmG2PczdxqjNGfCD/Atnhs\nj+e1puK9p/vz09dW730q3iPSvWP50SYppZRSrmjAUEop5YoGjLHdE6ft8bzWVLz3RNxjpt57Iu6h\n956e94h076hNq6S3UkqpxNEahlJKKVc0YCillHJFA4ZSSilXNGAopZRyRVfcC0FESoFy+2GtMeb4\nRGyfqHuEec7vN8b8cqK32/v+FdgCvGKM6QrY/iHgUBTbPwG8ZIzZKiJLgHXAHmOtLR98z3uNMbe5\n2S4ia4HVwCDwa2NMh4hkAHcAK4E9QDVwwBjzjIjcDFwA7MbqpTIXuP7/t3fmUXYXVR7/fMkGIQEC\nZJAdMQSGIFs4KiASRAyDgIByRByWMCznyCLjYQzD4DKCGJBFQFBR0DMocUCQhCUoSIYBWQIhkDQk\nhMAAYQ07hITJ9p0/br30r3/9e53XnX5kOl3fc97p17fq1a269au6Vbdu3V/6uxSYDVxn+7068vgh\ncEupHQauruD9JHAesEEVD2A7wKWy5gDrAS9X1df24hXJqZA+BrhnRe2TNAzYKfFYRjyby/sv9d1b\ntn9Xj1czIWm7cp0S/UBgfbpJVvXGBtUyHAz8wfbcit9sXZG/7jPVXcheUgVI2hn4BbAu8FIibwYs\nSt/7NYn+DvBT4PQm8n4H+KbtR+u0/QXbW6wC+mnARcBtwM7At2xPSPQLgDsapH8f+A4xkO8EPg1M\nBvYDhgJPF9kC+wC1iWFKib4YuNf2wZJOAE4G/gSMBc61fZ6kq4AFwB+BK4lJZRoh50HATcC+wN8D\n7wL/DRxQyHMo0R//VZLH94GzgBmldpwJjLN9Ton3vsTE8VoFjxOIsBALSmWdkvI/X6rvj5IMppXk\ncTeA7YMpQdJbwCMVvE8Hjkx9cxTw3UKePsADtO2/d4G1gIeA8cANtl8v80s8V6TAnySej/kNLh6m\nEONuZrFOhfbdCQzsBlnVGwP1ZHgm8Haq13KZpDFwYEX+Q4FxwMYUFovARNszq2TZWWSFUYCkx4CT\nbD9Uos8mZLVNk+ifIQbyqCbyrvEoTpw1bAMMAFqaRBcwooIOMDzVd4CkrYhJ8FrgeGCZ7Z06QV8C\n7Am8CmxWmEjeAm4Efk2s1EUMwPeB54gVepE+Hzje9j2SHgYOSAN1FrDY9iclPWp7VwBJ04lV827E\nAN3E9lJJIibrQen/gcDttkdJmglsRfv+GJ7qMaTUjlnAIts7Fnkn/gvr8JgFLKyQyYzU3l1L9X0U\n+Dgx8RTlsSCx+qBOv/ar4P0UsMD2LkmG+9t+U1ILgO0dSv13bCpzLPA14GBgauJ/qu3dUlsbUeA/\nJCb+Z2ls8XAAoWCWAqfV6mT7UkkLba8lqe9KympFY6NKhi2EUizLZASwg+13S/l/DHwrtf/FVP5m\nwBHETmUcK4vuiC+yunyAp+vRgTnNoqe0Rc3kndKWEANpy9LndWBeE+lbEYOxivdsYrtfq+MgYvC+\nATzWCfq8Gh2YVmr3Y8A/E5PHzon2LHGGV0V/nJiwNwAeLZRzA/B8+v4bYLf0fTaxQhxCKKH1E31N\n4ENgQPp/CCm2D7HCn1Mhjydq8ii2I/F+oYL3cGKSquIxDWipKKul0MZifddK9SrL47U6fbcVMaHV\n4z0rfZ8MrJm+PwE8UdF/r5X6tR8xQY4nlHSN/jAwNH2fBcxI34v9NCP1+UDgPWCdQvsWAr8DRgF7\np7+L0/e9S3W6OOXv3w2y6mhs1JPho7X+K8nkHeD1ivyzi/kLv+tPnbmts598htEWkyTdBvwHULMb\nbk6c9UjS15pEPxqY2WTeRxMP1CDbjxUbLWkisIXt55tBT2nP1eH9IjGpAmB7frIbzwU+2Qn6KwX6\nyEL56xI7kksk3QBcIuk1oK/tZen/NnTCPDGVWP1Z0sa2XyFWby2SniEU1wOS5hK7i48Rk9S/ATdI\nehb4DGGieFjSQ8BewPmpancBIypkOJ/WVejIQtK3gccqeM8FLq/DYxkxuZTL+j3wgzr1vRK4uiSP\nW6nou1Tf6XV4/wC4Lp3HPAHcLenPhLnkt7XfF/pvHm37dTEwEZgoaYSkIYSC7+NWU9UMwjQF8Lik\n3Ww/Qpi8PrS9QNIzTnZ92wvTzmdqave/2H5M0hLg3Vr7CnW6htgVzEpldllWKxgb9WTYj9gdt5FJ\nMlseL+lXpfyi/c6GJPNlFfROI5ukSpD0D8CXKdkAiW1n0+i2b282b1fYb1c1JG0GLLH9agV9F9u3\nNEgfQKy6/1aibwhsbHtGgfYlYE/bZ5XyVtIL6QOBjYA3CXNEX+BF269J2gTA9suS1gO+QOwIpkga\nQZxltNietQJ5DLD9vxX0DYmB/3yZd0pvx2MFZe1I7ADa1bdReRTyVbYvKesjiV1QX8JM8iDwVEV/\nDyd2Dm36L6U9R0x4Ip7tPW2/kmTeQtj53yBMbHOJkN772X5I0hppYVCrz2Tbu6bn6BJiR3AoMLJc\np/SbPQkHi8q+7ays6qFO/w23PbsT+fcHfkZYGWqLxS2AYcAptu/oSt3a8M0Ko/dBq7EXWE/jXQVJ\ng1zw1OkqfUVpjUDS+rbfqqAfbHtind90lLae7XfqpPW1vaRWb8LD69kq/ilPpQIH3ulI6TayeKgH\nFby9bD/ZQb6hxPnBUsJU1bdeuzviAczupEzWIHZdxcXiw7aXNsJ7hXXLCqMxSDrRdrtAXs2mdzOP\nc4iDv1XhBXYpYdJZHT3QusK7rteaus8DbUfC5j8PmASMtf12ot9PrMyL9D0JU9mzwHHAucDWqe4X\nEiZNiJX+FcA3iQPloqNGMQ3bN5XqtIRYAV8I3FibRCUdS3jLvUk8J1cQK/vhwHdsj++M0q2QxXLF\nV6GYvgScQZgVl8sjpb8HbG37DbX19voc0d99SzLcnvAAe51Y3U8D/o44r7iHOD+5sag8JE0GDq/g\nMZrwvnupJJMRxHnKmhX1nWK7ZqbrduQzjMahVUTvzrKOBb7q1dMLrKfxvhS4RdJFtMXewIaSvt0g\nXXXoEO6zi4izgeOB+yQdTNjeXyW8uor0SwivseMJN+dDbN8naTHhsnwzrc/W2sBBwDHA7YRSKqeZ\ncEEtYiYxcX4euEDSfcTB9hnAtsTdg8cJs+MzSUncK6ndYkNSTVEPoe2kfTZwsO1PpQn8ZqCfJBFn\nhCdLKiqm9YmD5zNTWfelXdIzhPdS7Y11pwG7O7y97icUTFm21xDKbHtJnwJOtv1pxVldv4p2TyBM\ncVU8WohD+wNLMnmI8PZqw7tWXyog6VbbB1aldQZZYZSguMBTdS5wj6SxzaLb/uVHwPvD8sRVazbV\nSqZb6LYflNQn826DkwjvpsEl+gGEGaNROoTHzhDCC66IgcDStJq9UNJUwvsH4L0K+jLgA9sPSHrd\n9n0p7x7AXwnTxs8BJI2yPUbSlYTvf1XadhXPYR/bp6R8axGK5QjC1HKZ7SMlzU+TH47zoc2BoyqU\n7uNJHuVJ+zBa++MnxL2KSWkCn0ys9pcrJkKpfRG40+G2PBW4I632LWlT2y8R7ta1Q+W1gYV1ZPt+\nqvsUSb9ItHnABrY/W2r3FdGUSh5LCIX1P0WZEDuL+WXetfpSjRPq0DuFrDAKSA/314E/0HqZazNi\nsABc1iT6eEmvEIeazeI9Hpin1dcLrKfxXkhMUP9OAZJGEyaQhugp7SzgZttTS/TDCNdgAGxPlvQV\nwkz1QR167bzjXwvpD0t6AeifzCdjSRNTStsPOLWY1sFY2krSmbbH2V4IXA9cL+l2YLCknwGz0s7r\nJuKAeVkdpUtKK0/aS2m9D7Gp7UmprlMkKa3m36hNwrHxaOOpV5PHjcTO4y+SbqStt9fWtHonFX9z\nP7Cpwrx3GOGJBqHA1kh5i+1el9jZVPHYBJhRIZONUr6q+q5fJSSHl99KI59hFKAwLYxw4bp/gd5M\n00V/YqCu3UTe/YmH7DRWUy+wHsZ7KvCngikCAEnbAmu4dDO3Hj2l7UEcjpbLOhJ4uzZhFuinAl+w\n/eUS/Tjgs7aPK9E/AXzF9gUKz6SfEh5pW5fyLU8jVsdVY2kscSmy/HyuQ1zIM+HpMxoYQ3iFDSAW\nU2Wl+yviQtqJhXJ2JM4NlgJ/BnYn3FkXpPT3iFX9YGD7lPd9om+2sD26UNYWxHnCGbT39loC/M32\ng6V27EC4Lc8ldjDjbL+vMJPdVc5f+F2VR9ldxM6nLJP+wKW2byuVMSLxXpM4NzGxs5mQ6tHQoXtH\nyAqjAMXN2NFu7xs/h5DVJ5pEr11gG95E3lsCf7G9bYdCyMjoBnQwlrr0HNZRuu8SSrc8aR9O7O4u\nTKSpjrsVGwH/SEy4VYrp3O5aia8KpF3J3US4lFcT7WPEOdO+tr+40kzcDbf/VpcPrYHZJhFB464i\ntrgvp0+z6HOIS0HN5D2HCM9Qr+0nrgp65t2zeXRA359W76yGnsOutK/Zn57Uf8BTHeR/qjvkkc8w\nCrB9h+ICUTs/ZmJF0jS6I47Mj5vNo4Pmrw5eYJn3R8+jkp7G0vcIG36jz2Gn26fmu6/3pP57Hhgt\naYLb3g06llZT3kohm6R6GVTfE6vZtvyZmXfP5dEV3q4TIbWzda1XTirrJNu/7Ab6doTn2nfdNrz5\n/oSr8aY0GE6fuHXuMt2lSAuqH2K/q+H0nyMOxA8izjAgbrJPJM4w3m4vwc4h7zB6ETrwXFkdvMB6\nK+//r+0bL6ldhNQuPIOV5RSwaGXpaeI/mfAca5G0PLw5cbC+gLg/cnUtTYVw+pLupDUi7pWEN9S8\nEv1aSfNojZQrYB9FqJG9bA9JdTmBttF4BxPRlC9N9Tg/8fg6ME3SMbQNp4/t7SraOIYIWrlyWFW2\nwfz56D/EwXq/OvR20Sy7kd6fGKiZd8/k0RXelRFSu/AMdhhplRTBd2XoRBDDQcALRPTYR4i7GxDu\nz4PS9+Vp6TfTaB8RtwWYXkGfRtysH0VrlNxX0venC3VpJBrvdMLU15fYQfRJdAHTOyOPzn7yDqN3\nYRnh212OmLkG1TbR7qJvTJgbMu+eyaMrvOtFSO3sM7gxsLkiomsZ2wADKtLq0UXcEK/K/wCwke3n\nJI0C/pg8unAyQxXTCNPPyy5FxCXMSKqgjyTOEYpRchc63rmyQJ2LxrsmoYwGE4ppXSKq7XRgmzrt\n3qhCfp1GVhi9C6cDf5VUjmY5EEDSpCbRhxEvdcm8eyaPrvAeRoQmKaOzz+AwYpV/NLFCL+IR4g7F\nQQ3SBTxTUdZ1xBv0fg3twpuvKWlntw99XhlOn7j/0aeCPpjYDYyhbTh06L5w+tulNpTNdyIuFK40\n8qF3L4PqRLPko/ECy7x7KI+u8HYdb6gu1PUq4DduDVVSK+dq4rLdfo3QU9ozwDHFspRC7AMX2z6y\nlP8Q4EG3D8deL5z+JkQIkBkleptIuWogSq46H07/KOAnZTmlsq4rt60ryAojIyMjI6MhrLGqK5CR\nkZGR0TOQFUZGRkZGRkPICiOj10LSZEUU2CLtdEk/X8HvuvwGuwbrNVTSQ5KmSdqrlNZP0jhJT0t6\nVNIDijhLGRlNR1YYGb0Z44l3EhRxRKKvSuxL+N/vYvveUto5hKvpDrZ3BQ6h+h0ZGRndjnzondFr\nIWl94nLUZrYXSdqKeDXmlsQLciYQLybqB5ztdPtX8R6FQckn/wynN5kp3lvwiO3fShoJXExcCHsD\nONalSKiJ3zXAhsQrPccQ7zOYSLwU6SXi7WsLU/6BhMvpxwv+/RkZHxnyDiOj18LxjucpQM2kcwRw\nvWMV9SFwaFrF7wNcJKmjIHHLIakfcDnxOtyRhFL4UUXWy4lYQTsS7zG4LPn7fw/4T9s715RFwjDi\nxm5WFhmrBPniXkZvR80sNSH9/adEF3CepM8RF6U2JXziX60qpIRtgR2AO5OO6UNc9Cpjd+KtbADX\nAhd0rQkZGR8NssLI6O2YQNy83RUY6NbXnH4DGAqMtL1Y0nNESIYiltB2l15LF/CE7d27ua5zgC0k\nrZN3GRmrAtkkldGrkeIETSbMRsXD7nWBeUlZ7EOca5TxPLC9pAHptu2+if4UMFTS7rDcs2lExe/v\np/XQ/RtA+YC7XNcFwNXApYpX7tY8qg5voKkZGSuNrDAyMkJR7ERbhfF7YDdJM4jYQ7PKP7I9F7ie\niFB6PRGRFNuLgK8C50t6nIj5s0cF31OBMSlY3FFE7KAV4WzigPxJSS3ArUQguoyMpiN7SWVkZGRk\nNIS8w8jIyMjIaAhZYWRkZGRkNISsMDIyMjIyGkJWGBkZGRkZDSErjIyMjIyMhpAVRkZGRkZGQ8gK\nIyMjIyOjIWSFkZGRkZHREP4PaMJagKv4+90AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111532f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111549438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "li = [np.arange(1,51)]\n",
    "plt.plot(cost_accuracies)\n",
    "plt.title(\"Determining Optimal Value of Regularization Term C\")\n",
    "plt.xlabel('Value of C ')\n",
    "plt.ylabel('Accuracy (%) ')\n",
    "costs_plot = np.around(costs,decimals=2)\n",
    "plt.xticks(li[0],costs_plot, rotation=90)\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing our Best Logistic Regression Optimization Procedure to that of Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations  [220  46 157  37  56]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.19801980198\n",
      "confusion matrix\n",
      " [[ 0  0  0  0  0  0]\n",
      " [12  6  8  9  3  0]\n",
      " [12  4 10 10  4  0]\n",
      " [17 12 16 11 10  0]\n",
      " [ 7  3  6 10 13  0]\n",
      " [ 6  4  2  4  3  0]]\n",
      "[0.29959988594055176]\n"
     ]
    }
   ],
   "source": [
    "# run logistic regression and vary some parameters\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "# first we create a reusable logisitic regression object\n",
    "#   here we can setup the object with different learning parameters and constants\n",
    "\n",
    "\n",
    "lr_sk = SKLogisticRegression(solver='lbfgs',class_weight='balanced',max_iter=500,C=0.002) \n",
    "\n",
    "lr_sk_accuracies = []\n",
    "lr_sk_times = []\n",
    "# now we can use the cv_object that we setup before to iterate through the \n",
    "#    different training and testing sets. Each time we will reuse the logisitic regression \n",
    "#    object, but it gets trained on different data each time we use it.\n",
    "\n",
    "iter_num=0\n",
    "# the indices are the rows used for training and testing in each iteration\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    # I will create new variables here so that it is more obvious what \n",
    "    # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "    # but it makes this code less readable)\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "#     print(X_train)\n",
    "#     print(y_train)\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    st = time.time()\n",
    "    lr_sk.fit(X_train,y_train)\n",
    "    t = (time.time() -st)\n",
    "    lr_sk_times.append(t)\n",
    "    #print(np.hstack((lr_sk.intercept_[:,np.newaxis],lr_sk.coef_)))\n",
    "    yhat = lr_sk.predict(X_test)\n",
    " \n",
    "    print(\"Iterations \",lr_sk.n_iter_)\n",
    "    # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    lr_sk_accuracies.append(acc)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"accuracy\", acc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1\n",
    "\n",
    "print(lr_sk_times)\n",
    "# Also note that every time you run the above code\n",
    "#   it randomly creates a new training and testing set, \n",
    "#   so accuracy will be different each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.663905143737793\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAGHCAYAAAA6MMHNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJElSr/8PnJdxe2YWeisAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c90fd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d4bc780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot([lr_sk_accuracies,lr_clf_accuracies])\n",
    "plt.title(\"Comparing Accuracies\")\n",
    "plt.xlabel('Implementation of Logistic Regression')\n",
    "plt.xticks([1,2],['SKL','OURS'])\n",
    "plt.figure()\n",
    "print((time.time() -st)*100)\n",
    "# ax = fig.add_subplot(111)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c7122e8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhUAAAGHCAYAAAAHoqCrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbXjs4TvNoHQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d3c0cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c7122e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot([lr_sk_times,lr_clf_times])\n",
    "plt.title(\"Comparing Training Times\")\n",
    "plt.xlabel('Implementation of Logistic Regression')\n",
    "plt.ylabel('Training Time (seconds) ')\n",
    "plt.xticks([1,2],['SKL','OURS'])\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing which implementation of Logistic Regression would be best for our case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exceptional Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
