{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "%matplotlib inline \n",
    "%load_ext memory_profiler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.special import expit\n",
    "import time\n",
    "import math\n",
    "\n",
    "df = pd.read_csv('responses.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change NaN number values to the mean\n",
    "df_imputed = df.fillna(df.median())\n",
    "# get categorical features\n",
    "object_features = list(df.select_dtypes(include=['object']).columns)\n",
    "# one hot encode categorical features\n",
    "one_hot_df = pd.concat([pd.get_dummies(df_imputed[col],prefix=col) for col in object_features], axis=1)\n",
    "# drop object features from imputed dataframe\n",
    "df_imputed_dropped = df_imputed.drop(object_features, 1)\n",
    "frames = [df_imputed_dropped, one_hot_df]\n",
    "# concatenate both frames by columns\n",
    "df_fixed = pd.concat(frames, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=3, random_state=None, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# we want to predict the X and y data as follows:\n",
    "if 'Fear of public speaking' in df_fixed:\n",
    "    y = df_fixed['Fear of public speaking'].values # get the labels we want\n",
    "    del df_fixed['Fear of public speaking'] # get rid of the class label\n",
    "    X = (df_fixed.values) # use everything else to predict!\n",
    "\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(\n",
    "                         n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43 µs, sys: 0 ns, total: 43 µs\n",
      "Wall time: 47 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# from last time, our logistic regression algorithm is given by (including everything we previously had):\n",
    "class BinaryLogisticRegression:\n",
    "    def __init__(self, eta, iterations=20, C=0.001):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        self.C = C\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "        \n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'Binary Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained Binary Logistic Regression Object'\n",
    "        \n",
    "    # convenience, private:\n",
    "    @staticmethod\n",
    "    def _add_bias(X):\n",
    "        return np.hstack((np.ones((X.shape[0],1)),X)) # add bias term\n",
    "    \n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        # increase stability, redefine sigmoid operation\n",
    "        return expit(theta) #1/(1+np.exp(-theta))\n",
    "    \n",
    "    # vectorized gradient calculation with regularization using L2 Norm\n",
    "    def _get_gradient(self,X,y):\n",
    "        ydiff = y-self.predict_proba(X,add_bias=False).ravel() # get y difference\n",
    "        gradient = np.mean(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\n",
    "        \n",
    "        gradient = gradient.reshape(self.w_.shape)\n",
    "        gradient[1:] += 2 * self.w_[1:] * self.C\n",
    "        \n",
    "        return gradient\n",
    "    \n",
    "    # public:\n",
    "    def predict_proba(self,X,add_bias=True):\n",
    "        # add bias term if requested\n",
    "        Xb = self._add_bias(X) if add_bias else X\n",
    "        return self._sigmoid(Xb @ self.w_) # return the probability y=1\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return (self.predict_proba(X)>0.5) #return the actual prediction\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        Xb = self._add_bias(X) # add bias term\n",
    "        num_samples, num_features = Xb.shape\n",
    "        \n",
    "        self.w_ = np.zeros((num_features,1)) # init weight vector to zeros\n",
    "        \n",
    "        # for as many as the max iterations\n",
    "        for _ in range(self.iters):\n",
    "            gradient = self._get_gradient(Xb,y)\n",
    "            self.w_ += gradient*self.eta # multiply by learning rate \n",
    "\n",
    "# blr = BinaryLogisticRegression(eta=0.1,iterations=500,C=0.001)\n",
    "\n",
    "# blr.fit(X,y)\n",
    "# print(blr)\n",
    "\n",
    "# yhat = blr.predict(X)\n",
    "# print('Accuracy of: ',accuracy_score(y,yhat+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34 µs, sys: 1 µs, total: 35 µs\n",
      "Wall time: 37 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from numpy.linalg import pinv\n",
    "class HessianBinaryLogisticRegression(BinaryLogisticRegression):\n",
    "    # just overwrite gradient function\n",
    "    def _get_gradient(self,X,y):\n",
    "        g = self.predict_proba(X,add_bias=False).ravel() # get sigmoid value for all classes\n",
    "        hessian = X.T @ np.diag(g*(1-g)) @ X + 2 * self.C # calculate the hessian\n",
    "\n",
    "        ydiff = y-g # get y difference\n",
    "        gradient = np.sum(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\n",
    "        gradient = gradient.reshape(self.w_.shape)\n",
    "        gradient[1:] += 2 * self.w_[1:] * self.C\n",
    "        \n",
    "        return pinv(hessian) @ gradient\n",
    "       \n",
    "# hlr = HessianBinaryLogisticRegression(eta=0.1,iterations=20,C=0.1) # note that we need only a few iterations here\n",
    "\n",
    "# hlr.fit(X,y)\n",
    "# yhat = hlr.predict(X)\n",
    "# print(hlr)\n",
    "# print('Accuracy of: ',accuracy_score(y,yhat+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 69 µs, sys: 1e+03 ns, total: 70 µs\n",
      "Wall time: 77 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# and we can update this to use a line search along the gradient like this:\n",
    "from scipy.optimize import minimize_scalar\n",
    "from scipy.optimize import OptimizeResult\n",
    "\n",
    "import copy\n",
    "class LineSearchLogisticRegression(BinaryLogisticRegression):\n",
    "    \n",
    "    # define custom line search for problem\n",
    "    @staticmethod\n",
    "    def line_search_function(eta,X,y,w,grad):\n",
    "        wnew = w + grad*eta\n",
    "        yhat = (1/(1+np.exp(-X @ wnew)))>0.5\n",
    "        return np.sum((y-yhat)**2)+np.sum(wnew**2)\n",
    "    @staticmethod\n",
    "    def line_search_function_l1(eta,X,y,w,grad):\n",
    "        if(math.sin(w) < 0 ):\n",
    "            w -=1\n",
    "        elif(math.sin(w) > 0):\n",
    "            w += 1\n",
    "        else:\n",
    "            w = w\n",
    "        wnew = w + grad*eta\n",
    "        yhat = (1/(1+np.exp(-X @ wnew)))>0.5\n",
    "        return np.sum((y-yhat)**2)+np.sum(math.fabs(wnew))\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        Xb = self._add_bias(X) # add bias term\n",
    "        num_samples, num_features = Xb.shape\n",
    "        \n",
    "        self.w_ = np.zeros((num_features,1)) # init weight vector to zeros\n",
    "        \n",
    "        # for as many as the max iterations\n",
    "        for _ in range(self.iters):\n",
    "            gradient = self._get_gradient(Xb,y)\n",
    "            \n",
    "            # do line search in gradient direction, using scipy function\n",
    "            opts = {'maxiter':self.iters/20} # unclear exactly what this should be\n",
    "            res = minimize_scalar(self.line_search_function, # objective function to optimize\n",
    "                                  bounds=(self.eta/1000,self.eta*10), #bounds to optimize\n",
    "                                  args=(Xb,y,self.w_,gradient), # additional argument for objective function\n",
    "                                  method='bounded', # bounded optimization for speed\n",
    "                                  options=opts) # set max iterations\n",
    "            print(res)\n",
    "            eta = res.x # get optimal learning rate\n",
    "            self.w_ += gradient*eta # set new function values\n",
    "                \n",
    "            \n",
    "\n",
    "# lslr = LineSearchLogisticRegression(eta=0.1,iterations=110, C=0.001)\n",
    "\n",
    "# lslr.fit(X,y)\n",
    "\n",
    "# yhat = lslr.predict(X)\n",
    "# print(lslr)\n",
    "# print('Accuracy of: ',accuracy_score(y,yhat))         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26 µs, sys: 1 µs, total: 27 µs\n",
      "Wall time: 30 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "class StochasticLogisticRegression(BinaryLogisticRegression):\n",
    "    # stochastic gradient calculation \n",
    "    def _get_gradient(self,X,y):\n",
    "        idx = int(np.random.rand()*len(y)) # grab random instance\n",
    "        ydiff = y[idx]-self.predict_proba(X[idx],add_bias=False) # get y difference (now scalar)\n",
    "        gradient = X[idx] * ydiff[:,np.newaxis] # make ydiff a column vector and multiply through\n",
    "        \n",
    "        gradient = gradient.reshape(self.w_.shape)\n",
    "        gradient[1:] += 2 * self.w_[1:] * self.C\n",
    "        \n",
    "        return gradient\n",
    "    \n",
    "    \n",
    "# slr = StochasticLogisticRegression(0.1,1000, C=0.001) # take a lot more steps!!\n",
    "\n",
    "# slr.fit(X,y)\n",
    "\n",
    "# yhat = slr.predict(X)\n",
    "# print(slr)\n",
    "# print('Accuracy of: ',accuracy_score(y,yhat))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38 µs, sys: 0 ns, total: 38 µs\n",
      "Wall time: 42 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# for this, we won't perform our own BFGS implementation \n",
    "# (it takes a good deal of code and understanding of the algorithm)\n",
    "# luckily for us, scipy has its own BFGS implementation:\n",
    "from scipy.optimize import fmin_bfgs\n",
    "class BFGSBinaryLogisticRegression(BinaryLogisticRegression):\n",
    "    \n",
    "    @staticmethod\n",
    "    def objective_function(w,X,y,C):\n",
    "        g = expit(X @ w)\n",
    "        return -np.sum(np.log(g[y==1]))-np.sum(np.log(1-g[y==0])) + C*sum(w**2) #-np.sum(y*np.log(g)+(1-y)*np.log(1-g))\n",
    "\n",
    "    @staticmethod\n",
    "    def objective_gradient(w,X,y,C):\n",
    "        g = expit(X @ w)\n",
    "        ydiff = y-g # get y difference\n",
    "        gradient = np.mean(X * ydiff[:,np.newaxis], axis=0)\n",
    "        gradient = gradient.reshape(w.shape)\n",
    "        gradient[1:] += 2 * w[1:] * C\n",
    "        return -gradient\n",
    "    \n",
    "    # just overwrite fit function\n",
    "    def fit(self, X, y):\n",
    "        Xb = self._add_bias(X) # add bias term\n",
    "        num_samples, num_features = Xb.shape\n",
    "        \n",
    "        self.w_ = fmin_bfgs(self.objective_function, # what to optimize\n",
    "                            np.zeros((num_features,1)), # starting point\n",
    "                            fprime=self.objective_gradient, # gradient function\n",
    "                            args=(Xb,y,self.C), # extra args for gradient and objective function\n",
    "                            gtol=1e-03, # stopping criteria for gradient, |v_k|\n",
    "                            maxiter=self.iters, # stopping criteria iterations\n",
    "                            disp=False)\n",
    "        self.w_ = self.w_.reshape((num_features,1))\n",
    "            \n",
    "# bfgslr = BFGSBinaryLogisticRegression(_,2) # note that we need only a few iterations here\n",
    "\n",
    "# bfgslr.fit(X,y)\n",
    "# yhat = bfgslr.predict(X)\n",
    "# print(bfgslr)\n",
    "# print('Accuracy of: ',accuracy_score(y,yhat+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MultiClassLogisticRegression:\n",
    "    def __init__(self, eta, iterations=20, C=0.0001, optimization=None):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        self.C = C\n",
    "        self.classifiers_ = []\n",
    "        self.optimization = optimization\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "    \n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'MultiClass Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained MultiClass Logistic Regression Object'\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        num_samples, num_features = X.shape\n",
    "        self.unique_ = np.sort(np.unique(y)) # get each unique class value\n",
    "        num_unique_classes = len(self.unique_)\n",
    "        self.classifiers_ = []\n",
    "        for i,yval in enumerate(self.unique_): # for each unique value\n",
    "            y_binary = y==yval # create a binary problem\n",
    "            # train the binary classifier for this class\n",
    "            #hblr = HessianBinaryLogisticRegression(self.eta,self.iters,self.C)\n",
    "            if(self.optimization == \"BFGSBinaryLogisticRegression\"):\n",
    "                hblr = BFGSBinaryLogisticRegression(self.eta,self.iters,self.C)\n",
    "            elif(self.optimization == \"StochasticLogisticRegression\"):\n",
    "                hblr = StochasticLogisticRegression(self.eta,self.iters,self.C)\n",
    "            else:\n",
    "                hblr = LineSearchLogisticRegression(self.eta,self.iters,self.C)\n",
    "\n",
    "            hblr.fit(X,y_binary)\n",
    "            #print(accuracy(y_binary,hblr.predict(X)))\n",
    "            # add the trained classifier to the list\n",
    "            self.classifiers_.append(hblr)\n",
    "            \n",
    "        # save all the weights into one matrix, separate column for each class\n",
    "        self.w_ = np.hstack([x.w_ for x in self.classifiers_]).T\n",
    "        \n",
    "    def predict_proba(self,X):\n",
    "        probs = []\n",
    "        for hblr in self.classifiers_:\n",
    "            probs.append(hblr.predict_proba(X).reshape((len(X),1))) # get probability for each classifier\n",
    "        \n",
    "        return np.hstack(probs) # make into single matrix\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return np.argmax(self.predict_proba(X),axis=1) # take argmax along row\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy 0.346534653465\n",
      "confusion matrix\n",
      " [[10 14  8  3  1]\n",
      " [10 18 11  1  2]\n",
      " [ 9 15 27 13  8]\n",
      " [ 5 10  5 11  5]\n",
      " [ 1  1  3  7  4]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 1  ====\n",
      "accuracy 0.356435643564\n",
      "confusion matrix\n",
      " [[15  6  6  5  0]\n",
      " [ 6 18 17  6  1]\n",
      " [10 18 28 13  6]\n",
      " [ 2  6 10 10  2]\n",
      " [ 1  3  7  5  1]]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.381188118812\n",
      "confusion matrix\n",
      " [[20 10  7  1  0]\n",
      " [13 16 16  4  1]\n",
      " [ 4 15 24 10  0]\n",
      " [ 5  6 12 14  2]\n",
      " [ 0  1 12  6  3]]\n"
     ]
    }
   ],
   "source": [
    "# run logistic regression and vary some parameters\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "# first we create a reusable logisitic regression object\n",
    "#   here we can setup the object with different learning parameters and constants\n",
    "\n",
    "\n",
    "lr_clf = MultiClassLogisticRegression(eta=0.1,iterations=2500, C=0.006, optimization=\"BFGSBinaryLogisticRegression\") # get object\n",
    "lr_clf_accuracies = []\n",
    "lr_clf_times = []\n",
    "# now we can use the cv_object that we setup before to iterate through the \n",
    "#    different training and testing sets. Each time we will reuse the logisitic regression \n",
    "#    object, but it gets trained on different data each time we use it.\n",
    "\n",
    "iter_num=0\n",
    "# the indices are the rows used for training and testing in each iteration\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    # I will create new variables here so that it is more obvious what \n",
    "    # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "    # but it makes this code less readable)\n",
    "    X_train = (X[train_indices])\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "#     print(X_train)\n",
    "#     print(y_train)\n",
    "    \n",
    "    X_test = (X[test_indices])\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    st = time.time()\n",
    "    lr_clf.fit(X_train,y_train)  # train object\n",
    "    t = (time.time() -st)\n",
    "    lr_clf_times.append(t)\n",
    "    \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    y_hat = lr_clf.predict(X_test) # get test set precitions\n",
    "\n",
    "    # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "    acc = mt.accuracy_score(y_test,y_hat+1)\n",
    "    lr_clf_accuracies.append(acc)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat+1)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"accuracy\", acc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1\n",
    "    \n",
    "# Also note that every time you run the above code\n",
    "#   it randomly creates a new training and testing set, \n",
    "#   so accuracy will be different each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: 179321.99078527954\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 178777.42279419178\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 841434.35441396141\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 181237.2873215141\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 179603.79416316087\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 178836.85945464144\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 841356.30265707267\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 181801.03769656082\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 179945.18603762699\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 178955.81035026774\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 235710.7773649311\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 235337.15002187598\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 784971.25692252466\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 237068.34318708372\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 235538.77266871469\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 784776.29223168327\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 238189.07685830249\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 236017.97759564751\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 235418.84259687338\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 784827.39014832629\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 312289.89109307178\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 708075.41133648483\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 313889.05907958199\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 312131.98811848124\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 708258.70181779785\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 313297.20626663661\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 312247.25153946783\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 708104.95134147338\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 313754.99336154381\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 312114.7004586822\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 195436.4351043762\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 194930.10492407996\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:12: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: 825359.88082220498\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 196963.59269694006\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 195444.77429922609\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 194930.94559302338\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 825356.08608829801\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 196980.27218900155\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 195453.95672606648\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 194932.62817376529\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 99846.611912391279\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 99312.776822368178\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 99029.835913664545\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 98980.456333506081\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 921166.99052776862\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 102460.75255665407\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 101265.67904317251\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 100321.25441187764\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 99627.571651917271\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 99184.723779264677\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "MultiClass Logistic Regression Object with coefficients:\n",
      "[[ -7.87442891e-02  -3.51886375e-01  -1.73335952e-01  -2.89984814e-01\n",
      "   -1.29972292e-01  -1.46277457e-01  -1.65262840e-01  -1.97763054e-01\n",
      "   -3.37182584e-01  -2.77579727e-01  -1.40547198e-01  -2.23583764e-01\n",
      "   -1.66319863e-01  -1.07214092e-01  -1.52238082e-01  -2.02552642e-01\n",
      "   -1.53129150e-01  -1.76281332e-01  -2.26810671e-01  -8.80635330e-02\n",
      "   -4.13605616e-01  -1.33928208e-01  -3.70908114e-01  -2.84264685e-01\n",
      "   -3.39353247e-01  -2.75125199e-01  -1.12727234e-01  -3.54437772e-01\n",
      "   -4.45821965e-01  -2.50141277e-01  -1.04536991e-01  -1.70833379e-01\n",
      "    1.52995106e-03  -5.60713151e-02   8.10092592e-02  -1.39767805e-01\n",
      "   -4.58771435e-02  -2.94724798e-01  -7.89450872e-02   6.22534620e-02\n",
      "   -3.98450446e-01  -2.89085953e-01  -2.59208560e-01  -1.51684379e-01\n",
      "   -2.43185701e-01  -3.11962842e-01   2.31222371e-01   6.14182318e-02\n",
      "   -8.87909838e-02  -4.14823171e-02  -3.89888821e-01  -1.12275855e-01\n",
      "   -1.14296181e-02  -1.07929853e-01  -1.95653683e-01   3.10258300e-02\n",
      "   -2.46397023e-01  -3.84200372e-01  -2.08341856e-01  -1.02320621e-01\n",
      "   -9.18558321e-02  -2.55659095e-01   6.52004003e-02  -4.10644650e-01\n",
      "   -4.04622733e-01  -3.30323878e-01  -4.31783552e-01  -4.86772907e-01\n",
      "   -5.16827944e-01  -5.99921128e-01  -4.78200372e-01  -3.20868067e-01\n",
      "   -6.04206616e-01  -1.87636409e-01  -4.72419256e-04  -4.83867303e-02\n",
      "   -2.02162556e-01  -7.92777766e-02  -2.00217582e-01  -2.70112259e-01\n",
      "   -1.76179007e-01  -1.89258824e-01  -2.41729241e-01  -3.13476699e-01\n",
      "   -6.99305244e-02  -3.47021467e-01  -7.23175255e-02  -5.48720955e-01\n",
      "   -5.54059364e-02  -3.56105895e-01  -7.03819030e-02  -2.88638471e-01\n",
      "   -3.09915544e-01  -3.36670692e-01  -1.79232166e-01  -3.47482976e-01\n",
      "   -3.77091310e-01  -5.54728845e-01  -2.35783423e-01  -4.85888074e-01\n",
      "   -5.92407174e-01  -1.48736661e-01  -1.29146413e-01  -1.43160667e-01\n",
      "    2.12735633e-01  -1.52237302e-01   3.13802104e-01  -4.23166089e-01\n",
      "   -1.99773996e-01   1.87526022e-01  -1.37213291e-01  -3.63225087e-01\n",
      "   -1.72948983e-01   1.23576383e-01  -2.80522769e-01   5.07812538e-02\n",
      "   -1.22158057e+00  -3.59555374e-01  -5.19501148e-01  -1.56158995e-02\n",
      "    1.61475725e-01  -1.16955326e-01  -7.39376029e-02  -3.02783104e-01\n",
      "   -3.78311950e-01   1.81511897e-01  -2.32606899e-01  -3.29106355e-01\n",
      "   -3.53429574e-01  -2.22143669e-01  -4.21570472e-02   1.71131206e-02\n",
      "   -9.51401355e-02  -9.78094430e-02  -1.31263576e-01  -1.38468497e+00\n",
      "   -1.26005958e+01  -3.72422831e+00  -5.13162861e-03   5.89359199e-02\n",
      "   -2.11638390e-03  -4.32449710e-02  -8.98293040e-02   2.27605378e-02\n",
      "   -8.34918416e-03  -9.35044724e-02   3.36115160e-02  -8.15359577e-02\n",
      "   -2.90538517e-02   3.17106907e-03   1.27959520e-03  -2.26535378e-02\n",
      "   -6.37286249e-02  -4.01886948e-02   1.21313526e-02  -4.79748246e-02\n",
      "   -2.83837973e-03  -1.35077425e-01   5.69304325e-02   8.45852204e-03\n",
      "   -8.44906889e-02   2.50257326e-03   5.39834941e-03   2.22572178e-04\n",
      "   -7.29138185e-03  -1.39205021e-03  -7.73644828e-02  -7.93691909e-02\n",
      "    2.39089752e-03  -8.93864975e-02   1.43004572e-02  -4.78119867e-02\n",
      "   -2.72740535e-02]\n",
      " [  3.51497553e-02   1.41658259e-01   1.40664325e-01   1.16381536e-01\n",
      "    1.95407404e-01   1.52635297e-01   1.93585874e-01   1.15423497e-01\n",
      "    6.11123085e-02  -5.87821355e-02  -5.74167182e-02  -1.24144194e-01\n",
      "    1.09560282e-01   1.19663325e-01   2.26908611e-01   9.41429355e-02\n",
      "   -8.07061567e-02   2.92935431e-01   1.35349145e-01   1.40803522e-01\n",
      "    1.47007581e-01   1.28735678e-02   9.09895465e-02   1.12680113e-01\n",
      "    1.12106981e-01   1.12130035e-01   1.94742350e-01   2.42618945e-01\n",
      "    1.54703998e-01   1.59142263e-01   2.43330105e-01   1.18659471e-01\n",
      "    1.20037437e-01   9.69811608e-02   3.64591718e-01   1.16929863e-01\n",
      "    1.61687210e-01   5.35793100e-02   1.80947819e-02   1.68018209e-01\n",
      "    8.86296112e-02   7.98342059e-02   9.08955946e-03   7.76858397e-02\n",
      "    2.02428262e-01   1.31810264e-01   1.43957203e-01   5.03310792e-02\n",
      "    1.09513299e-01   1.79838020e-01   2.37503077e-01   2.33916337e-01\n",
      "    1.56151124e-01   8.86873909e-02   5.88696845e-02   1.97872686e-01\n",
      "    7.97055139e-02  -1.15962764e-02   5.80636821e-02   1.29451497e-01\n",
      "    1.75073210e-01   1.62670347e-01   1.24627447e-01   8.44370573e-02\n",
      "   -1.82891304e-02  -3.18729828e-02  -1.13959442e-01  -5.30248519e-02\n",
      "   -9.06224361e-02  -4.45915932e-02  -4.75588025e-02  -9.31338249e-02\n",
      "   -5.87827195e-02   9.61751584e-02   2.04296483e-01   8.34162879e-03\n",
      "    1.32009284e-01   1.42988366e-01   8.90623782e-02   1.10844867e-01\n",
      "    1.30047682e-01   9.72855277e-02   1.99577488e-01   2.48248704e-01\n",
      "    3.44234777e-02   1.75216502e-02  -7.37918129e-02  -2.78073690e-02\n",
      "    2.17074625e-01   6.85291637e-02   1.35549041e-01  -8.94201449e-02\n",
      "    1.17293177e-01   1.66195804e-01   1.49155363e-01   1.37931738e-01\n",
      "    5.94541969e-02   8.97254017e-03   9.00437634e-02  -1.93744023e-02\n",
      "   -7.47259232e-02   2.24783299e-01   9.77171267e-02   7.70776898e-02\n",
      "    1.46784631e-01   1.92067251e-01   2.36837147e-01  -8.99092177e-03\n",
      "    2.21559873e-01   2.14107708e-01   1.78460346e-01   1.69817270e-01\n",
      "    8.40635299e-02   1.99461345e-01   1.02223982e-02   1.32897288e-01\n",
      "   -2.49784541e-01   1.66944318e-01   4.94086416e-02   1.31192193e-01\n",
      "    1.86555095e-01   1.30736081e-01   1.54411596e-01   1.54960214e-01\n",
      "   -2.02968399e-02   2.10755883e-01   6.84705081e-02   9.79619620e-02\n",
      "    1.70772244e-03   1.58265932e-01   9.52057379e-02   1.08707881e-01\n",
      "    8.04890467e-02   2.08043151e-02   1.11546398e-01   7.65905865e-01\n",
      "    6.77494330e+00   2.88251340e+00   4.12896707e-02  -5.12631457e-02\n",
      "   -8.25758374e-03   1.57914582e-02   6.93558836e-02  -1.02080976e-02\n",
      "    3.14892427e-02   5.75874362e-03   4.76661930e-02  -3.30189542e-02\n",
      "    1.80574278e-02  -3.27738269e-02  -1.48331264e-03   2.51588273e-02\n",
      "    4.18029788e-02   6.56419116e-02  -2.52168989e-02  -6.77427110e-03\n",
      "    1.41327627e-03   8.67867799e-03   2.78102889e-02   6.48245286e-03\n",
      "    3.14197903e-02   7.75565637e-03  -9.46075087e-03   3.77262762e-03\n",
      "    8.39794849e-03   1.35955251e-02   7.69758471e-03   3.91751546e-02\n",
      "   -2.21898661e-03   3.68741669e-02   1.97415127e-03   5.35530446e-02\n",
      "   -1.47047264e-02]\n",
      " [ -2.38880757e-02  -1.44816915e-01  -1.14860964e-01  -1.67580855e-01\n",
      "   -7.06162426e-02  -1.01600278e-01  -1.75148278e-01  -1.66399562e-01\n",
      "   -6.72158558e-02  -8.86472883e-03  -7.93421627e-02  -5.37111369e-02\n",
      "   -1.86500253e-01  -3.56882452e-01  -2.16093156e-01  -1.36640731e-01\n",
      "   -2.68793819e-02  -2.66499412e-01  -1.58095002e-01  -2.04894033e-01\n",
      "   -1.82952723e-02  -7.69846160e-02   8.17429075e-02  -1.00375431e-01\n",
      "   -1.03810011e-01  -6.55448179e-02  -1.09740590e-01  -1.99970778e-01\n",
      "   -4.75512811e-02  -5.24031472e-02  -1.09825055e-01  -6.82734521e-02\n",
      "   -2.08371202e-01  -2.04942982e-01  -2.18919332e-01  -6.90916961e-02\n",
      "   -1.12740733e-01  -8.79088713e-02  -1.30018606e-01  -2.16070360e-01\n",
      "    2.82128119e-02   4.81703692e-02  -7.54503509e-02  -5.84996543e-02\n",
      "   -2.04367092e-01  -2.52864490e-02  -1.74110119e-01  -9.68281960e-02\n",
      "   -1.98496504e-01  -2.16558427e-01  -6.68384082e-02  -1.62091072e-01\n",
      "   -1.70637987e-01  -1.59684576e-01   5.88827484e-02  -2.38844375e-01\n",
      "   -3.02586525e-02   5.53814612e-02  -6.29968683e-02  -1.06758204e-01\n",
      "   -2.45276097e-01  -1.34120614e-01  -2.19822398e-01  -6.00811895e-02\n",
      "    2.30290891e-02   8.98848984e-02   5.91660125e-02   7.90307087e-02\n",
      "   -4.41636145e-02   4.83557346e-02   5.88798942e-03  -6.30049076e-02\n",
      "   -9.77415463e-03  -1.22750525e-01  -1.41437288e-01  -1.17545089e-05\n",
      "   -1.23596602e-01  -1.81358762e-01  -4.16954489e-02  -3.50699653e-02\n",
      "   -1.58591464e-01  -1.33873223e-01  -1.34468550e-01  -1.63176502e-01\n",
      "   -8.41876687e-02  -3.99201522e-02  -1.78774940e-01   8.54721494e-02\n",
      "    2.10308754e-02  -9.25361412e-02  -1.12615715e-01  -4.08540527e-02\n",
      "   -7.78129353e-02  -1.15768710e-01  -1.25109751e-01  -9.14249146e-02\n",
      "   -1.33733406e-02  -9.51930305e-02  -1.84845650e-01   4.79652100e-02\n",
      "    9.37425169e-02  -1.65455943e-01  -1.16318803e-01   1.70968312e-02\n",
      "   -1.44554767e-01   2.08227146e-02  -2.75261204e-01  -9.31023126e-02\n",
      "   -1.75896813e-01  -2.14425476e-01  -2.09928262e-01  -1.82906104e-01\n",
      "   -1.18401482e-01  -2.78266386e-01  -9.17322966e-02  -1.32524323e-01\n",
      "    2.27940523e-01  -1.56285869e-01  -3.34689931e-02  -1.37444576e-01\n",
      "   -1.73882521e-01  -5.73639530e-02  -1.16875256e-01  -2.43086368e-02\n",
      "   -5.02326452e-02  -2.24187876e-01  -1.03697713e-01  -8.11580126e-02\n",
      "    8.76654469e-02  -1.12334130e-01  -6.71360717e-02  -1.45155132e-01\n",
      "   -2.22618305e-02  -5.56717989e-02  -1.98122414e-01  -6.59841387e-01\n",
      "   -4.39750181e+00  -1.57449653e+00  -5.00777578e-02  -7.98074337e-03\n",
      "   -1.49478021e-02  -2.03903143e-02   2.57074515e-02  -4.31837663e-02\n",
      "   -1.96776516e-02   4.12767345e-02  -4.37744124e-02   7.28416974e-02\n",
      "   -5.03737420e-02  -8.45909134e-03  -1.22761566e-02  -1.32231340e-02\n",
      "    1.26519250e-02  -2.87843777e-02  -1.82865194e-02   2.28373637e-02\n",
      "    2.78226441e-04  -2.01137671e-02   4.10501023e-03  -2.74793897e-02\n",
      "   -5.25714683e-03   4.07249625e-03   3.76175582e-03  -2.37062362e-03\n",
      "   -2.22483968e-02  -4.21814794e-02   3.63353657e-02  -3.77771265e-02\n",
      "    1.22191680e-02  -9.54116234e-03  -1.33679461e-02  -5.25231279e-02\n",
      "    2.11110163e-02]\n",
      " [  4.71354828e-04  -1.50693922e-02  -4.45532797e-02   7.15985558e-02\n",
      "   -1.20066311e-01  -4.22605374e-02  -5.13396785e-02   1.09335081e-01\n",
      "    1.23464808e-01   5.92374938e-02   1.17019019e-01   1.62765743e-01\n",
      "    1.35825110e-01   1.45398870e-01   1.31076759e-03   1.49124338e-01\n",
      "    1.03260239e-02   2.18463063e-02   4.56151847e-02   8.52982518e-02\n",
      "   -5.69757852e-02  -1.50518013e-02  -3.90440027e-02  -7.62309157e-02\n",
      "   -2.53607101e-03   5.67390219e-02  -1.17680950e-01  -4.73398574e-02\n",
      "   -5.45195771e-02  -6.68733835e-02  -9.95841239e-02  -8.16763092e-02\n",
      "   -9.75347149e-02  -2.13994656e-02  -2.95434715e-01  -8.03297094e-02\n",
      "   -2.11114241e-02   2.46665434e-03   4.48845667e-02  -1.85407230e-01\n",
      "    8.20099330e-02   3.28719584e-02   4.29363181e-02  -6.25272319e-02\n",
      "    9.42700871e-03   6.94334747e-02  -1.94753713e-01  -7.92704422e-03\n",
      "   -7.88850841e-02  -1.50453212e-01  -1.52135701e-01  -9.24635006e-02\n",
      "   -3.12428296e-02   1.09467382e-02  -1.11449860e-01  -5.81324732e-02\n",
      "    1.61224590e-02   1.11119556e-01  -5.47932405e-02   1.69613314e-03\n",
      "   -3.24180362e-02  -7.73446158e-02  -3.88173782e-02   1.98598855e-01\n",
      "    1.40229377e-01   9.06980899e-02   2.12132569e-01   2.01722058e-01\n",
      "    3.10356582e-01   2.96608274e-01   2.79639379e-01   1.94264681e-01\n",
      "    2.47743957e-01   2.53507945e-02  -2.13460772e-01  -4.34340081e-02\n",
      "   -4.36606084e-02  -3.46994429e-02  -1.06107313e-01  -4.22653513e-02\n",
      "   -2.26303806e-02  -5.05698291e-02   1.58368720e-02  -5.59107945e-02\n",
      "   -4.51650838e-02   1.43345417e-01   1.25810128e-01   9.51950412e-02\n",
      "   -3.52598769e-01  -2.42418377e-02  -1.94212796e-01   1.76962389e-01\n",
      "   -5.23496737e-02   7.44449146e-02  -2.07301663e-02   7.84918882e-02\n",
      "    2.41175273e-02   2.32830161e-01   9.60805576e-02   2.07559955e-01\n",
      "    4.65556397e-02  -2.23035388e-01  -8.45681869e-02  -7.87693745e-02\n",
      "   -2.13240614e-01  -1.96816632e-01  -2.80583113e-01   1.61311361e-01\n",
      "   -7.59445784e-02  -1.83964921e-01   5.59611206e-02   1.32094782e-01\n",
      "   -4.54073134e-03  -6.46460117e-02   1.05826584e-01  -1.57254019e-01\n",
      "    4.67461589e-01   6.64195642e-02   8.47891443e-02  -9.98210782e-02\n",
      "   -1.90202466e-01  -1.29385066e-02  -1.03657480e-01  -1.04655484e-01\n",
      "    1.07101440e-01  -2.29604743e-01   2.00059180e-02   2.75238828e-02\n",
      "    3.29197915e-02  -1.41097590e-02  -8.67363988e-02  -5.71854826e-02\n",
      "   -6.54215677e-02   1.11605731e-02   2.72383027e-02   7.16170758e-03\n",
      "   -2.32472936e-01  -5.93813050e-01  -3.98043281e-02   1.93102283e-02\n",
      "    7.79000080e-03   1.12402407e-02  -4.02973301e-02   2.27604886e-02\n",
      "    1.14636171e-02  -2.91129356e-02  -2.08738086e-02  -1.71443703e-02\n",
      "    3.53377637e-02   3.78434604e-02  -8.62682111e-03   2.11245070e-03\n",
      "   -2.90563003e-02  -2.53292351e-02   2.20377404e-02   6.51041125e-03\n",
      "   -2.83837994e-03   2.83781529e-02  -3.22272657e-02   2.33181203e-02\n",
      "   -2.00992036e-02  -2.72167100e-02   5.39834500e-03   2.22572174e-04\n",
      "    2.73810450e-02   1.34675413e-02  -1.79261301e-02   9.78834521e-03\n",
      "   -1.24687604e-02  -2.28959495e-04  -5.51240746e-03   1.71995796e-03\n",
      "   -2.50811872e-03]\n",
      " [ -6.49415926e-02  -2.44719454e-01  -2.48289730e-01  -1.25090400e-01\n",
      "   -1.96244505e-01  -1.48684113e-01  -1.91001541e-01  -2.14590008e-01\n",
      "   -2.33192044e-01  -1.92054471e-01  -1.24140413e-01  -4.72620013e-02\n",
      "   -2.63440856e-01  -1.21144041e-01  -2.24396534e-01  -3.12162342e-01\n",
      "   -9.75824058e-02  -2.50770296e-01  -9.49531594e-02  -2.05019643e-01\n",
      "   -2.81468837e-01  -1.39389262e-01  -2.33966718e-01  -2.38708056e-01\n",
      "   -1.18920346e-01  -2.44394337e-01  -2.84368434e-01  -1.32802677e-01\n",
      "   -1.13447429e-01  -2.85862046e-01  -2.33381275e-01  -2.70094943e-01\n",
      "   -2.20522534e-01  -2.06716563e-01  -3.00191400e-01  -1.39934083e-01\n",
      "   -2.65614017e-01  -2.10374400e-01  -2.47077914e-01  -1.65506535e-01\n",
      "   -1.67054756e-01  -1.77148342e-01  -1.14896590e-01  -2.11232958e-01\n",
      "   -2.58196542e-01  -2.12139845e-01  -3.03135564e-01  -3.58745944e-01\n",
      "   -6.16610847e-02  -5.80502258e-02  -1.33912576e-01  -2.02230455e-01\n",
      "   -2.48373537e-01  -6.53559029e-02  -2.74328301e-01  -3.61580825e-01\n",
      "   -7.33818075e-02  -8.32112687e-02  -1.56522003e-01  -3.54587697e-01\n",
      "   -1.88678425e-01  -2.95791736e-01  -3.05763290e-01  -2.53967133e-01\n",
      "   -4.55454228e-03  -8.37039734e-02  -4.06300921e-03  -8.27449536e-02\n",
      "    2.67607671e-03  -9.18264053e-02  -6.32108087e-02  -2.19449013e-02\n",
      "    5.00842059e-02  -2.03026805e-01  -2.63749531e-01  -2.68036096e-01\n",
      "   -1.65116706e-01  -2.34459443e-01  -1.93372828e-01  -1.19880444e-01\n",
      "   -2.73060684e-01  -2.37369314e-01  -2.05248205e-01  -2.22454413e-01\n",
      "   -2.58973812e-01  -4.42962283e-02  -9.55452080e-02  -2.29217053e-02\n",
      "   -3.20134751e-01  -5.12805808e-02  -2.84053426e-01   2.06317765e-02\n",
      "   -1.84879546e-01  -8.49409932e-02  -2.17917566e-01  -3.06092498e-01\n",
      "   -2.23846489e-01   5.62252004e-02  -2.38893515e-01  -1.78070571e-01\n",
      "    1.53619908e-01  -1.24598760e-01  -1.94379970e-01  -1.63832509e-01\n",
      "   -4.49297170e-01  -2.51674528e-01  -4.52754334e-01  -3.68052120e-02\n",
      "   -2.48236449e-01  -4.25556334e-01  -2.72782627e-01  -1.52549000e-01\n",
      "   -2.56674883e-01  -4.36237964e-01  -1.20755677e-01  -3.55257052e-01\n",
      "    3.45314857e-01  -1.68753034e-01   3.03936341e-02  -3.67178340e-01\n",
      "   -4.71540512e-01  -3.51079564e-01  -2.99903175e-01  -1.16807963e-01\n",
      "   -1.10532438e-01  -4.08289053e-01  -1.71025236e-01  -7.23440405e-02\n",
      "   -1.77736608e-01  -2.41038884e-01  -3.07182083e-01  -3.41607081e-01\n",
      "   -3.18227198e-01  -2.50537806e-01  -2.61268979e-01  -1.41884497e+00\n",
      "   -1.26626731e+01  -5.94729476e+00  -1.15527815e-01  -3.46828735e-02\n",
      "   -7.98868841e-04   1.15884361e-02  -3.66426128e-02  -1.19212248e-02\n",
      "   -3.40897242e-02  -1.62281863e-02  -7.09140007e-02   1.14602275e-02\n",
      "   -4.48857887e-03  -1.09153023e-02   1.77294740e-02  -2.87984283e-02\n",
      "   -4.19580955e-02  -7.48602608e-02  -1.10878223e-03   7.40730151e-03\n",
      "    3.48391189e-03   4.71781715e-02  -1.19223825e-01  -2.10317433e-02\n",
      "   -4.23428698e-02  -1.66180754e-02  -5.67739145e-03  -2.83869401e-03\n",
      "   -1.48640797e-02   1.16392752e-02  -3.61511253e-02  -2.86663512e-02\n",
      "   -3.52760008e-02  -3.31054044e-02  -3.48885983e-02  -3.17641278e-02\n",
      "   -3.10427453e-02]]\n",
      "Accuracy of:  0.230693069307\n",
      "CPU times: user 1.23 s, sys: 43.8 ms, total: 1.28 s\n",
      "Wall time: 330 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr = MultiClassLogisticRegression(eta=0.1,iterations=10,C=0.0001)\n",
    "lr.fit(X,y)\n",
    "print(lr)\n",
    "\n",
    "yhat = lr.predict(X)\n",
    "print('Accuracy of: ',accuracy_score(y,yhat+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# linear boundaries visualization from sklearn documentation\n",
    "from matplotlib import pyplot as plt\n",
    "import copy\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_decision_boundaries(lr,Xin,y,title=''):\n",
    "    Xb = copy.deepcopy(Xin)\n",
    "    lr.fit(Xb[:,:2],y) # train only on two features\n",
    "\n",
    "    h=0.01\n",
    "    # create a mesh to plot in\n",
    "    x_min, x_max = Xb[:, 0].min() - 1, Xb[:, 0].max() + 1\n",
    "    y_min, y_max = Xb[:, 1].min() - 1, Xb[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "    # get prediction values\n",
    "    Z = lr.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.5)\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(Xb[:, 0], Xb[:, 1], c=y, cmap=plt.cm.Paired)\n",
    "    plt.xlabel('Feature')\n",
    "    plt.ylabel('Fear of Public Speaking')\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.title(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18 µs, sys: 1 µs, total: 19 µs\n",
      "Wall time: 6.91 µs\n",
      "For  BFGSBinaryLogisticRegression  and cost  0.0  Accuracy of:  0.615841584158\n",
      "CPU times: user 19 µs, sys: 2 µs, total: 21 µs\n",
      "Wall time: 7.87 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  0.002  Accuracy of:  0.616831683168\n",
      "CPU times: user 14 µs, sys: 1e+03 ns, total: 15 µs\n",
      "Wall time: 5.01 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  0.004  Accuracy of:  0.611881188119\n",
      "CPU times: user 10 µs, sys: 1 µs, total: 11 µs\n",
      "Wall time: 8.11 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  0.006  Accuracy of:  0.609900990099\n",
      "CPU times: user 15 µs, sys: 0 ns, total: 15 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:12: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  0.008  Accuracy of:  0.60297029703\n",
      "CPU times: user 14 µs, sys: 3 µs, total: 17 µs\n",
      "Wall time: 8.11 µs\n",
      "For  StochasticLogisticRegression  and cost  0.0  Accuracy of:  0.191089108911\n",
      "CPU times: user 13 µs, sys: 2 µs, total: 15 µs\n",
      "Wall time: 5.01 µs\n",
      "For  StochasticLogisticRegression  and cost  0.002  Accuracy of:  0.175247524752\n",
      "CPU times: user 12 µs, sys: 0 ns, total: 12 µs\n",
      "Wall time: 7.15 µs\n",
      "For  StochasticLogisticRegression  and cost  0.004  Accuracy of:  0.305940594059\n",
      "CPU times: user 8 µs, sys: 1 µs, total: 9 µs\n",
      "Wall time: 4.05 µs\n",
      "For  StochasticLogisticRegression  and cost  0.006  Accuracy of:  0.305940594059\n",
      "CPU times: user 8 µs, sys: 0 ns, total: 8 µs\n",
      "Wall time: 7.15 µs\n",
      "For  StochasticLogisticRegression  and cost  0.008  Accuracy of:  0.175247524752\n",
      "CPU times: user 8 µs, sys: 4 µs, total: 12 µs\n",
      "Wall time: 6.91 µs\n",
      "     fun: 179321.99078527954\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 178777.40723027076\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 841434.41769791197\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 181237.0556913777\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 179603.30502635142\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 178836.66507243697\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 841356.42341514293\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 181799.68417352147\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 179943.87710958949\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 178955.18075676935\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 235710.7773649311\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 235337.14207215258\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 784971.30497807381\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 237068.29220734464\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 235538.60614278613\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 784776.32519188209\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 238188.36195513123\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 236017.28039118441\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 235418.55558345502\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 784827.62897442537\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 312289.89109307178\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 708075.42880182096\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 313889.01983764587\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 312131.9143438536\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 708258.89715105295\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 313296.85907093721\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 312247.05982354813\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 708105.1180482459\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 313754.3512406174\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 312114.57467434392\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 195436.4351043762\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 194930.10444733061\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 825359.95704497979\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 196963.43788564476\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 195444.44353768151\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 194930.94004986863\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 825356.36061217031\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 196979.44996674309\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 195453.28516483904\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 194932.61122308538\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 99846.611912391279\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 99312.644085697902\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 99029.752920719708\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 98980.454762326641\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 921167.07703882037\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 102460.06229674893\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 101264.4224640202\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 100319.85929300667\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 99626.372783708328\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 99183.962936125201\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "For  LineSearchLogisticRegression  and cost  0.0  Accuracy of:  0.230693069307\n",
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.01 µs\n",
      "     fun: 179321.99078527954\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 178777.7217137916\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 841433.15398491989\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 181241.70773487413\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 179613.13156885753\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 178840.61915875052\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 841354.0597538841\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 181826.9672339815\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 179970.33172675956\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:12: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: 178968.05998343704\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 235710.7773649311\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 235337.30191130107\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 784970.3437335809\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 237069.31966501949\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 235541.95283029205\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 784775.68260826694\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 238202.72942111662\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 236031.33424671303\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 235424.40786265908\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 784822.92652511958\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 312289.89109307178\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 708075.07993851893\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 313889.80741893355\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 312133.40290729294\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 708254.99824834103\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 313303.84029328736\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 312250.93020300311\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 708101.79745095002\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 313767.30066457117\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 312117.16796714696\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 195436.4351043762\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 194930.11692290325\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 825358.42365808808\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 196966.58146417697\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 195451.1060774668\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 194931.09049118235\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 825350.87599713041\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 196996.06465852039\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 195466.88893475221\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 194933.07095291076\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 99846.611912391279\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 99315.303851035453\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 99031.428424952348\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 98980.502072859759\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 921165.33712225931\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 102474.12313664709\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 101289.84377066937\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 100348.11802371834\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 99650.760807307714\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 99199.597536344882\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "For  LineSearchLogisticRegression  and cost  0.002  Accuracy of:  0.230693069307\n",
      "CPU times: user 14 µs, sys: 1 µs, total: 15 µs\n",
      "Wall time: 7.87 µs\n",
      "     fun: 179321.99078527954\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 178778.04294489324\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 841431.89445405186\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 181246.40082622843\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 179623.05086687327\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 178844.71456945752\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 841351.80659524747\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 181854.70251010972\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 179997.37591310576\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 178981.5567949008\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 235710.7773649311\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 235337.46352872488\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 784969.38222008734\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 237070.36370821201\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 235545.33370845372\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 784775.07533361251\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 238217.24394579674\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 236045.62142291386\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 235430.49924236396\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 784818.38406769477\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 312289.89109307178\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 708074.73200873216\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 313890.60077643825\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 312134.91904250486\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 708251.11589074833\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 313310.90053091117\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:12: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: 312254.87730540405\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 708098.50629903178\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 313780.47774675029\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 312119.92786535429\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 195436.4351043762\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 194930.1355891827\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 825356.89040446701\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 196969.76307654491\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 195457.83760611701\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 194931.32496507774\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 825345.4236839388\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 197012.97892989058\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 195480.82993042332\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 194933.79115643757\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 99846.611912391279\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 99317.9742099141\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 99033.137032537605\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 98980.583193423867\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 921163.61453763058\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 102488.40490256931\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 101315.62052862802\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 100376.93660709812\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 99675.888824677299\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 99216.053927017492\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "For  LineSearchLogisticRegression  and cost  0.004  Accuracy of:  0.230693069307\n",
      "CPU times: user 7 µs, sys: 1 µs, total: 8 µs\n",
      "Wall time: 5.01 µs\n",
      "     fun: 179321.99078527954\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 178778.37092357574\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 841430.63917181687\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 181251.13515076606\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 179633.06374388811\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 178848.95355048025\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 841349.66718390735\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 181882.89722680554\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 180025.02279584479\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 178995.6910160057\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:12: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: 235710.7773649311\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 235337.626924424\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 784968.42045619909\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 237071.42438644206\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 235548.74901091668\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 784774.50386235875\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 238231.90699980312\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 236060.14539428236\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 235436.83485111929\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 784814.00794545165\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 312289.89109307178\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 708074.38501246076\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 313891.39991386386\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 312136.46283312951\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 708247.25039256783\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 313318.04051444412\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 312258.90238188289\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 708095.24606815528\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 313793.88620250329\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 312122.85942615691\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 195436.4351043762\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 194930.16044616894\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 825355.35880032892\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 196972.97809468384\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 195464.63633433453\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 194931.64498186554\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 825340.00708207337\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 197030.19274405646\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 195495.11376819937\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 194934.78249126696\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 99846.611912391279\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 99320.655162333846\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 99034.878999130757\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 98980.698687328128\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 921161.91159292939\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 102502.89707126078\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 101341.74783231385\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 100406.31790874933\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 99701.770166345013\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 99233.357706846335\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "For  LineSearchLogisticRegression  and cost  0.006  Accuracy of:  0.230693069307\n",
      "CPU times: user 12 µs, sys: 2 µs, total: 14 µs\n",
      "Wall time: 7.15 µs\n",
      "     fun: 179321.99078527954\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 178778.70564983904\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 841429.38820491254\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 181255.91089493842\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 179643.17103091275\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 178853.33837684258\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 841347.64482317562\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 181911.55873321052\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 180053.28578831325\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 179010.48303112088\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 235710.7773649311\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 235337.79209839841\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 784967.45846057218\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 237072.50174950101\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 235552.19897358265\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 784773.96869453404\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 238246.72007032845\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 236074.9096872753\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 235331.44957794575\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 785045.94086687965\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 312289.89109307178\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 708074.03894970461\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 313892.20483494061\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 312138.03436333133\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 708243.40207029053\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 313325.2609819987\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 312263.00670107472\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 708092.01826606004\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:12: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: 313807.52981345798\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 312125.96784039139\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 195436.4351043762\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 194930.19149386202\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 825353.82890368137\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 196976.22665986817\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 195471.50287478627\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 194932.05209683179\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 825334.62819882098\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 197047.71093363583\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 195509.74866265932\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 194936.05599448484\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 99846.611912391279\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 99323.346708294688\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 99036.654581164097\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 98980.849122737884\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 921160.22911236761\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 102517.60197031518\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.38202781464898006\n",
      "     fun: 101368.23124401423\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 100436.27294895797\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 99728.424120045951\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "     fun: 99251.538398450692\n",
      " message: 'Maximum number of function calls reached.'\n",
      "    nfev: 2\n",
      "  status: 1\n",
      " success: False\n",
      "       x: 0.61807218535101982\n",
      "For  LineSearchLogisticRegression  and cost  0.008  Accuracy of:  0.230693069307\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "costs = [n for n in np.arange(0,0.01,0.002)]\n",
    "\n",
    "optimizations = [\"BFGSBinaryLogisticRegression\",\"StochasticLogisticRegression\",\"LineSearchLogisticRegression\"]\n",
    "\n",
    "for optimization in optimizations:\n",
    "    for cost in costs:\n",
    "        %%time\n",
    "        lr = MultiClassLogisticRegression(eta=0.1,\n",
    "                                           iterations=10,\n",
    "                                           C=cost,optimization=optimization) # get object\n",
    "        lr.fit(X,y)\n",
    "#         print(lr)\n",
    "        yhat = lr.predict(X)\n",
    "        print('For ',optimization,' and cost ', cost,' Accuracy of: ',accuracy_score(y,yhat+1))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of:  0.610891089109\n",
      "CPU times: user 615 ms, sys: 20 ms, total: 635 ms\n",
      "Wall time: 163 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression as SKLogisticRegression\n",
    "\n",
    "lr_sk = SKLogisticRegression(solver='lbfgs')#,max_iter=100,C=0.005) \n",
    "lr_sk.fit(X,y)\n",
    "#print(np.hstack((lr_sk.intercept_[:,np.newaxis],lr_sk.coef_)))\n",
    "yhat = lr_sk.predict(X)\n",
    "print('Accuracy of: ',accuracy_score(y,yhat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations  [100 100 100 100 100]\n",
      "====Iteration 0  ====\n",
      "accuracy 0.173267326733\n",
      "confusion matrix\n",
      " [[ 0  0  0  0  0  0]\n",
      " [ 7 15 13  8  3  0]\n",
      " [14 10  9  7  0  0]\n",
      " [13 10 29 11  2  0]\n",
      " [ 3 11  9  6  0  0]\n",
      " [ 5  2 11  3  1  0]]\n",
      "Iterations  [100 100 100 100 100]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.217821782178\n",
      "confusion matrix\n",
      " [[ 0  0  0  0  0  0]\n",
      " [ 7 10 16  6  0  0]\n",
      " [ 9  8 20  7  1  0]\n",
      " [16 20 20 12  3  0]\n",
      " [ 5  7 13  7  2  0]\n",
      " [ 5  3  2  3  0  0]]\n",
      "Iterations  [100 100 100 100 100]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.227722772277\n",
      "confusion matrix\n",
      " [[ 0  0  0  0  0  0]\n",
      " [ 7  7 11  4  1  0]\n",
      " [10 12 23  6  1  0]\n",
      " [11 14 15 14  1  0]\n",
      " [ 3 12 13  6  2  0]\n",
      " [11  3  9  5  1  0]]\n",
      "[0.14763784408569336, 0.1508932113647461, 0.13695096969604492]\n"
     ]
    }
   ],
   "source": [
    "# run logistic regression and vary some parameters\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "# first we create a reusable logisitic regression object\n",
    "#   here we can setup the object with different learning parameters and constants\n",
    "\n",
    "\n",
    "lr_sk = SKLogisticRegression(solver='lbfgs')#,max_iter=100,C=0.005) \n",
    "\n",
    "lr_sk_accuracies = []\n",
    "lr_sk_times = []\n",
    "# now we can use the cv_object that we setup before to iterate through the \n",
    "#    different training and testing sets. Each time we will reuse the logisitic regression \n",
    "#    object, but it gets trained on different data each time we use it.\n",
    "\n",
    "iter_num=0\n",
    "# the indices are the rows used for training and testing in each iteration\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    # I will create new variables here so that it is more obvious what \n",
    "    # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "    # but it makes this code less readable)\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "#     print(X_train)\n",
    "#     print(y_train)\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    st = time.time()\n",
    "    lr_sk.fit(X_train,y_train)\n",
    "    t = (time.time() -st)\n",
    "    lr_sk_times.append(t)\n",
    "    #print(np.hstack((lr_sk.intercept_[:,np.newaxis],lr_sk.coef_)))\n",
    "    yhat = lr_sk.predict(X_test)\n",
    " \n",
    "    print(\"Iterations \",lr_sk.n_iter_)\n",
    "    # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    lr_sk_accuracies.append(acc)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"accuracy\", acc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1\n",
    "\n",
    "print(lr_sk_times)\n",
    "# Also note that every time you run the above code\n",
    "#   it randomly creates a new training and testing set, \n",
    "#   so accuracy will be different each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.964406967163086\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAGHCAYAAAA6MMHNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11bcc9978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116e29dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot([lr_sk_accuracies,lr_clf_accuracies])\n",
    "plt.title(\"Comparing Accuracies\")\n",
    "plt.xlabel('Implementation of Logistic Regression')\n",
    "plt.xticks([1,2],['SKL','OURS'])\n",
    "plt.figure()\n",
    "print((time.time() -st)*100)\n",
    "# ax = fig.add_subplot(111)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11cb18198>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh4AAAGHCAYAAAD/QltcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRsbEQ5IkjYyJhyRJGpn/D3y0VbVs7E6cAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11cb18278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11cb18198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot([lr_sk_times,lr_clf_times])\n",
    "plt.title(\"Comparing Training Times\")\n",
    "plt.xlabel('Implementation of Logistic Regression')\n",
    "plt.ylabel('Training Time (seconds) ')\n",
    "plt.xticks([1,2],['SKL','OURS'])\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14763784408569336, 0.1508932113647461, 0.13695096969604492]\n",
      "[0.2919349670410156, 0.24648189544677734, 0.24258089065551758]\n"
     ]
    }
   ],
   "source": [
    "print(lr_sk_times)\n",
    "print(lr_clf_times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00000000e-03,   1.20679264e-03,   1.45634848e-03,\n",
       "         1.75751062e-03,   2.12095089e-03,   2.55954792e-03,\n",
       "         3.08884360e-03,   3.72759372e-03,   4.49843267e-03,\n",
       "         5.42867544e-03,   6.55128557e-03,   7.90604321e-03,\n",
       "         9.54095476e-03,   1.15139540e-02,   1.38949549e-02,\n",
       "         1.67683294e-02,   2.02358965e-02,   2.44205309e-02,\n",
       "         2.94705170e-02,   3.55648031e-02,   4.29193426e-02,\n",
       "         5.17947468e-02,   6.25055193e-02,   7.54312006e-02,\n",
       "         9.10298178e-02,   1.09854114e-01,   1.32571137e-01,\n",
       "         1.59985872e-01,   1.93069773e-01,   2.32995181e-01,\n",
       "         2.81176870e-01,   3.39322177e-01,   4.09491506e-01,\n",
       "         4.94171336e-01,   5.96362332e-01,   7.19685673e-01,\n",
       "         8.68511374e-01,   1.04811313e+00,   1.26485522e+00,\n",
       "         1.52641797e+00,   1.84206997e+00,   2.22299648e+00,\n",
       "         2.68269580e+00,   3.23745754e+00,   3.90693994e+00,\n",
       "         4.71486636e+00,   5.68986603e+00,   6.86648845e+00,\n",
       "         8.28642773e+00,   1.00000000e+01])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "costs = np.logspace(-3,1)\n",
    "costs.sort()\n",
    "costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.05 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  0.001  Accuracy of:  0.614851485149\n",
      "CPU times: user 13 µs, sys: 1 µs, total: 14 µs\n",
      "Wall time: 5.96 µs\n",
      "For  BFGSBinaryLogisticRegression  and cost  0.00120679264064  Accuracy of:  0.614851485149\n",
      "CPU times: user 9 µs, sys: 1 µs, total: 10 µs\n",
      "Wall time: 7.15 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  0.0014563484775  Accuracy of:  0.615841584158\n",
      "CPU times: user 11 µs, sys: 1 µs, total: 12 µs\n",
      "Wall time: 6.91 µs\n",
      "For  BFGSBinaryLogisticRegression  and cost  0.00175751062485  Accuracy of:  0.616831683168\n",
      "CPU times: user 14 µs, sys: 1 µs, total: 15 µs\n",
      "Wall time: 5.01 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  0.00212095088792  Accuracy of:  0.616831683168\n",
      "CPU times: user 13 µs, sys: 0 ns, total: 13 µs\n",
      "Wall time: 5.01 µs\n",
      "For  BFGSBinaryLogisticRegression  and cost  0.0025595479227  Accuracy of:  0.616831683168\n",
      "CPU times: user 16 µs, sys: 0 ns, total: 16 µs\n",
      "Wall time: 7.15 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  0.00308884359648  Accuracy of:  0.614851485149\n",
      "CPU times: user 12 µs, sys: 1 µs, total: 13 µs\n",
      "Wall time: 5.01 µs\n",
      "For  BFGSBinaryLogisticRegression  and cost  0.00372759372031  Accuracy of:  0.613861386139\n",
      "CPU times: user 13 µs, sys: 1 µs, total: 14 µs\n",
      "Wall time: 7.15 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  0.00449843266897  Accuracy of:  0.608910891089\n",
      "CPU times: user 13 µs, sys: 1 µs, total: 14 µs\n",
      "Wall time: 7.15 µs\n",
      "For  BFGSBinaryLogisticRegression  and cost  0.00542867543932  Accuracy of:  0.605940594059\n",
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  0.0065512855686  Accuracy of:  0.60099009901\n",
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 5.01 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  0.00790604321091  Accuracy of:  0.60297029703\n",
      "CPU times: user 20 µs, sys: 1 µs, total: 21 µs\n",
      "Wall time: 7.87 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  0.0095409547635  Accuracy of:  0.592079207921\n",
      "CPU times: user 9 µs, sys: 1 µs, total: 10 µs\n",
      "Wall time: 7.15 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  0.0115139539933  Accuracy of:  0.59801980198\n",
      "CPU times: user 15 µs, sys: 6 µs, total: 21 µs\n",
      "Wall time: 8.82 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  0.0138949549437  Accuracy of:  0.59900990099\n",
      "CPU times: user 17 µs, sys: 2 µs, total: 19 µs\n",
      "Wall time: 7.87 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  0.0167683293681  Accuracy of:  0.590099009901\n",
      "CPU times: user 7 µs, sys: 1 µs, total: 8 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  0.0202358964773  Accuracy of:  0.590099009901\n",
      "CPU times: user 6 µs, sys: 0 ns, total: 6 µs\n",
      "Wall time: 5.01 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  0.0244205309455  Accuracy of:  0.578217821782\n",
      "CPU times: user 8 µs, sys: 1 µs, total: 9 µs\n",
      "Wall time: 5.01 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  0.0294705170255  Accuracy of:  0.573267326733\n",
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  0.0355648030622  Accuracy of:  0.561386138614\n",
      "CPU times: user 18 µs, sys: 1e+03 ns, total: 19 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  0.0429193426013  Accuracy of:  0.560396039604\n",
      "CPU times: user 13 µs, sys: 1e+03 ns, total: 14 µs\n",
      "Wall time: 7.15 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  0.0517947467923  Accuracy of:  0.549504950495\n",
      "CPU times: user 18 µs, sys: 1 µs, total: 19 µs\n",
      "Wall time: 7.87 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  0.0625055192527  Accuracy of:  0.543564356436\n",
      "CPU times: user 21 µs, sys: 0 ns, total: 21 µs\n",
      "Wall time: 5.01 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  0.0754312006335  Accuracy of:  0.516831683168\n",
      "CPU times: user 7 µs, sys: 0 ns, total: 7 µs\n",
      "Wall time: 5.96 µs\n",
      "For  BFGSBinaryLogisticRegression  and cost  0.0910298177992  Accuracy of:  0.529702970297\n",
      "CPU times: user 13 µs, sys: 1 µs, total: 14 µs\n",
      "Wall time: 5.01 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  0.109854114199  Accuracy of:  0.515841584158\n",
      "CPU times: user 18 µs, sys: 0 ns, total: 18 µs\n",
      "Wall time: 5.01 µs\n",
      "For  BFGSBinaryLogisticRegression  and cost  0.132571136559  Accuracy of:  0.487128712871\n",
      "CPU times: user 14 µs, sys: 5 µs, total: 19 µs\n",
      "Wall time: 8.11 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  0.159985871961  Accuracy of:  0.50198019802\n",
      "CPU times: user 16 µs, sys: 1 µs, total: 17 µs\n",
      "Wall time: 7.87 µs\n",
      "For  BFGSBinaryLogisticRegression  and cost  0.193069772888  Accuracy of:  0.49702970297\n",
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 5.01 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  0.232995181052  Accuracy of:  0.491089108911\n",
      "CPU times: user 16 µs, sys: 1 µs, total: 17 µs\n",
      "Wall time: 5.01 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  0.281176869797  Accuracy of:  0.446534653465\n",
      "CPU times: user 15 µs, sys: 0 ns, total: 15 µs\n",
      "Wall time: 6.2 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  0.33932217719  Accuracy of:  0.452475247525\n",
      "CPU times: user 13 µs, sys: 1 µs, total: 14 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  0.409491506238  Accuracy of:  0.442574257426\n",
      "CPU times: user 6 µs, sys: 0 ns, total: 6 µs\n",
      "Wall time: 5.01 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  0.494171336132  Accuracy of:  0.394059405941\n",
      "CPU times: user 14 µs, sys: 2 µs, total: 16 µs\n",
      "Wall time: 7.15 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  0.596362331659  Accuracy of:  0.410891089109\n",
      "CPU times: user 6 µs, sys: 0 ns, total: 6 µs\n",
      "Wall time: 5.01 µs\n",
      "For  BFGSBinaryLogisticRegression  and cost  0.719685673001  Accuracy of:  0.39603960396\n",
      "CPU times: user 11 µs, sys: 8 µs, total: 19 µs\n",
      "Wall time: 11.9 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  0.868511373751  Accuracy of:  0.390099009901\n",
      "CPU times: user 8 µs, sys: 1 µs, total: 9 µs\n",
      "Wall time: 5.01 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  1.04811313415  Accuracy of:  0.336633663366\n",
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 7.87 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  1.26485521686  Accuracy of:  0.336633663366\n",
      "CPU times: user 17 µs, sys: 0 ns, total: 17 µs\n",
      "Wall time: 5.96 µs\n",
      "For  BFGSBinaryLogisticRegression  and cost  1.52641796718  Accuracy of:  0.338613861386\n",
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 6.2 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  1.84206996933  Accuracy of:  0.312871287129\n",
      "CPU times: user 17 µs, sys: 1e+03 ns, total: 18 µs\n",
      "Wall time: 7.87 µs\n",
      "For  BFGSBinaryLogisticRegression  and cost  2.22299648253  Accuracy of:  0.254455445545\n",
      "CPU times: user 8 µs, sys: 0 ns, total: 8 µs\n",
      "Wall time: 5.01 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  2.68269579528  Accuracy of:  0.254455445545\n",
      "CPU times: user 16 µs, sys: 0 ns, total: 16 µs\n",
      "Wall time: 5.01 µs\n",
      "For  BFGSBinaryLogisticRegression  and cost  3.23745754282  Accuracy of:  0.234653465347\n",
      "CPU times: user 15 µs, sys: 1e+03 ns, total: 16 µs\n",
      "Wall time: 5.01 µs\n",
      "For  BFGSBinaryLogisticRegression  and cost  3.90693993705  Accuracy of:  0.0970297029703\n",
      "CPU times: user 6 µs, sys: 0 ns, total: 6 µs\n",
      "Wall time: 5.01 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/rupalsanghavi/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:10: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  BFGSBinaryLogisticRegression  and cost  4.71486636346  Accuracy of:  0.0970297029703\n",
      "CPU times: user 15 µs, sys: 0 ns, total: 15 µs\n",
      "Wall time: 5.96 µs\n",
      "For  BFGSBinaryLogisticRegression  and cost  5.68986602902  Accuracy of:  0.0970297029703\n",
      "CPU times: user 15 µs, sys: 2 µs, total: 17 µs\n",
      "Wall time: 5.01 µs\n",
      "For  BFGSBinaryLogisticRegression  and cost  6.86648845004  Accuracy of:  0.0970297029703\n",
      "CPU times: user 11 µs, sys: 0 ns, total: 11 µs\n",
      "Wall time: 8.11 µs\n",
      "For  BFGSBinaryLogisticRegression  and cost  8.28642772855  Accuracy of:  0.0970297029703\n",
      "CPU times: user 2 µs, sys: 4 µs, total: 6 µs\n",
      "Wall time: 5.96 µs\n",
      "For  BFGSBinaryLogisticRegression  and cost  10.0  Accuracy of:  0.0970297029703\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "costs = np.logspace(-3,1)\n",
    "costs.sort()\n",
    "\n",
    "cost_accuracies = []\n",
    "optimizations = [\"BFGSBinaryLogisticRegression\"]#,\"StochasticLogisticRegression\",\"LineSearchLogisticRegression\"]\n",
    "\n",
    "for optimization in optimizations:\n",
    "    for cost in costs:\n",
    "        %%time\n",
    "        lr = MultiClassLogisticRegression(eta=0.1,\n",
    "                                           iterations=10,\n",
    "                                           C=cost,optimization=optimization) # get object\n",
    "        lr.fit(X,y)\n",
    "#         print(lr)\n",
    "        yhat = lr.predict(X)\n",
    "        acc = accuracy_score(y,yhat+1)\n",
    "        cost_accuracies.append([acc])\n",
    "        print('For ',optimization,' and cost ', cost,' Accuracy of: ',acc)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "li = [np.arange(1,51)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11cb95be0>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh0AAAGbCAYAAABgYSK/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11cb3fd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11cb95be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(cost_accuracies)\n",
    "plt.title(\"Determining Optimal Value of Regularization Term C\")\n",
    "plt.xlabel('Value of C ')\n",
    "plt.ylabel('Accuracy (%) ')\n",
    "costs_plot = np.around(costs,decimals=2)\n",
    "plt.xticks(li[0],costs_plot, rotation=65)\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute 'format'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-58e0de847007>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcost_accuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'format'"
     ]
    }
   ],
   "source": [
    "[cost.format(round(a,2) for cost in cost_accuracies)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cost_accuracies = np.around(cost_accuracies,decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
